group_by(sampledate) %>%
filter((flagwtemp) == "") %>%
filter(!is.na(wtemp)) %>%
filter(sum(!is.na(wtemp))>1) %>%
fill(wtemp, .direction = 'up') %>%
fill(wtemp, .direction = 'down') %>%
# mutate(wtemp = ifelse(row.number() ==1 & is.na(wtemp), lead(wtemp), wtemp)) %>%
# mutate(ifelse(is.na(wtemp[which.min(depth)])), wtemp[which.min(depth+1)], wtemp[which.min(depth)]) %>%
mutate(iwtemp = na.approx(wtemp)) %>%
mutate(wdens = get_dens(iwtemp, 0)) %>%
select(year4, sampledate, depth, iwtemp, wtemp, wdens)
hyp <- bath %>%
filter(lakeid == name)
data %>%
filter(year4 == a) %>%
group_by(sampledate)
strat.df <- data.frame('year' = NULL, 'on' = NULL, 'off' = NULL, 'duration' = NULL, 'id' = NULL)
en.df <- data.frame('sampledate' = NULL, 'energy' = NULL, 'n2' = NULL, 'id' = NULL)
for (name in ntl.id){
data <- dt1 %>%
filter(lakeid == name) %>%
group_by(sampledate) %>%
filter((flagwtemp) == "") %>%
filter(!is.na(wtemp)) %>%
filter(sum(!is.na(wtemp))>1) %>%
fill(wtemp, .direction = 'up') %>%
fill(wtemp, .direction = 'down') %>%
# mutate(wtemp = ifelse(row.number() ==1 & is.na(wtemp), lead(wtemp), wtemp)) %>%
# mutate(ifelse(is.na(wtemp[which.min(depth)])), wtemp[which.min(depth+1)], wtemp[which.min(depth)]) %>%
mutate(iwtemp = na.approx(wtemp)) %>%
mutate(wdens = get_dens(iwtemp, 0)) %>%
select(year4, sampledate, depth, iwtemp, wtemp, wdens)
for (a in unique(data$year4)){
hyp <- bath %>%
filter(lakeid == name)
df <- data %>%
filter(year4 == a) %>%
group_by(sampledate) %>%
distinct(depth, .keep_all = TRUE) %>%
# arrange(depth) %>%
mutate(dup = duplicated(depth)) %>%
summarise(#metadeps = meta.depths(wtr = iwtemp[which(dup == FALSE)],
#                      depths = depth[which(dup == FALSE)], slope = 0.1, seasonal = TRUE, mixed.cutoff = 1),
thermdep = thermo.depth(wtr = iwtemp[which(dup == FALSE)], depths = depth[which(dup == FALSE)],
Smin = 0.1, seasonal = TRUE, index = FALSE,
mixed.cutoff = 1),
densdiff = wdens[which.max(depth)] - wdens[which.min(depth)],
surfwtemp = iwtemp[which.min(depth)])
dz = 0.1
en <- data %>%
filter(year4 == a) %>%
group_by(sampledate) %>%
arrange(depth) %>%
summarise(z = seq(min(depth),max(depth),dz),
area = approx(hyp$Depth_m, hyp$area, seq(min(depth), max(depth),dz))$y,
density = approx(depth, wdens, seq(min(depth), max(depth),dz))$y,
temp = approx(depth, wtemp, seq(min(depth), max(depth),dz))$y) %>%
mutate('energy' = (area * dz) * density *temp * 4186,
'n2' = c(0,buoyancy.freq(temp, z))) %>%
summarise('energy' = sum(energy, na.rm = T)/max(area, na.rm = T),
'n2max' = max(n2))
df = df %>% mutate(densdiff = ifelse(densdiff > 0.1 & surfwtemp >= 4, densdiff, NA))
df <- df[complete.cases(df),]
strat.df <- rbind(strat.df, data.frame('year' = a,
'on' = yday(df$sampledate[which.min(df$sampledate)]),
'off' = yday(df$sampledate[which.max(df$sampledate)]),
'duration' = yday(df$sampledate[which.max(df$sampledate)]) - yday(df$sampledate[which.min(df$sampledate)]),
'id' = name))
en.df <- rbind(en.df, data.frame('sampledate' = en$sampledate, 'energy' = en$energy, 'n2' = en$n2max,
id = rep(name, nrow(en))))
}
}
m.strat.df <- reshape2::melt(strat.df, id.vars = 'id')
ggplot(subset(m.strat.df, variable != 'year')) +
geom_density(aes(x = value, col = id, fill = id), alpha = 0.5) +
facet_wrap(~ factor(variable))
g1 <- ggplot(en.df) +
geom_line(aes(sampledate, energy, col = id))+
geom_point(aes(sampledate, energy, col = id))+
facet_wrap(~ id, ncol =1) +
theme_minimal()
g2 <- ggplot(en.df) +
geom_line(aes(sampledate, n2, col = id))+
geom_point(aes(sampledate, n2, col = id))+
facet_wrap(~ id, ncol =1) +
theme_minimal()
g1 | g2 + plot_layout(guides = 'collect')
library(deSolve)
library(tidyverse)
LotVmod <- function (Time, State, Pars) {
with(as.list(c(State, Pars)), {
dx = x*(alpha - beta*y) # prey
dy = -y*(gamma - delta*x) # predator
return(list(c(dx, dy)))
})
}
# The prey grows at a linear rate (alpha) and gets eaten by the predator at the rate of (beta).
# The predator gains a certain amount vitality by eating the prey at a rate (delta), while dying off at another rate (gamma).
Pars <- c(alpha = 2, beta = .5, gamma = .2, delta = .6)
State <- c(x = 10, y = 10)
Time <- seq(0, 100, by = 1)
out <- as.data.frame(ode(func = LotVmod, y = State, parms = Pars, times = Time))
ggplot(out) +
geom_path(aes(x = time, y = x), col = 'blue') + #prey
geom_path(aes(x = time, y = y), col = 'red3') + #predator
theme_bw()
ggplot(out) +
geom_path(aes(x = time, y = x, col = 'prey')) + #prey
geom_path(aes(x = time, y = y, col = 'predator')) + #predator
theme_bw()
ggplot(out) +
geom_path(aes(x = time, y = x, col = 'prey')) + #prey
geom_path(aes(x = time, y = y, col = 'predator')) + #predator
theme_bw() +
labs(title = "Lotka-Volterra predator prey model",
subtitle = paste(names(Pars), Pars, sep = " = ", collapse = "; "),
x = "Time", y = "Population density")
# The prey grows at a linear rate (alpha) and gets eaten by the predator at the rate of (beta).
# The predator gains a certain amount vitality by eating the prey at a rate (delta), while dying off at another rate (gamma).
Pars <- c(alpha = 1, beta = 0.2, gamma = 0.5, delta = 0.2)
State <- c(x = 10, y = 10)
Time <- seq(0, 100, by = 1)
out <- as.data.frame(ode(func = LotVmod, y = State, parms = Pars, times = Time))
ggplot(out) +
geom_path(aes(x = time, y = x, col = 'prey')) + #prey
geom_path(aes(x = time, y = y, col = 'predator')) + #predator
theme_bw() +
labs(title = "Lotka-Volterra predator prey model",
subtitle = paste(names(Pars), Pars, sep = " = ", collapse = "; "),
x = "Time", y = "Population density")
Time <- seq(0, 60, by = 1)
out <- as.data.frame(ode(func = LotVmod, y = State, parms = Pars, times = Time))
ggplot(out) +
geom_path(aes(x = time, y = x, col = 'prey')) + #prey
geom_path(aes(x = time, y = y, col = 'predator')) + #predator
theme_bw() +
labs(title = "Lotka-Volterra predator prey model",
subtitle = paste(names(Pars), Pars, sep = " = ", collapse = "; "),
x = "Time", y = "Population density")
Time <- seq(0, 40, by = 1)
out <- as.data.frame(ode(func = LotVmod, y = State, parms = Pars, times = Time))
ggplot(out) +
geom_path(aes(x = time, y = x, col = 'prey')) + #prey
geom_path(aes(x = time, y = y, col = 'predator')) + #predator
theme_bw() +
labs(title = "Lotka-Volterra predator prey model",
subtitle = paste(names(Pars), Pars, sep = " = ", collapse = "; "),
x = "Time", y = "Population density")
ggplot(out) +
geom_path(aes(x = time, y = x, col = 'prey')) + #prey
geom_path(aes(x = time, y = y, col = 'predator')) + #predator
theme_bw() +
labs(title = "Lotka-Volterra predator prey model",
subtitle = paste(names(Pars), Pars, sep = " = ", collapse = "; "),
x = "Time", y = "Population density", fill = '')
ggplot(out) +
geom_path(aes(x = time, y = x, col = 'prey')) + #prey
geom_path(aes(x = time, y = y, col = 'predator')) + #predator
theme_bw() +
labs(title = "Lotka-Volterra predator prey model",
subtitle = paste(names(Pars), Pars, sep = " = ", collapse = "; "),
x = "Time", y = "Population density") +
guides(fill=guide_legend(title=""))
ggplot(out) +
geom_path(aes(x = time, y = x, col = 'prey')) + #prey
geom_path(aes(x = time, y = y, col = 'predator')) + #predator
theme_bw() +
labs(title = "Lotka-Volterra predator prey model",
subtitle = paste(names(Pars), Pars, sep = " = ", collapse = "; "),
x = "Time", y = "Population density") +
guides(fill="")
ggplot(out) +
geom_path(aes(x = time, y = x, col = 'prey')) + #prey
geom_path(aes(x = time, y = y, col = 'predator')) + #predator
theme_bw() +
labs(title = "Lotka-Volterra predator prey model",
subtitle = paste(names(Pars), Pars, sep = " = ", collapse = "; "),
x = "Time", y = "Population density", color = '')
shiny::runApp('Projects/DSI/LotkaVolterra/LotkaVolterra')
runApp('Projects/DSI/LotkaVolterra/LotkaVolterra')
runApp('Projects/DSI/LotkaVolterra/LotkaVolterra')
plot(lynx)
install.packages('tidyverse')
install.packages('tidyverse')
install.packages('tidyverse')
install.packages('dplyr')
install.packages('dplyr')
install.packages('tidyverse')
library(tidyverse)
install.packages('rLakeAnalyzer')
install.packages('plyr')
install.packages('Rcpp')
inUrl2  <- "https://pasta.lternet.edu/package/data/eml/knb-lter-ntl/130/29/63d0587cf326e83f57b054bf2ad0f7fe"
infile2 <- tempfile()
try(download.file(inUrl2,infile2,method="curl"))
if (is.na(file.size(infile2))) download.file(inUrl2,infile2,method="auto")
dt2 <-read.csv(infile2,header=F
,skip=1
,sep=","
,quot='"'
, col.names=c(
"sampledate",
"year4",
"month",
"daynum",
"hour",
"depth",
"wtemp",
"flag_wtemp"    ), check.names=TRUE)
unlink(infile2)
# Fix any interval or ratio columns mistakenly read in as nominal and nominal columns read as numeric or dates read as strings
# attempting to convert dt2$sampledate dateTime string to R date structure (date or POSIXct)
tmpDateFormat<-"%Y-%m-%d"
tmp2sampledate<-as.Date(dt2$sampledate,format=tmpDateFormat)
# Keep the new dates only if they all converted correctly
if(length(tmp2sampledate) == length(tmp2sampledate[!is.na(tmp2sampledate)])){dt2$sampledate <- tmp2sampledate } else {print("Date conversion failed for dt2$sampledate. Please inspect the data and do the date conversion yourself.")}
rm(tmpDateFormat,tmp2sampledate)
if (class(dt2$year4)=="factor") dt2$year4 <-as.numeric(levels(dt2$year4))[as.integer(dt2$year4) ]
if (class(dt2$year4)=="character") dt2$year4 <-as.numeric(dt2$year4)
if (class(dt2$month)=="factor") dt2$month <-as.numeric(levels(dt2$month))[as.integer(dt2$month) ]
if (class(dt2$month)=="character") dt2$month <-as.numeric(dt2$month)
if (class(dt2$daynum)=="factor") dt2$daynum <-as.numeric(levels(dt2$daynum))[as.integer(dt2$daynum) ]
if (class(dt2$daynum)=="character") dt2$daynum <-as.numeric(dt2$daynum)
if (class(dt2$depth)=="factor") dt2$depth <-as.numeric(levels(dt2$depth))[as.integer(dt2$depth) ]
if (class(dt2$depth)=="character") dt2$depth <-as.numeric(dt2$depth)
if (class(dt2$wtemp)=="factor") dt2$wtemp <-as.numeric(levels(dt2$wtemp))[as.integer(dt2$wtemp) ]
if (class(dt2$wtemp)=="character") dt2$wtemp <-as.numeric(dt2$wtemp)
if (class(dt2$flag_wtemp)!="factor") dt2$flag_wtemp<- as.factor(dt2$flag_wtemp)
# Convert Missing Values to NA for non-dates
# Here is the structure of the input data frame:
str(dt2)
attach(dt2)
# The analyses below are basic descriptions of the variables. After testing, they should be replaced.
summary(sampledate)
summary(year4)
summary(month)
summary(daynum)
summary(hour)
summary(depth)
summary(wtemp)
summary(flag_wtemp)
# Get more details on character variables
summary(as.factor(dt2$flag_wtemp))
detach(dt2)
head(dt2)
dt2$datetime <- as.POSIXct(paste0(sampledate,' ',hour,':00:00'))
dt2$datetime <- as.POSIXct(paste0(dt2$sampledate,' ',dt2$hour,':00:00'))
ggplot(subset(dt2, year > 2007 && year < 2009), aes(datetime, as.numeric(depth))) +
geom_raster(aes(fill = as.numeric(wtemp)), interpolate = TRUE) +
scale_fill_gradientn(limits = c(0,30),
colours = rev(RColorBrewer::brewer.pal(11, 'Spectral')))+
theme_minimal()  +xlab('Time') +
ylab('Depth') +
labs(fill = 'Temp. [degC]') +
scale_y_reverse()
library(tidyverse)
ggplot(subset(dt2, year > 2007 && year < 2009), aes(datetime, as.numeric(depth))) +
geom_raster(aes(fill = as.numeric(wtemp)), interpolate = TRUE) +
scale_fill_gradientn(limits = c(0,30),
colours = rev(RColorBrewer::brewer.pal(11, 'Spectral')))+
theme_minimal()  +xlab('Time') +
ylab('Depth') +
labs(fill = 'Temp. [degC]') +
scale_y_reverse()
ggplot(subset(dt2, year4 > 2007 && year4 < 2009), aes(datetime, as.numeric(depth))) +
geom_raster(aes(fill = as.numeric(wtemp)), interpolate = TRUE) +
scale_fill_gradientn(limits = c(0,30),
colours = rev(RColorBrewer::brewer.pal(11, 'Spectral')))+
theme_minimal()  +xlab('Time') +
ylab('Depth') +
labs(fill = 'Temp. [degC]') +
scale_y_reverse()
ggplot(subset(dt2, year4 > 2007 & year4 < 2009), aes(datetime, as.numeric(depth))) +
geom_raster(aes(fill = as.numeric(wtemp)), interpolate = TRUE) +
scale_fill_gradientn(limits = c(0,30),
colours = rev(RColorBrewer::brewer.pal(11, 'Spectral')))+
theme_minimal()  +xlab('Time') +
ylab('Depth') +
labs(fill = 'Temp. [degC]') +
scale_y_reverse()
ggplot(subset(dt2, year4 > 2007 & year4 < 2013), aes(datetime, as.numeric(depth))) +
geom_raster(aes(fill = as.numeric(wtemp)), interpolate = TRUE) +
scale_fill_gradientn(limits = c(0,30),
colours = rev(RColorBrewer::brewer.pal(11, 'Spectral')))+
theme_minimal()  +xlab('Time') +
ylab('Depth') +
labs(fill = 'Temp. [degC]') +
scale_y_reverse()
ggplot(subset(dt2, year4 == 2010), aes(datetime, as.numeric(depth))) +
geom_raster(aes(fill = as.numeric(wtemp)), interpolate = TRUE) +
scale_fill_gradientn(limits = c(0,30),
colours = rev(RColorBrewer::brewer.pal(11, 'Spectral')))+
theme_minimal()  +xlab('Time') +
ylab('Depth') +
labs(fill = 'Temp. [degC]') +
scale_y_reverse()
install.packages('akima')
install.packages('akima')
install.packages('oce')
install.packages('akima')
library(akima)
.interpolate2grid <- function(xyzData, xcol = 1, ycol = 2, zcol = 3) {
# Interpolate field or modeled data to grid
# xcol, ycol, and zcol and column numbers from data.frame
# The spreads of x and y must be within four orders of magnitude of each other for interp to work
# Therefore must scale data to be within similar magnitude to numeric dates (1e6)
gridData <-interp2xyz(akima::interp(x = as.numeric(xyzData[,xcol]), y=(xyzData[,ycol]*1e6), z=xyzData[,zcol], duplicate="mean", linear = T,
extrap = T,
xo = as.numeric(seq(min(xyzData[,xcol]), max(xyzData[,xcol]), by = 'days')), #precision
yo = 1e6*seq(min(xyzData[,ycol]), max(xyzData[,ycol]), by = 1)), data.frame=TRUE) %>%
dplyr::mutate(x =  as.POSIXct(x, origin = '1970-01-01', tz = Sys.timezone())) %>%
dplyr::mutate(y = y/1e6) %>%
dplyr::arrange(x,y)
return(gridData)
}
idx.na = which(is.na(dt2$wtemp))
dt2_omit <- dt2[-c(idx.na),]
# Akima interpolation of observed data (Gridded Bivariate Interpolation for Irregular Data)
str(dt2_omit)
observed_df <- .interpolate2grid(dt2_omit, xcol = 9, ycol = 6, zcol = 7) %>%
rename(DateTime = .data$x, Depth = .data$y, var = .data$z)
library(akima)
.interpolate2grid <- function(xyzData, xcol = 1, ycol = 2, zcol = 3) {
# Interpolate field or modeled data to grid
# xcol, ycol, and zcol and column numbers from data.frame
# The spreads of x and y must be within four orders of magnitude of each other for interp to work
# Therefore must scale data to be within similar magnitude to numeric dates (1e6)
gridData <-interp2xyz(akima::interp(x = as.numeric(xyzData[,xcol]), y=(xyzData[,ycol]*1e6), z=xyzData[,zcol], duplicate="mean", linear = T,
extrap = T,
xo = as.numeric(seq(min(xyzData[,xcol]), max(xyzData[,xcol]), by = 'hour')), #precision
yo = 1e6*seq(min(xyzData[,ycol]), max(xyzData[,ycol]), by = 1)), data.frame=TRUE) %>%
dplyr::mutate(x =  as.POSIXct(x, origin = '1970-01-01', tz = Sys.timezone())) %>%
dplyr::mutate(y = y/1e6) %>%
dplyr::arrange(x,y)
return(gridData)
}
idx.na = which(is.na(dt2$wtemp))
dt2_omit <- dt2[-c(idx.na),]
# Akima interpolation of observed data (Gridded Bivariate Interpolation for Irregular Data)
str(dt2_omit)
observed_df <- .interpolate2grid(dt2_omit, xcol = 9, ycol = 6, zcol = 7) %>%
rename(DateTime = .data$x, Depth = .data$y, var = .data$z)
observed_df
library(lubridate)
observed_df$year = year(observed_df$DateTime)
str(observed_df)
ggplot(subset(observed_df, year == 2010), aes(Datetime, as.numeric(Depth))) +
geom_raster(aes(fill = as.numeric(var)), interpolate = TRUE) +
scale_fill_gradientn(limits = c(0,30),
colours = rev(RColorBrewer::brewer.pal(11, 'Spectral')))+
theme_minimal()  +xlab('Time') +
ylab('Depth') +
labs(fill = 'Temp. [degC]') +
scale_y_reverse()
ggplot(subset(observed_df, year == 2010), aes(DateTime, as.numeric(Depth))) +
geom_raster(aes(fill = as.numeric(var)), interpolate = TRUE) +
scale_fill_gradientn(limits = c(0,30),
colours = rev(RColorBrewer::brewer.pal(11, 'Spectral')))+
theme_minimal()  +xlab('Time') +
ylab('Depth') +
labs(fill = 'Temp. [degC]') +
scale_y_reverse()
ggplot(subset(observed_df, year == 2010), aes(DateTime, as.numeric(Depth))) +
geom_raster(aes(fill = as.numeric(var)), interpolate = TRUE) +
scale_fill_gradientn(limits = c(-2,30),
colours = rev(RColorBrewer::brewer.pal(11, 'Spectral')))+
theme_minimal()  +xlab('Time') +
ylab('Depth') +
labs(fill = 'Temp. [degC]') +
scale_y_reverse()
ggsave('cont.png', units = 'in', dpi=300, width = 15, height = 10)
getwd()
ggsave('cont.png', units = 'in', dpi=300, width = 30, height = 20)
library(tidyverse)
library(rLakeAnalyzer)
library(lubridate)
cat("\f")
rm(list = ls())
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
library(keras)
library(tidyverse)
library(lubridate)
set.seed(123)
input_df <- read_csv('../output/meteorology_input.csv')
output_df <- read_csv('../output/temp_total04.csv')
buoy <- read_csv('../output/buoyancy.csv')
buoy
buoy <- buoy %>%
select(-time)
input_df <- cbind(input_df,buoy) %>%
select(-c(time,Area_m2))
input_df
input_df <- cbind(input_df,buoy) %>%
select(-c(time,Area_m2,n2S-2_25))
input_df <- read_csv('../output/meteorology_input.csv')
output_df <- read_csv('../output/temp_total04.csv')
buoy <- read_csv('../output/buoyancy.csv')
buoy <- buoy %>%
select(-time)
input_df <- cbind(input_df,buoy) %>%
select(-c(time,Area_m2,n2S-2_25))
input_df <- cbind(input_df,buoy) %>%
select(-c(time,Area_m2,'n2S-2_25'))
input_df
output_df <- output_df %>%
select(-time)
input <- as.matrix(cbind(input_df[2:nrow(input_df),], output_df[1:(nrow(output_df)-1),]))
target <- as.matrix(output_df[2:nrow(output_df),])
idx <- floor(nrow(input) * 0.6)
train_features <- input[1:idx,]
train_target <- target[1:idx,]
test_features <- input[(idx+1):nrow(input),]
test_target <- target[(idx+1):nrow(input),]
normalize <- function(x){
num <- x - min(x)
denom <- max(x) - min(x)
return(num/denom)
}
network = keras_model_sequential() %>%
layer_dense(units=32, activation="relu", input_shape=c(33)) %>%
# layer_dropout(rate = 0.2) %>%
layer_dense(units=32, activation = "relu") %>%
# layer_dropout(rate = 0.1) %>%
layer_dense(units=25, activation="linear")
summary(network)
network %>% compile(optimizer = 'adam',
loss = "mse", metrics = c("mean_absolute_error"))
network %>% fit(train_features, train_target, epochs = 1000, validation_split = 0.4)
str(train_features)
network = keras_model_sequential() %>%
layer_dense(units=32, activation="relu", input_shape=c(57)) %>%
# layer_dropout(rate = 0.2) %>%
layer_dense(units=32, activation = "relu") %>%
# layer_dropout(rate = 0.1) %>%
layer_dense(units=25, activation="linear")
summary(network)
network %>% compile(optimizer = 'adam',
loss = "mse", metrics = c("mean_absolute_error"))
network %>% fit(train_features, train_target, epochs = 1000, validation_split = 0.4)
network = keras_model_sequential() %>%
layer_dense(units=32, activation="gelu", input_shape=c(57)) %>%
# layer_dropout(rate = 0.2) %>%
layer_dense(units=32, activation = "gelu") %>%
# layer_dropout(rate = 0.1) %>%
layer_dense(units=25, activation="linear")
summary(network)
network %>% compile(optimizer = 'adam',
loss = "mse", metrics = c("mean_absolute_error"))
network %>% fit(train_features, train_target, epochs = 1000, validation_split = 0.4)
scores = network %>% evaluate(train_features, train_target, verbose = 0)
print(scores)
observed <- read_cv('../output/observed_temp.csv')
observed <- read_csv('../output/observed_temp.csv')
str(observed)
str(output_df)
cat("\f")
rm(list = ls())
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
library(keras)
library(tidyverse)
library(lubridate)
set.seed(123)
input_df <- read_csv('../output/meteorology_input.csv')
output_df <- read_csv('../output/temp_total04.csv')
buoy <- read_csv('../output/buoyancy.csv')
observed <- read_csv('../output/observed_temp.csv')
buoy <- buoy %>%
select(-time)
input_df <- cbind(input_df,buoy) %>%
select(-c(time,Area_m2,'n2S-2_25'))
output_df <- output_df %>%
select(-time)
observed <- observed %>%
select(-time)
input <- as.matrix(cbind(input_df[2:nrow(input_df),], output_df[1:(nrow(output_df)-1),]))
target <- as.matrix(output_df[2:nrow(output_df),])
target <- as.matrix(obsrved[2:nrow(observed),])
# network <- keras_model_sequential() %>%
#   layer_dense(units = 15, activation = "sigmoid", input_shape = c(34)) %>%
#   layer_dense(units = 25)
idx <- floor(nrow(input) * 0.6)
train_features <- input[1:idx,]
train_target <- target[1:idx,]
test_features <- input[(idx+1):nrow(input),]
test_target <- target[(idx+1):nrow(input),]
normalize <- function(x){
num <- x - min(x)
denom <- max(x) - min(x)
return(num/denom)
}
# normalise stuff?
# train_features <- as.matrix(apply(train_features, 2, normalize))
# train_target <- as.matrix(apply(train_target, 2, normalize))
# test_features <- as.matrix(apply(test_features, 2, normalize))
# test_target <- as.matrix(apply(test_target, 2, normalize))
network = keras_model_sequential() %>%
layer_dense(units=32, activation="gelu", input_shape=c(57)) %>%
# layer_dropout(rate = 0.2) %>%
layer_dense(units=32, activation = "gelu") %>%
# layer_dropout(rate = 0.1) %>%
layer_dense(units=25, activation="linear")
summary(network)
network %>% compile(optimizer = 'adam',
loss = "mse", metrics = c("mean_absolute_error"))
network %>% fit(train_features, train_target, epochs = 1000, validation_split = 0.4)
scores = network %>% evaluate(train_features, train_target, verbose = 0)
print(scores)
pred_train <- network %>% predict(train_features, batch_size = 128)
pred_test <- network %>% predict(test_features, batch_size = 128)
pred_test
val.scores = network %>% evaluate(test_features, test_target, verbose = 0)
print(val.scores)
