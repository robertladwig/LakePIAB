{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:2')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix03</th>\n",
       "      <th>temp_conv04</th>\n",
       "      <th>temp_initial00</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "      <th>ice</th>\n",
       "      <th>snow</th>\n",
       "      <th>snowice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.220007</td>\n",
       "      <td>590.851292</td>\n",
       "      <td>-30.129462</td>\n",
       "      <td>-35.559056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.757216</td>\n",
       "      <td>0.008038</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.379096</td>\n",
       "      <td>5.402835</td>\n",
       "      <td>5.431685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.220007</td>\n",
       "      <td>590.851292</td>\n",
       "      <td>-30.129462</td>\n",
       "      <td>-35.559056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.757216</td>\n",
       "      <td>0.008038</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.427976</td>\n",
       "      <td>5.429684</td>\n",
       "      <td>5.464454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.220007</td>\n",
       "      <td>590.851292</td>\n",
       "      <td>-30.129462</td>\n",
       "      <td>-35.559056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.757216</td>\n",
       "      <td>0.008038</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.458125</td>\n",
       "      <td>5.452260</td>\n",
       "      <td>5.481707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.220007</td>\n",
       "      <td>590.851292</td>\n",
       "      <td>-30.129462</td>\n",
       "      <td>-35.559056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.757216</td>\n",
       "      <td>0.008038</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.476137</td>\n",
       "      <td>5.452260</td>\n",
       "      <td>5.490656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-1.220007</td>\n",
       "      <td>590.851292</td>\n",
       "      <td>-30.129462</td>\n",
       "      <td>-35.559056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.757216</td>\n",
       "      <td>0.008038</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.486623</td>\n",
       "      <td>5.486623</td>\n",
       "      <td>5.495258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065970</th>\n",
       "      <td>21</td>\n",
       "      <td>3.860010</td>\n",
       "      <td>597.535984</td>\n",
       "      <td>25.682372</td>\n",
       "      <td>36.658380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.709571</td>\n",
       "      <td>0.068577</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>0.478225</td>\n",
       "      <td>0.496168</td>\n",
       "      <td>0.478190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.255083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065971</th>\n",
       "      <td>22</td>\n",
       "      <td>3.860010</td>\n",
       "      <td>597.535984</td>\n",
       "      <td>25.682372</td>\n",
       "      <td>36.658380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.709571</td>\n",
       "      <td>0.068577</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461923</td>\n",
       "      <td>0.483696</td>\n",
       "      <td>0.461851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.255083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065972</th>\n",
       "      <td>23</td>\n",
       "      <td>3.860010</td>\n",
       "      <td>597.535984</td>\n",
       "      <td>25.682372</td>\n",
       "      <td>36.658380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.709571</td>\n",
       "      <td>0.068577</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>0.456284</td>\n",
       "      <td>0.471708</td>\n",
       "      <td>0.456712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.255083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065973</th>\n",
       "      <td>24</td>\n",
       "      <td>3.860010</td>\n",
       "      <td>597.535984</td>\n",
       "      <td>25.682372</td>\n",
       "      <td>36.658380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.709571</td>\n",
       "      <td>0.068577</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.457236</td>\n",
       "      <td>0.456712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.255083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065974</th>\n",
       "      <td>25</td>\n",
       "      <td>3.860010</td>\n",
       "      <td>597.535984</td>\n",
       "      <td>25.682372</td>\n",
       "      <td>36.658380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.709571</td>\n",
       "      <td>0.068577</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>4.151886</td>\n",
       "      <td>4.151886</td>\n",
       "      <td>4.151886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.255083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3065975 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0            1     -1.220007     590.851292   -30.129462     -35.559056   \n",
       "1            2     -1.220007     590.851292   -30.129462     -35.559056   \n",
       "2            3     -1.220007     590.851292   -30.129462     -35.559056   \n",
       "3            4     -1.220007     590.851292   -30.129462     -35.559056   \n",
       "4            5     -1.220007     590.851292   -30.129462     -35.559056   \n",
       "...        ...           ...            ...          ...            ...   \n",
       "3065970     21      3.860010     597.535984    25.682372      36.658380   \n",
       "3065971     22      3.860010     597.535984    25.682372      36.658380   \n",
       "3065972     23      3.860010     597.535984    25.682372      36.658380   \n",
       "3065973     24      3.860010     597.535984    25.682372      36.658380   \n",
       "3065974     25      3.860010     597.535984    25.682372      36.658380   \n",
       "\n",
       "         Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  \\\n",
       "0                   0.0               0.8            1.757216   \n",
       "1                   0.0               0.8            1.757216   \n",
       "2                   0.0               0.8            1.757216   \n",
       "3                   0.0               0.8            1.757216   \n",
       "4                   0.0               0.8            1.757216   \n",
       "...                 ...               ...                 ...   \n",
       "3065970             0.0               0.8            6.709571   \n",
       "3065971             0.0               0.8            6.709571   \n",
       "3065972             0.0               0.8            6.709571   \n",
       "3065973             0.0               0.8            6.709571   \n",
       "3065974             0.0               0.8            6.709571   \n",
       "\n",
       "         ShearStress_Nm-2     Area_m2  ...  day_of_year  time_of_day  \\\n",
       "0                0.008038  36000000.0  ...            1            2   \n",
       "1                0.008038  36000000.0  ...            1            2   \n",
       "2                0.008038  36000000.0  ...            1            2   \n",
       "3                0.008038  36000000.0  ...            1            2   \n",
       "4                0.008038  36000000.0  ...            1            2   \n",
       "...                   ...         ...  ...          ...          ...   \n",
       "3065970          0.068577  36000000.0  ...          363            0   \n",
       "3065971          0.068577  36000000.0  ...          363            0   \n",
       "3065972          0.068577  36000000.0  ...          363            0   \n",
       "3065973          0.068577  36000000.0  ...          363            0   \n",
       "3065974          0.068577  36000000.0  ...          363            0   \n",
       "\n",
       "         temp_mix03  temp_conv04  temp_initial00  obs_temp  input_obs  \\\n",
       "0          5.379096     5.402835        5.431685       NaN        NaN   \n",
       "1          5.427976     5.429684        5.464454       NaN        NaN   \n",
       "2          5.458125     5.452260        5.481707       NaN        NaN   \n",
       "3          5.476137     5.452260        5.490656       NaN        NaN   \n",
       "4          5.486623     5.486623        5.495258       NaN        NaN   \n",
       "...             ...          ...             ...       ...        ...   \n",
       "3065970    0.478225     0.496168        0.478190       NaN        NaN   \n",
       "3065971    0.461923     0.483696        0.461851       NaN        NaN   \n",
       "3065972    0.456284     0.471708        0.456712       NaN        NaN   \n",
       "3065973    0.001672     0.457236        0.456712       NaN        NaN   \n",
       "3065974    4.151886     4.151886        4.151886       NaN        NaN   \n",
       "\n",
       "              ice  snow  snowice  \n",
       "0        0.000000   0.0      0.0  \n",
       "1        0.000000   0.0      0.0  \n",
       "2        0.000000   0.0      0.0  \n",
       "3        0.000000   0.0      0.0  \n",
       "4        0.000000   0.0      0.0  \n",
       "...           ...   ...      ...  \n",
       "3065970  0.255083   0.0      0.0  \n",
       "3065971  0.255083   0.0      0.0  \n",
       "3065972  0.255083   0.0      0.0  \n",
       "3065973  0.255083   0.0      0.0  \n",
       "3065974  0.255083   0.0      0.0  \n",
       "\n",
       "[3065975 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 122639\n",
      "Number of training points: 1839575\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'ShearVelocity_mS-1', 'ShearStress_Nm-2', 'day_of_year', \n",
    "                 'time_of_day', 'ice', 'snow', 'snowice','temp_diff02']\n",
    "output_columns = ['temp_mix03']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1839575, 9), X_test: (1226400, 9)\n",
      "y_train: (1839575, 1), y_test: (1226400, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1024\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=9, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:20<5:46:48, 20.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 0.021229637870445857, Test_loss: 0.0011478922822968339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [15:11<5:31:02, 20.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 0.0004133505432005675, Test_loss: 0.00044799695742524714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [30:29<5:13:16, 20.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Train_loss: 0.0003802729361293881, Test_loss: 0.000419459614274201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 151/1000 [45:38<4:59:06, 21.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 150, Train_loss: 0.0003422764149361518, Test_loss: 0.00039877924029686117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [1:00:49<4:36:34, 20.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 200, Train_loss: 0.0003328309799354375, Test_loss: 0.0003898757635610437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 251/1000 [1:16:03<4:31:41, 21.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 250, Train_loss: 0.0003264962788110071, Test_loss: 0.0003656162123441137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [1:31:24<4:11:11, 21.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 300, Train_loss: 0.0003193578857252308, Test_loss: 0.00039168504648235905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 351/1000 [1:46:48<3:52:12, 21.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 350, Train_loss: 0.0003141150508370246, Test_loss: 0.00036014209476059535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [2:02:04<3:29:27, 20.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400, Train_loss: 0.00030760504269671234, Test_loss: 0.00037924172704611206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 451/1000 [2:17:11<3:12:49, 21.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 450, Train_loss: 0.000310508435452148, Test_loss: 0.00036795122101161405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [2:32:15<2:52:56, 20.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500, Train_loss: 0.0002883890610812091, Test_loss: 0.00034615166938129876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 551/1000 [2:47:24<2:35:28, 20.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 550, Train_loss: 0.0002849137588784493, Test_loss: 0.0003492286245729562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 601/1000 [3:02:37<2:20:25, 21.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600, Train_loss: 0.0002845552822675193, Test_loss: 0.0003410185604904111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 651/1000 [3:17:47<2:00:26, 20.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 650, Train_loss: 0.00028349265563407664, Test_loss: 0.000343775583749832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 701/1000 [3:32:51<1:42:57, 20.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 700, Train_loss: 0.00028193084811046934, Test_loss: 0.00034171651685416276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 751/1000 [3:47:54<1:26:33, 20.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 750, Train_loss: 0.000281606105632812, Test_loss: 0.00034202656171579437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 801/1000 [4:03:04<1:09:15, 20.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800, Train_loss: 0.000281224463966099, Test_loss: 0.00034458095467281344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 851/1000 [4:18:12<51:34, 20.77s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 850, Train_loss: 0.00028068345965789616, Test_loss: 0.0003424726274068928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 901/1000 [4:33:15<34:08, 20.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900, Train_loss: 0.00027996528522708226, Test_loss: 0.00034182803025266167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 951/1000 [4:48:24<17:09, 21.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 950, Train_loss: 0.00027988234739400306, Test_loss: 0.00033974617551308533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [5:03:15<00:00, 18.20s/it]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_[:,0], pred_[:,0])\n",
    "    \n",
    "    l2_error_temp = l2_error(y_[:,0], pred_[:,0])\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 0.12194736170779724\n",
      "L2 Error  of Temp: 0.011897466445907267\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 0.11018267932198954\n",
      "L2 Error  of Temp: 0.011469719280275311\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/mixing_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.97979954])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
