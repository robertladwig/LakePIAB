{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:2')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix03</th>\n",
       "      <th>temp_conv04</th>\n",
       "      <th>temp_initial00</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "      <th>ice</th>\n",
       "      <th>snow</th>\n",
       "      <th>snowice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.220007</td>\n",
       "      <td>590.730964</td>\n",
       "      <td>-35.085181</td>\n",
       "      <td>-41.432575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.439240</td>\n",
       "      <td>0.013584</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.278988</td>\n",
       "      <td>5.334504</td>\n",
       "      <td>5.406383</td>\n",
       "      <td>5.334504</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.220007</td>\n",
       "      <td>590.730964</td>\n",
       "      <td>-35.085181</td>\n",
       "      <td>-41.432575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.439240</td>\n",
       "      <td>0.013584</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.335771</td>\n",
       "      <td>5.372093</td>\n",
       "      <td>5.436557</td>\n",
       "      <td>5.372093</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.220007</td>\n",
       "      <td>590.730964</td>\n",
       "      <td>-35.085181</td>\n",
       "      <td>-41.432575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.439240</td>\n",
       "      <td>0.013584</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.425026</td>\n",
       "      <td>5.409226</td>\n",
       "      <td>5.436557</td>\n",
       "      <td>5.409226</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.220007</td>\n",
       "      <td>590.730964</td>\n",
       "      <td>-35.085181</td>\n",
       "      <td>-41.432575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.439240</td>\n",
       "      <td>0.013584</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.462485</td>\n",
       "      <td>5.440322</td>\n",
       "      <td>5.468520</td>\n",
       "      <td>5.440322</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-1.220007</td>\n",
       "      <td>590.730964</td>\n",
       "      <td>-35.085181</td>\n",
       "      <td>-41.432575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.439240</td>\n",
       "      <td>0.013584</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.486707</td>\n",
       "      <td>5.440322</td>\n",
       "      <td>5.498996</td>\n",
       "      <td>5.440322</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065970</th>\n",
       "      <td>21</td>\n",
       "      <td>3.860010</td>\n",
       "      <td>597.535984</td>\n",
       "      <td>35.016904</td>\n",
       "      <td>49.982107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>9.313737</td>\n",
       "      <td>0.115895</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>0.208127</td>\n",
       "      <td>0.208127</td>\n",
       "      <td>0.193572</td>\n",
       "      <td>0.208127</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.251441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065971</th>\n",
       "      <td>22</td>\n",
       "      <td>3.860010</td>\n",
       "      <td>597.535984</td>\n",
       "      <td>35.016904</td>\n",
       "      <td>49.982107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>9.313737</td>\n",
       "      <td>0.115895</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>0.246119</td>\n",
       "      <td>0.246119</td>\n",
       "      <td>0.231173</td>\n",
       "      <td>0.246119</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.251441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065972</th>\n",
       "      <td>23</td>\n",
       "      <td>3.860010</td>\n",
       "      <td>597.535984</td>\n",
       "      <td>35.016904</td>\n",
       "      <td>49.982107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>9.313737</td>\n",
       "      <td>0.115895</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>0.290310</td>\n",
       "      <td>0.290310</td>\n",
       "      <td>0.281563</td>\n",
       "      <td>0.290310</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.251441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065973</th>\n",
       "      <td>24</td>\n",
       "      <td>3.860010</td>\n",
       "      <td>597.535984</td>\n",
       "      <td>35.016904</td>\n",
       "      <td>49.982107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>9.313737</td>\n",
       "      <td>0.115895</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>0.328151</td>\n",
       "      <td>0.328151</td>\n",
       "      <td>0.350871</td>\n",
       "      <td>0.328151</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.251441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065974</th>\n",
       "      <td>25</td>\n",
       "      <td>3.860010</td>\n",
       "      <td>597.535984</td>\n",
       "      <td>35.016904</td>\n",
       "      <td>49.982107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>9.313737</td>\n",
       "      <td>0.115895</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>4.288655</td>\n",
       "      <td>4.288655</td>\n",
       "      <td>4.288655</td>\n",
       "      <td>4.288655</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.251441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3065975 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0            1     -1.220007     590.730964   -35.085181     -41.432575   \n",
       "1            2     -1.220007     590.730964   -35.085181     -41.432575   \n",
       "2            3     -1.220007     590.730964   -35.085181     -41.432575   \n",
       "3            4     -1.220007     590.730964   -35.085181     -41.432575   \n",
       "4            5     -1.220007     590.730964   -35.085181     -41.432575   \n",
       "...        ...           ...            ...          ...            ...   \n",
       "3065970     21      3.860010     597.535984    35.016904      49.982107   \n",
       "3065971     22      3.860010     597.535984    35.016904      49.982107   \n",
       "3065972     23      3.860010     597.535984    35.016904      49.982107   \n",
       "3065973     24      3.860010     597.535984    35.016904      49.982107   \n",
       "3065974     25      3.860010     597.535984    35.016904      49.982107   \n",
       "\n",
       "         Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  \\\n",
       "0                   0.0               0.4            2.439240   \n",
       "1                   0.0               0.4            2.439240   \n",
       "2                   0.0               0.4            2.439240   \n",
       "3                   0.0               0.4            2.439240   \n",
       "4                   0.0               0.4            2.439240   \n",
       "...                 ...               ...                 ...   \n",
       "3065970             0.0               0.4            9.313737   \n",
       "3065971             0.0               0.4            9.313737   \n",
       "3065972             0.0               0.4            9.313737   \n",
       "3065973             0.0               0.4            9.313737   \n",
       "3065974             0.0               0.4            9.313737   \n",
       "\n",
       "         ShearStress_Nm-2     Area_m2  ...  day_of_year  time_of_day  \\\n",
       "0                0.013584  36000000.0  ...            1            2   \n",
       "1                0.013584  36000000.0  ...            1            2   \n",
       "2                0.013584  36000000.0  ...            1            2   \n",
       "3                0.013584  36000000.0  ...            1            2   \n",
       "4                0.013584  36000000.0  ...            1            2   \n",
       "...                   ...         ...  ...          ...          ...   \n",
       "3065970          0.115895  36000000.0  ...          363            0   \n",
       "3065971          0.115895  36000000.0  ...          363            0   \n",
       "3065972          0.115895  36000000.0  ...          363            0   \n",
       "3065973          0.115895  36000000.0  ...          363            0   \n",
       "3065974          0.115895  36000000.0  ...          363            0   \n",
       "\n",
       "         temp_mix03  temp_conv04  temp_initial00  obs_temp  input_obs  \\\n",
       "0          5.278988     5.334504        5.406383  5.334504     -999.0   \n",
       "1          5.335771     5.372093        5.436557  5.372093     -999.0   \n",
       "2          5.425026     5.409226        5.436557  5.409226     -999.0   \n",
       "3          5.462485     5.440322        5.468520  5.440322     -999.0   \n",
       "4          5.486707     5.440322        5.498996  5.440322     -999.0   \n",
       "...             ...          ...             ...       ...        ...   \n",
       "3065970    0.208127     0.208127        0.193572  0.208127     -999.0   \n",
       "3065971    0.246119     0.246119        0.231173  0.246119     -999.0   \n",
       "3065972    0.290310     0.290310        0.281563  0.290310     -999.0   \n",
       "3065973    0.328151     0.328151        0.350871  0.328151     -999.0   \n",
       "3065974    4.288655     4.288655        4.288655  4.288655     -999.0   \n",
       "\n",
       "              ice  snow  snowice  \n",
       "0        0.000000   0.0      0.0  \n",
       "1        0.000000   0.0      0.0  \n",
       "2        0.000000   0.0      0.0  \n",
       "3        0.000000   0.0      0.0  \n",
       "4        0.000000   0.0      0.0  \n",
       "...           ...   ...      ...  \n",
       "3065970  0.251441   0.0      0.0  \n",
       "3065971  0.251441   0.0      0.0  \n",
       "3065972  0.251441   0.0      0.0  \n",
       "3065973  0.251441   0.0      0.0  \n",
       "3065974  0.251441   0.0      0.0  \n",
       "\n",
       "[3065975 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 122639\n",
      "Number of training points: 1839575\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'day_of_year', 'time_of_day', 'temp_diff02']\n",
    "output_columns = ['temp_conv04']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1839575, 4), X_test: (1226400, 4)\n",
      "y_train: (1839575, 1), y_test: (1226400, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1024\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=4, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:36<10:09:14, 36.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 0.018629883255788297, Test_loss: 0.002670607331732851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [20:49<7:18:56, 27.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 0.0003843795026467365, Test_loss: 0.00042308911332412106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [36:42<5:06:22, 20.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Train_loss: 0.0003709736911600827, Test_loss: 0.00040457966231326756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 151/1000 [51:30<4:47:58, 20.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 150, Train_loss: 0.0003627681568488528, Test_loss: 0.00041748144459189995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [1:06:21<4:32:15, 20.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 200, Train_loss: 0.00035716831488159713, Test_loss: 0.000383056052606785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 251/1000 [1:21:12<4:16:20, 20.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 250, Train_loss: 0.0003533336084855474, Test_loss: 0.0003902321522234262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [1:36:07<4:04:52, 21.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 300, Train_loss: 0.00034958791989212753, Test_loss: 0.00038151318830852404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 351/1000 [1:51:01<3:40:40, 20.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 350, Train_loss: 0.00034788022259689253, Test_loss: 0.0003850493115966821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [2:05:55<3:25:40, 20.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400, Train_loss: 0.000346021281229954, Test_loss: 0.00038988172156726635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 451/1000 [2:20:46<3:07:15, 20.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 450, Train_loss: 0.00034475638338985414, Test_loss: 0.0003914850212879723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [2:35:40<2:51:02, 20.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500, Train_loss: 0.0003350850895451953, Test_loss: 0.000375839954973839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 551/1000 [2:50:26<2:31:09, 20.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 550, Train_loss: 0.00033391075527419077, Test_loss: 0.0003786384616463896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 601/1000 [3:05:19<2:17:15, 20.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600, Train_loss: 0.000333686903830309, Test_loss: 0.00037623839385083366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 651/1000 [3:20:12<1:58:39, 20.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 650, Train_loss: 0.0003332039500373163, Test_loss: 0.00037611176461672653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 701/1000 [3:34:59<1:44:15, 20.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 700, Train_loss: 0.0003329546210443773, Test_loss: 0.0003754945705808957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 751/1000 [3:49:54<1:25:23, 20.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 750, Train_loss: 0.0003327059396926449, Test_loss: 0.00037541506460517465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 801/1000 [4:04:48<1:08:11, 20.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800, Train_loss: 0.0003326021015700953, Test_loss: 0.00037655547608488185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 851/1000 [4:19:45<51:29, 20.74s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 850, Train_loss: 0.000332169862687637, Test_loss: 0.00037713289100604154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 901/1000 [4:34:41<34:29, 20.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900, Train_loss: 0.00033201861821913664, Test_loss: 0.0003763197784084539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 951/1000 [4:49:37<16:47, 20.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 950, Train_loss: 0.00033182553077922125, Test_loss: 0.0003759334359405275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [5:04:09<00:00, 18.25s/it]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_[:,0], pred_[:,0])\n",
    "    \n",
    "    l2_error_temp = l2_error(y_[:,0], pred_[:,0])\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 0.10762586131343226\n",
      "L2 Error  of Temp: 0.0134926626490021\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 0.1009503702166739\n",
      "L2 Error  of Temp: 0.01333694947921216\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/convection_model_time_HS.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.15043004])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
