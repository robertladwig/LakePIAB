{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ladwi\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:2')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix03</th>\n",
       "      <th>temp_conv04</th>\n",
       "      <th>temp_initial00</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "      <th>ice</th>\n",
       "      <th>snow</th>\n",
       "      <th>snowice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.260530</td>\n",
       "      <td>565.10046</td>\n",
       "      <td>-4.184752</td>\n",
       "      <td>-4.714701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.115875</td>\n",
       "      <td>-0.115875</td>\n",
       "      <td>-0.019025</td>\n",
       "      <td>5.558093</td>\n",
       "      <td>5.560076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.260530</td>\n",
       "      <td>565.10046</td>\n",
       "      <td>-4.184752</td>\n",
       "      <td>-4.714701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "      <td>0.470220</td>\n",
       "      <td>0.470220</td>\n",
       "      <td>-0.019025</td>\n",
       "      <td>4.870203</td>\n",
       "      <td>4.876163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.260530</td>\n",
       "      <td>565.10046</td>\n",
       "      <td>-4.184752</td>\n",
       "      <td>-4.714701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "      <td>1.092054</td>\n",
       "      <td>1.073671</td>\n",
       "      <td>0.046866</td>\n",
       "      <td>5.106928</td>\n",
       "      <td>5.112209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.260530</td>\n",
       "      <td>565.10046</td>\n",
       "      <td>-4.184752</td>\n",
       "      <td>-4.714701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "      <td>1.054755</td>\n",
       "      <td>1.073671</td>\n",
       "      <td>0.799295</td>\n",
       "      <td>5.106928</td>\n",
       "      <td>5.112209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-1.260530</td>\n",
       "      <td>565.10046</td>\n",
       "      <td>-4.184752</td>\n",
       "      <td>-4.714701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "      <td>1.312011</td>\n",
       "      <td>1.312011</td>\n",
       "      <td>1.381341</td>\n",
       "      <td>5.106928</td>\n",
       "      <td>5.112209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752345</th>\n",
       "      <td>46</td>\n",
       "      <td>-3.080809</td>\n",
       "      <td>529.16738</td>\n",
       "      <td>-15.814628</td>\n",
       "      <td>-20.288304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.155746</td>\n",
       "      <td>4.155746</td>\n",
       "      <td>4.155679</td>\n",
       "      <td>4.045759</td>\n",
       "      <td>4.047768</td>\n",
       "      <td>0.283046</td>\n",
       "      <td>0.025199</td>\n",
       "      <td>0.044785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752346</th>\n",
       "      <td>47</td>\n",
       "      <td>-3.080809</td>\n",
       "      <td>529.16738</td>\n",
       "      <td>-15.814628</td>\n",
       "      <td>-20.288304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.250744</td>\n",
       "      <td>4.250744</td>\n",
       "      <td>4.250654</td>\n",
       "      <td>4.435799</td>\n",
       "      <td>4.438573</td>\n",
       "      <td>0.283046</td>\n",
       "      <td>0.025199</td>\n",
       "      <td>0.044785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752347</th>\n",
       "      <td>48</td>\n",
       "      <td>-3.080809</td>\n",
       "      <td>529.16738</td>\n",
       "      <td>-15.814628</td>\n",
       "      <td>-20.288304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.347902</td>\n",
       "      <td>4.347902</td>\n",
       "      <td>4.347777</td>\n",
       "      <td>5.532094</td>\n",
       "      <td>5.534868</td>\n",
       "      <td>0.283046</td>\n",
       "      <td>0.025199</td>\n",
       "      <td>0.044785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752348</th>\n",
       "      <td>49</td>\n",
       "      <td>-3.080809</td>\n",
       "      <td>529.16738</td>\n",
       "      <td>-15.814628</td>\n",
       "      <td>-20.288304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.438525</td>\n",
       "      <td>4.438525</td>\n",
       "      <td>4.438403</td>\n",
       "      <td>7.391329</td>\n",
       "      <td>7.391820</td>\n",
       "      <td>0.283046</td>\n",
       "      <td>0.025199</td>\n",
       "      <td>0.044785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752349</th>\n",
       "      <td>50</td>\n",
       "      <td>-3.080809</td>\n",
       "      <td>529.16738</td>\n",
       "      <td>-15.814628</td>\n",
       "      <td>-20.288304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.538099</td>\n",
       "      <td>4.538099</td>\n",
       "      <td>4.537926</td>\n",
       "      <td>11.007965</td>\n",
       "      <td>11.008260</td>\n",
       "      <td>0.283046</td>\n",
       "      <td>0.025199</td>\n",
       "      <td>0.044785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1752350 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0            1     -1.260530      565.10046    -4.184752      -4.714701   \n",
       "1            2     -1.260530      565.10046    -4.184752      -4.714701   \n",
       "2            3     -1.260530      565.10046    -4.184752      -4.714701   \n",
       "3            4     -1.260530      565.10046    -4.184752      -4.714701   \n",
       "4            5     -1.260530      565.10046    -4.184752      -4.714701   \n",
       "...        ...           ...            ...          ...            ...   \n",
       "1752345     46     -3.080809      529.16738   -15.814628     -20.288304   \n",
       "1752346     47     -3.080809      529.16738   -15.814628     -20.288304   \n",
       "1752347     48     -3.080809      529.16738   -15.814628     -20.288304   \n",
       "1752348     49     -3.080809      529.16738   -15.814628     -20.288304   \n",
       "1752349     50     -3.080809      529.16738   -15.814628     -20.288304   \n",
       "\n",
       "         Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  \\\n",
       "0                   0.0               0.4              -999.0   \n",
       "1                   0.0               0.4              -999.0   \n",
       "2                   0.0               0.4              -999.0   \n",
       "3                   0.0               0.4              -999.0   \n",
       "4                   0.0               0.4              -999.0   \n",
       "...                 ...               ...                 ...   \n",
       "1752345             0.0               0.4              -999.0   \n",
       "1752346             0.0               0.4              -999.0   \n",
       "1752347             0.0               0.4              -999.0   \n",
       "1752348             0.0               0.4              -999.0   \n",
       "1752349             0.0               0.4              -999.0   \n",
       "\n",
       "         ShearStress_Nm-2     Area_m2  ...  day_of_year  time_of_day  \\\n",
       "0                  -999.0  39850000.0  ...          364            1   \n",
       "1                  -999.0  39850000.0  ...          364            1   \n",
       "2                  -999.0  39850000.0  ...          364            1   \n",
       "3                  -999.0  39850000.0  ...          364            1   \n",
       "4                  -999.0  39850000.0  ...          364            1   \n",
       "...                   ...         ...  ...          ...          ...   \n",
       "1752345            -999.0  39850000.0  ...          362           23   \n",
       "1752346            -999.0  39850000.0  ...          362           23   \n",
       "1752347            -999.0  39850000.0  ...          362           23   \n",
       "1752348            -999.0  39850000.0  ...          362           23   \n",
       "1752349            -999.0  39850000.0  ...          362           23   \n",
       "\n",
       "         temp_mix03  temp_conv04  temp_initial00   obs_temp  input_obs  \\\n",
       "0         -0.115875    -0.115875       -0.019025   5.558093   5.560076   \n",
       "1          0.470220     0.470220       -0.019025   4.870203   4.876163   \n",
       "2          1.092054     1.073671        0.046866   5.106928   5.112209   \n",
       "3          1.054755     1.073671        0.799295   5.106928   5.112209   \n",
       "4          1.312011     1.312011        1.381341   5.106928   5.112209   \n",
       "...             ...          ...             ...        ...        ...   \n",
       "1752345    4.155746     4.155746        4.155679   4.045759   4.047768   \n",
       "1752346    4.250744     4.250744        4.250654   4.435799   4.438573   \n",
       "1752347    4.347902     4.347902        4.347777   5.532094   5.534868   \n",
       "1752348    4.438525     4.438525        4.438403   7.391329   7.391820   \n",
       "1752349    4.538099     4.538099        4.537926  11.007965  11.008260   \n",
       "\n",
       "              ice      snow   snowice  \n",
       "0        0.000000  0.000000  0.000000  \n",
       "1        0.000000  0.000000  0.000000  \n",
       "2        0.000000  0.000000  0.000000  \n",
       "3        0.000000  0.000000  0.000000  \n",
       "4        0.000000  0.000000  0.000000  \n",
       "...           ...       ...       ...  \n",
       "1752345  0.283046  0.025199  0.044785  \n",
       "1752346  0.283046  0.025199  0.044785  \n",
       "1752347  0.283046  0.025199  0.044785  \n",
       "1752348  0.283046  0.025199  0.044785  \n",
       "1752349  0.283046  0.025199  0.044785  \n",
       "\n",
       "[1752350 rows x 45 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 70094\n",
      "Number of training points: 1051400\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'AirTemp_degC', 'Longwave_Wm-2', 'Latent_Wm-2', 'Sensible_Wm-2', 'Shortwave_Wm-2',\n",
    "                'lightExtinct_m-1','Area_m2', 'Uw',\n",
    "                 'day_of_year', 'time_of_day',  \n",
    "                 'buoyancy', 'diffusivity', 'temp_initial00', \n",
    "                'temp_heat01', 'temp_diff02', 'temp_conv04', 'temp_total05',\n",
    "                'ice', 'snow', 'snowice']\n",
    "output_columns = ['obs_temp']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1051400, 21), X_test: (700950, 21)\n",
      "y_train: (1051400, 1), y_test: (700950, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1024\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32,32,32,32,32,32,32,32,32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=21, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_2): GELU()\n",
      "    (layer_3): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_3): GELU()\n",
      "    (layer_4): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_4): GELU()\n",
      "    (layer_5): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_5): GELU()\n",
      "    (layer_6): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_6): GELU()\n",
      "    (layer_7): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_7): GELU()\n",
      "    (layer_8): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_8): GELU()\n",
      "    (layer_9): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_9): GELU()\n",
      "    (layer_10): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:19<5:16:41, 19.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 0.06535570001902517, Test_loss: 0.12575105924777905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [12:17<4:22:03, 16.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 0.003381069310117393, Test_loss: 0.1345811281954856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [24:51<4:14:35, 16.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Train_loss: 0.002642544768360727, Test_loss: 0.13773518779185892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 151/1000 [36:02<3:46:56, 16.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 150, Train_loss: 0.0023429268888790003, Test_loss: 0.13424188568100442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [46:41<3:11:10, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 200, Train_loss: 0.0021520578463406765, Test_loss: 0.13885043630627983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 251/1000 [57:21<3:00:09, 14.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 250, Train_loss: 0.002138698555868275, Test_loss: 0.1390049062669277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [1:07:58<2:47:18, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 300, Train_loss: 0.001947619643029707, Test_loss: 0.13188734454864187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 351/1000 [1:18:53<2:40:05, 14.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 350, Train_loss: 0.001936173414609267, Test_loss: 0.14119627538857724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [1:30:51<2:50:50, 17.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400, Train_loss: 0.0018393901711104923, Test_loss: 0.13950232929400555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 451/1000 [1:43:48<2:48:20, 18.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 450, Train_loss: 0.0018530906512000268, Test_loss: 0.13924400714042523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [1:56:59<2:29:33, 17.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500, Train_loss: 0.0013447113245242286, Test_loss: 0.1396121826355964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 551/1000 [2:10:08<2:12:17, 17.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 550, Train_loss: 0.0012386714691725155, Test_loss: 0.13832407352738899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 601/1000 [2:23:13<1:55:57, 17.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600, Train_loss: 0.0012201369889017046, Test_loss: 0.13802354974046785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 651/1000 [2:35:58<1:49:39, 18.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 650, Train_loss: 0.0012053253650896527, Test_loss: 0.13866068422352473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 701/1000 [2:48:47<1:19:35, 15.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 700, Train_loss: 0.001194927641467174, Test_loss: 0.13950994892222604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 751/1000 [3:00:29<1:07:11, 16.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 750, Train_loss: 0.001185354072464124, Test_loss: 0.14009251784988727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 801/1000 [3:12:59<56:46, 17.12s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800, Train_loss: 0.0011763420139490187, Test_loss: 0.13973917389512877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 851/1000 [3:25:13<40:39, 16.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 850, Train_loss: 0.0011702309954982203, Test_loss: 0.14087425967012226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 901/1000 [3:37:04<24:28, 14.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900, Train_loss: 0.0011619035157528293, Test_loss: 0.14022651654362245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 951/1000 [3:47:50<11:50, 14.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 950, Train_loss: 0.0011567063755450993, Test_loss: 0.14046440834628188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [3:58:39<00:00, 14.32s/it]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_[:,0], pred_[:,0])\n",
    "    \n",
    "    l2_error_temp = l2_error(y_[:,0], pred_[:,0])\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 2.4253917105196834\n",
      "L2 Error  of Temp: 0.20223373184165921\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 0.21765792709287385\n",
      "L2 Error  of Temp: 0.01941990542760171\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/direct_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.1628537])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
