{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ladwi\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:2')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix03</th>\n",
       "      <th>temp_conv04</th>\n",
       "      <th>temp_initial00</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "      <th>ice</th>\n",
       "      <th>snow</th>\n",
       "      <th>snowice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.260530</td>\n",
       "      <td>565.10046</td>\n",
       "      <td>-4.184752</td>\n",
       "      <td>-4.714701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.115875</td>\n",
       "      <td>-0.115875</td>\n",
       "      <td>-0.019025</td>\n",
       "      <td>5.558093</td>\n",
       "      <td>5.560076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.260530</td>\n",
       "      <td>565.10046</td>\n",
       "      <td>-4.184752</td>\n",
       "      <td>-4.714701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "      <td>0.470220</td>\n",
       "      <td>0.470220</td>\n",
       "      <td>-0.019025</td>\n",
       "      <td>4.870203</td>\n",
       "      <td>4.876163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.260530</td>\n",
       "      <td>565.10046</td>\n",
       "      <td>-4.184752</td>\n",
       "      <td>-4.714701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "      <td>1.092054</td>\n",
       "      <td>1.073671</td>\n",
       "      <td>0.046866</td>\n",
       "      <td>5.106928</td>\n",
       "      <td>5.112209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.260530</td>\n",
       "      <td>565.10046</td>\n",
       "      <td>-4.184752</td>\n",
       "      <td>-4.714701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "      <td>1.054755</td>\n",
       "      <td>1.073671</td>\n",
       "      <td>0.799295</td>\n",
       "      <td>5.106928</td>\n",
       "      <td>5.112209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-1.260530</td>\n",
       "      <td>565.10046</td>\n",
       "      <td>-4.184752</td>\n",
       "      <td>-4.714701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "      <td>1.312011</td>\n",
       "      <td>1.312011</td>\n",
       "      <td>1.381341</td>\n",
       "      <td>5.106928</td>\n",
       "      <td>5.112209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752345</th>\n",
       "      <td>46</td>\n",
       "      <td>-3.080809</td>\n",
       "      <td>529.16738</td>\n",
       "      <td>-15.814628</td>\n",
       "      <td>-20.288304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.155746</td>\n",
       "      <td>4.155746</td>\n",
       "      <td>4.155679</td>\n",
       "      <td>4.045759</td>\n",
       "      <td>4.047768</td>\n",
       "      <td>0.283046</td>\n",
       "      <td>0.025199</td>\n",
       "      <td>0.044785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752346</th>\n",
       "      <td>47</td>\n",
       "      <td>-3.080809</td>\n",
       "      <td>529.16738</td>\n",
       "      <td>-15.814628</td>\n",
       "      <td>-20.288304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.250744</td>\n",
       "      <td>4.250744</td>\n",
       "      <td>4.250654</td>\n",
       "      <td>4.435799</td>\n",
       "      <td>4.438573</td>\n",
       "      <td>0.283046</td>\n",
       "      <td>0.025199</td>\n",
       "      <td>0.044785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752347</th>\n",
       "      <td>48</td>\n",
       "      <td>-3.080809</td>\n",
       "      <td>529.16738</td>\n",
       "      <td>-15.814628</td>\n",
       "      <td>-20.288304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.347902</td>\n",
       "      <td>4.347902</td>\n",
       "      <td>4.347777</td>\n",
       "      <td>5.532094</td>\n",
       "      <td>5.534868</td>\n",
       "      <td>0.283046</td>\n",
       "      <td>0.025199</td>\n",
       "      <td>0.044785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752348</th>\n",
       "      <td>49</td>\n",
       "      <td>-3.080809</td>\n",
       "      <td>529.16738</td>\n",
       "      <td>-15.814628</td>\n",
       "      <td>-20.288304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.438525</td>\n",
       "      <td>4.438525</td>\n",
       "      <td>4.438403</td>\n",
       "      <td>7.391329</td>\n",
       "      <td>7.391820</td>\n",
       "      <td>0.283046</td>\n",
       "      <td>0.025199</td>\n",
       "      <td>0.044785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752349</th>\n",
       "      <td>50</td>\n",
       "      <td>-3.080809</td>\n",
       "      <td>529.16738</td>\n",
       "      <td>-15.814628</td>\n",
       "      <td>-20.288304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.538099</td>\n",
       "      <td>4.538099</td>\n",
       "      <td>4.537926</td>\n",
       "      <td>11.007965</td>\n",
       "      <td>11.008260</td>\n",
       "      <td>0.283046</td>\n",
       "      <td>0.025199</td>\n",
       "      <td>0.044785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1752350 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0            1     -1.260530      565.10046    -4.184752      -4.714701   \n",
       "1            2     -1.260530      565.10046    -4.184752      -4.714701   \n",
       "2            3     -1.260530      565.10046    -4.184752      -4.714701   \n",
       "3            4     -1.260530      565.10046    -4.184752      -4.714701   \n",
       "4            5     -1.260530      565.10046    -4.184752      -4.714701   \n",
       "...        ...           ...            ...          ...            ...   \n",
       "1752345     46     -3.080809      529.16738   -15.814628     -20.288304   \n",
       "1752346     47     -3.080809      529.16738   -15.814628     -20.288304   \n",
       "1752347     48     -3.080809      529.16738   -15.814628     -20.288304   \n",
       "1752348     49     -3.080809      529.16738   -15.814628     -20.288304   \n",
       "1752349     50     -3.080809      529.16738   -15.814628     -20.288304   \n",
       "\n",
       "         Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  \\\n",
       "0                   0.0               0.4              -999.0   \n",
       "1                   0.0               0.4              -999.0   \n",
       "2                   0.0               0.4              -999.0   \n",
       "3                   0.0               0.4              -999.0   \n",
       "4                   0.0               0.4              -999.0   \n",
       "...                 ...               ...                 ...   \n",
       "1752345             0.0               0.4              -999.0   \n",
       "1752346             0.0               0.4              -999.0   \n",
       "1752347             0.0               0.4              -999.0   \n",
       "1752348             0.0               0.4              -999.0   \n",
       "1752349             0.0               0.4              -999.0   \n",
       "\n",
       "         ShearStress_Nm-2     Area_m2  ...  day_of_year  time_of_day  \\\n",
       "0                  -999.0  39850000.0  ...          364            1   \n",
       "1                  -999.0  39850000.0  ...          364            1   \n",
       "2                  -999.0  39850000.0  ...          364            1   \n",
       "3                  -999.0  39850000.0  ...          364            1   \n",
       "4                  -999.0  39850000.0  ...          364            1   \n",
       "...                   ...         ...  ...          ...          ...   \n",
       "1752345            -999.0  39850000.0  ...          362           23   \n",
       "1752346            -999.0  39850000.0  ...          362           23   \n",
       "1752347            -999.0  39850000.0  ...          362           23   \n",
       "1752348            -999.0  39850000.0  ...          362           23   \n",
       "1752349            -999.0  39850000.0  ...          362           23   \n",
       "\n",
       "         temp_mix03  temp_conv04  temp_initial00   obs_temp  input_obs  \\\n",
       "0         -0.115875    -0.115875       -0.019025   5.558093   5.560076   \n",
       "1          0.470220     0.470220       -0.019025   4.870203   4.876163   \n",
       "2          1.092054     1.073671        0.046866   5.106928   5.112209   \n",
       "3          1.054755     1.073671        0.799295   5.106928   5.112209   \n",
       "4          1.312011     1.312011        1.381341   5.106928   5.112209   \n",
       "...             ...          ...             ...        ...        ...   \n",
       "1752345    4.155746     4.155746        4.155679   4.045759   4.047768   \n",
       "1752346    4.250744     4.250744        4.250654   4.435799   4.438573   \n",
       "1752347    4.347902     4.347902        4.347777   5.532094   5.534868   \n",
       "1752348    4.438525     4.438525        4.438403   7.391329   7.391820   \n",
       "1752349    4.538099     4.538099        4.537926  11.007965  11.008260   \n",
       "\n",
       "              ice      snow   snowice  \n",
       "0        0.000000  0.000000  0.000000  \n",
       "1        0.000000  0.000000  0.000000  \n",
       "2        0.000000  0.000000  0.000000  \n",
       "3        0.000000  0.000000  0.000000  \n",
       "4        0.000000  0.000000  0.000000  \n",
       "...           ...       ...       ...  \n",
       "1752345  0.283046  0.025199  0.044785  \n",
       "1752346  0.283046  0.025199  0.044785  \n",
       "1752347  0.283046  0.025199  0.044785  \n",
       "1752348  0.283046  0.025199  0.044785  \n",
       "1752349  0.283046  0.025199  0.044785  \n",
       "\n",
       "[1752350 rows x 45 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 70094\n",
      "Number of training points: 1051400\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'AirTemp_degC', 'Longwave_Wm-2', 'Latent_Wm-2', 'Sensible_Wm-2', 'Shortwave_Wm-2',\n",
    "                'lightExtinct_m-1','Area_m2', 'Uw',\n",
    "                 'day_of_year', 'time_of_day',  \n",
    "                 'buoyancy', 'diffusivity', 'temp_initial00', \n",
    "                'temp_heat01', 'temp_diff02', 'temp_total05',\n",
    "                'ice', 'snow', 'snowice']\n",
    "output_columns = ['temp_conv04']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1051400, 20), X_test: (700950, 20)\n",
      "y_train: (1051400, 1), y_test: (700950, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1024\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32,32,32,32,32,32,32,32,32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=20, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_2): GELU()\n",
      "    (layer_3): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_3): GELU()\n",
      "    (layer_4): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_4): GELU()\n",
      "    (layer_5): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_5): GELU()\n",
      "    (layer_6): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_6): GELU()\n",
      "    (layer_7): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_7): GELU()\n",
      "    (layer_8): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_8): GELU()\n",
      "    (layer_9): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_9): GELU()\n",
      "    (layer_10): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:18<5:05:55, 18.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 0.027292981112865888, Test_loss: 0.00023171531852678035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1000 [02:08<3:57:02, 14.35s/it]"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_[:,0], pred_[:,0])\n",
    "    \n",
    "    l2_error_temp = l2_error(y_[:,0], pred_[:,0])\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/direct_model_train_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
