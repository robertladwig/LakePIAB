{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:2')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>diffusivity</th>\n",
       "      <th>temp_heat01</th>\n",
       "      <th>temp_diff02</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix03</th>\n",
       "      <th>temp_conv04</th>\n",
       "      <th>temp_initial00</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.416676</td>\n",
       "      <td>15.416676</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.426904</td>\n",
       "      <td>15.426904</td>\n",
       "      <td>15.489510</td>\n",
       "      <td>22.279</td>\n",
       "      <td>22.279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>15.448083</td>\n",
       "      <td>15.437735</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.401481</td>\n",
       "      <td>15.401481</td>\n",
       "      <td>15.448078</td>\n",
       "      <td>22.295</td>\n",
       "      <td>22.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>15.376622</td>\n",
       "      <td>15.374550</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.346109</td>\n",
       "      <td>15.346109</td>\n",
       "      <td>15.376617</td>\n",
       "      <td>22.091</td>\n",
       "      <td>22.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>15.287991</td>\n",
       "      <td>15.287547</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.272596</td>\n",
       "      <td>15.272596</td>\n",
       "      <td>15.287987</td>\n",
       "      <td>22.296</td>\n",
       "      <td>22.296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>15.195124</td>\n",
       "      <td>15.195829</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.193004</td>\n",
       "      <td>15.193004</td>\n",
       "      <td>15.195121</td>\n",
       "      <td>22.231</td>\n",
       "      <td>22.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495570</th>\n",
       "      <td>21</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>8.373718</td>\n",
       "      <td>8.375543</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>8.375543</td>\n",
       "      <td>8.375543</td>\n",
       "      <td>8.373683</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495571</th>\n",
       "      <td>22</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>7.324853</td>\n",
       "      <td>7.326184</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>7.326184</td>\n",
       "      <td>7.326184</td>\n",
       "      <td>7.324806</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495572</th>\n",
       "      <td>23</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>6.297841</td>\n",
       "      <td>6.298671</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>6.298671</td>\n",
       "      <td>6.298671</td>\n",
       "      <td>6.297760</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495573</th>\n",
       "      <td>24</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>5.282023</td>\n",
       "      <td>5.282477</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.282477</td>\n",
       "      <td>5.282477</td>\n",
       "      <td>5.282023</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495574</th>\n",
       "      <td>25</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495575 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0           1     13.965021     717.887954   -32.080993      -6.880394   \n",
       "1           2     13.965021     717.887954   -32.080993      -6.880394   \n",
       "2           3     13.965021     717.887954   -32.080993      -6.880394   \n",
       "3           4     13.965021     717.887954   -32.080993      -6.880394   \n",
       "4           5     13.965021     717.887954   -32.080993      -6.880394   \n",
       "...       ...           ...            ...          ...            ...   \n",
       "495570     21     17.945001     796.182785   -59.448422     -13.843945   \n",
       "495571     22     17.945001     796.182785   -59.448422     -13.843945   \n",
       "495572     23     17.945001     796.182785   -59.448422     -13.843945   \n",
       "495573     24     17.945001     796.182785   -59.448422     -13.843945   \n",
       "495574     25     17.945001     796.182785   -59.448422     -13.843945   \n",
       "\n",
       "        Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  \\\n",
       "0                  0.0               0.8            1.803546   \n",
       "1                  0.0               0.8            1.803546   \n",
       "2                  0.0               0.8            1.803546   \n",
       "3                  0.0               0.8            1.803546   \n",
       "4                  0.0               0.8            1.803546   \n",
       "...                ...               ...                 ...   \n",
       "495570             0.0               0.8            0.322170   \n",
       "495571             0.0               0.8            0.322170   \n",
       "495572             0.0               0.8            0.322170   \n",
       "495573             0.0               0.8            0.322170   \n",
       "495574             0.0               0.8            0.322170   \n",
       "\n",
       "        ShearStress_Nm-2     Area_m2  ...  diffusivity  temp_heat01  \\\n",
       "0               0.008386  36000000.0  ...     0.000037    15.416676   \n",
       "1               0.008386  36000000.0  ...     0.000031    15.448083   \n",
       "2               0.008386  36000000.0  ...     0.000028    15.376622   \n",
       "3               0.008386  36000000.0  ...     0.000028    15.287991   \n",
       "4               0.008386  36000000.0  ...     0.000029    15.195124   \n",
       "...                  ...         ...  ...          ...          ...   \n",
       "495570          0.000534  36000000.0  ...     0.000015     8.373718   \n",
       "495571          0.000534  36000000.0  ...     0.000017     7.324853   \n",
       "495572          0.000534  36000000.0  ...     0.000020     6.297841   \n",
       "495573          0.000534  36000000.0  ...     0.000029     5.282023   \n",
       "495574          0.000534  36000000.0  ...     0.000029     4.270583   \n",
       "\n",
       "        temp_diff02  day_of_year  time_of_day  temp_mix03  temp_conv04  \\\n",
       "0         15.416676          155            1   15.426904    15.426904   \n",
       "1         15.437735          155            1   15.401481    15.401481   \n",
       "2         15.374550          155            1   15.346109    15.346109   \n",
       "3         15.287547          155            1   15.272596    15.272596   \n",
       "4         15.195829          155            1   15.193004    15.193004   \n",
       "...             ...          ...          ...         ...          ...   \n",
       "495570     8.375543          213           23    8.375543     8.375543   \n",
       "495571     7.326184          213           23    7.326184     7.326184   \n",
       "495572     6.298671          213           23    6.298671     6.298671   \n",
       "495573     5.282477          213           23    5.282477     5.282477   \n",
       "495574     4.270583          213           23    4.270583     4.270583   \n",
       "\n",
       "        temp_initial00  obs_temp  input_obs  \n",
       "0            15.489510    22.279     22.279  \n",
       "1            15.448078    22.295     22.295  \n",
       "2            15.376617    22.091     22.091  \n",
       "3            15.287987    22.296     22.296  \n",
       "4            15.195121    22.231     22.231  \n",
       "...                ...       ...        ...  \n",
       "495570        8.373683    11.099     11.099  \n",
       "495571        7.324806    11.099     11.099  \n",
       "495572        6.297760    11.099     11.099  \n",
       "495573        5.282023    11.099     11.099  \n",
       "495574        4.270583    11.099     11.099  \n",
       "\n",
       "[495575 rows x 23 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 19823\n",
      "Number of training points: 297325\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'AirTemp_degC', 'Longwave_Wm-2', 'Latent_Wm-2', 'Sensible_Wm-2', 'Shortwave_Wm-2',\n",
    "                'lightExtinct_m-1','Area_m2', 'Uw',\n",
    "                 'day_of_year', 'time_of_day',  \n",
    "                 'buoyancy', 'diffusivity', 'temp_initial00', \n",
    "                'temp_heat01', 'temp_diff02', 'temp_conv04', 'temp_total05',\n",
    "                'ice', 'snow', 'snowice']\n",
    "output_columns = ['obs_temp']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (297325, 20), X_test: (198250, 20)\n",
      "y_train: (297325, 1), y_test: (198250, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1024\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32,32,32,32,32,32,32,32,32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=20, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_2): GELU()\n",
      "    (layer_3): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_3): GELU()\n",
      "    (layer_4): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_4): GELU()\n",
      "    (layer_5): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_5): GELU()\n",
      "    (layer_6): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_6): GELU()\n",
      "    (layer_7): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_7): GELU()\n",
      "    (layer_8): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_8): GELU()\n",
      "    (layer_9): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_9): GELU()\n",
      "    (layer_10): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:05<1:23:29,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 0.16391152496804895, Test_loss: 0.11637790156912405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [04:21<2:03:39,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 0.02421934767610224, Test_loss: 0.17291967967313895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [07:50<1:16:46,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Train_loss: 0.01624825819878746, Test_loss: 0.16986536067555247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 151/1000 [11:21<1:02:04,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 150, Train_loss: 0.013384102814898048, Test_loss: 0.1840760110176562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [14:51<1:04:36,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 200, Train_loss: 0.011971767991781235, Test_loss: 0.18375738279068285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 251/1000 [18:16<58:34,  4.69s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 250, Train_loss: 0.010897142959829048, Test_loss: 0.17735963529839957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [21:47<55:33,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 300, Train_loss: 0.010326000032914463, Test_loss: 0.1813425307747783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 351/1000 [25:14<51:24,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 350, Train_loss: 0.009895391218185015, Test_loss: 0.18556394924400085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [28:44<45:47,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400, Train_loss: 0.009725987474366869, Test_loss: 0.1835844057237672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 451/1000 [32:13<43:43,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 450, Train_loss: 0.0095837381540372, Test_loss: 0.18648536103902405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [35:39<43:59,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500, Train_loss: 0.007520267299834089, Test_loss: 0.1884390632765963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 551/1000 [39:03<33:16,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 550, Train_loss: 0.007157829945388529, Test_loss: 0.19189889897045093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 601/1000 [42:30<30:34,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600, Train_loss: 0.0070842701791308796, Test_loss: 0.1920365090337918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 651/1000 [45:55<20:50,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 650, Train_loss: 0.007019258944375306, Test_loss: 0.19256902653147878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 701/1000 [48:25<17:17,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 700, Train_loss: 0.006967574423595085, Test_loss: 0.193410517158198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 751/1000 [51:02<14:20,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 750, Train_loss: 0.006930142858696147, Test_loss: 0.19291498315203742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 801/1000 [53:35<12:27,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800, Train_loss: 0.006884391157154979, Test_loss: 0.19406409707573272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 851/1000 [56:40<08:33,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 850, Train_loss: 0.006855263795601236, Test_loss: 0.19424877734374754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 901/1000 [59:18<06:15,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900, Train_loss: 0.006795624815106802, Test_loss: 0.19454573534582695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 951/1000 [1:01:52<02:45,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 950, Train_loss: 0.006769143747441035, Test_loss: 0.19361198676231595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:04:19<00:00,  3.86s/it]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_[:,0], pred_[:,0])\n",
    "    \n",
    "    l2_error_temp = l2_error(y_[:,0], pred_[:,0])\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 2.3307337420875234\n",
      "L2 Error  of Temp: 0.1446051765979888\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 0.43172149491519746\n",
      "L2 Error  of Temp: 0.026373330806278163\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/direct_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.49091384])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
