{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ladwi\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:2')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix03</th>\n",
       "      <th>temp_conv04</th>\n",
       "      <th>temp_initial00</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "      <th>ice</th>\n",
       "      <th>snow</th>\n",
       "      <th>snowice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.989824</td>\n",
       "      <td>551.514698</td>\n",
       "      <td>-19.194445</td>\n",
       "      <td>-28.116538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>1.189659</td>\n",
       "      <td>1.189659</td>\n",
       "      <td>1.400563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-2.989824</td>\n",
       "      <td>551.514698</td>\n",
       "      <td>-19.194445</td>\n",
       "      <td>-28.116538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>1.337920</td>\n",
       "      <td>1.337920</td>\n",
       "      <td>1.400563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-2.989824</td>\n",
       "      <td>551.514698</td>\n",
       "      <td>-19.194445</td>\n",
       "      <td>-28.116538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>1.719089</td>\n",
       "      <td>1.719089</td>\n",
       "      <td>1.378568</td>\n",
       "      <td>6.204667</td>\n",
       "      <td>6.207320</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-2.989824</td>\n",
       "      <td>551.514698</td>\n",
       "      <td>-19.194445</td>\n",
       "      <td>-28.116538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>2.013660</td>\n",
       "      <td>2.013660</td>\n",
       "      <td>1.443240</td>\n",
       "      <td>6.260337</td>\n",
       "      <td>6.263034</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-2.989824</td>\n",
       "      <td>551.514698</td>\n",
       "      <td>-19.194445</td>\n",
       "      <td>-28.116538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>2.087996</td>\n",
       "      <td>2.087996</td>\n",
       "      <td>1.729038</td>\n",
       "      <td>6.319616</td>\n",
       "      <td>6.322359</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2628545</th>\n",
       "      <td>46</td>\n",
       "      <td>-12.920028</td>\n",
       "      <td>494.226632</td>\n",
       "      <td>-46.982710</td>\n",
       "      <td>-95.220702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.066941</td>\n",
       "      <td>4.066941</td>\n",
       "      <td>4.066863</td>\n",
       "      <td>3.029762</td>\n",
       "      <td>3.030952</td>\n",
       "      <td>0.47505</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2628546</th>\n",
       "      <td>47</td>\n",
       "      <td>-12.920028</td>\n",
       "      <td>494.226632</td>\n",
       "      <td>-46.982710</td>\n",
       "      <td>-95.220702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.172542</td>\n",
       "      <td>4.172542</td>\n",
       "      <td>4.172443</td>\n",
       "      <td>3.185105</td>\n",
       "      <td>3.189226</td>\n",
       "      <td>0.47505</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2628547</th>\n",
       "      <td>48</td>\n",
       "      <td>-12.920028</td>\n",
       "      <td>494.226632</td>\n",
       "      <td>-46.982710</td>\n",
       "      <td>-95.220702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.282669</td>\n",
       "      <td>4.282669</td>\n",
       "      <td>4.282541</td>\n",
       "      <td>4.005785</td>\n",
       "      <td>4.009906</td>\n",
       "      <td>0.47505</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2628548</th>\n",
       "      <td>49</td>\n",
       "      <td>-12.920028</td>\n",
       "      <td>494.226632</td>\n",
       "      <td>-46.982710</td>\n",
       "      <td>-95.220702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.386953</td>\n",
       "      <td>4.386953</td>\n",
       "      <td>4.386816</td>\n",
       "      <td>4.826464</td>\n",
       "      <td>4.830586</td>\n",
       "      <td>0.47505</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2628549</th>\n",
       "      <td>50</td>\n",
       "      <td>-12.920028</td>\n",
       "      <td>494.226632</td>\n",
       "      <td>-46.982710</td>\n",
       "      <td>-95.220702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.503658</td>\n",
       "      <td>4.503658</td>\n",
       "      <td>4.503485</td>\n",
       "      <td>7.996234</td>\n",
       "      <td>7.998070</td>\n",
       "      <td>0.47505</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2628550 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0            1     -2.989824     551.514698   -19.194445     -28.116538   \n",
       "1            2     -2.989824     551.514698   -19.194445     -28.116538   \n",
       "2            3     -2.989824     551.514698   -19.194445     -28.116538   \n",
       "3            4     -2.989824     551.514698   -19.194445     -28.116538   \n",
       "4            5     -2.989824     551.514698   -19.194445     -28.116538   \n",
       "...        ...           ...            ...          ...            ...   \n",
       "2628545     46    -12.920028     494.226632   -46.982710     -95.220702   \n",
       "2628546     47    -12.920028     494.226632   -46.982710     -95.220702   \n",
       "2628547     48    -12.920028     494.226632   -46.982710     -95.220702   \n",
       "2628548     49    -12.920028     494.226632   -46.982710     -95.220702   \n",
       "2628549     50    -12.920028     494.226632   -46.982710     -95.220702   \n",
       "\n",
       "         Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  \\\n",
       "0                   0.0               0.4              -999.0   \n",
       "1                   0.0               0.4              -999.0   \n",
       "2                   0.0               0.4              -999.0   \n",
       "3                   0.0               0.4              -999.0   \n",
       "4                   0.0               0.4              -999.0   \n",
       "...                 ...               ...                 ...   \n",
       "2628545             0.0               0.4              -999.0   \n",
       "2628546             0.0               0.4              -999.0   \n",
       "2628547             0.0               0.4              -999.0   \n",
       "2628548             0.0               0.4              -999.0   \n",
       "2628549             0.0               0.4              -999.0   \n",
       "\n",
       "         ShearStress_Nm-2     Area_m2  ...  day_of_year  time_of_day  \\\n",
       "0                  -999.0  39850000.0  ...          365            1   \n",
       "1                  -999.0  39850000.0  ...          365            1   \n",
       "2                  -999.0  39850000.0  ...          365            1   \n",
       "3                  -999.0  39850000.0  ...          365            1   \n",
       "4                  -999.0  39850000.0  ...          365            1   \n",
       "...                   ...         ...  ...          ...          ...   \n",
       "2628545            -999.0  39850000.0  ...          362           23   \n",
       "2628546            -999.0  39850000.0  ...          362           23   \n",
       "2628547            -999.0  39850000.0  ...          362           23   \n",
       "2628548            -999.0  39850000.0  ...          362           23   \n",
       "2628549            -999.0  39850000.0  ...          362           23   \n",
       "\n",
       "         temp_mix03  temp_conv04  temp_initial00  obs_temp  input_obs  \\\n",
       "0          1.189659     1.189659        1.400563  0.000000   0.000000   \n",
       "1          1.337920     1.337920        1.400563  0.000000   0.000000   \n",
       "2          1.719089     1.719089        1.378568  6.204667   6.207320   \n",
       "3          2.013660     2.013660        1.443240  6.260337   6.263034   \n",
       "4          2.087996     2.087996        1.729038  6.319616   6.322359   \n",
       "...             ...          ...             ...       ...        ...   \n",
       "2628545    4.066941     4.066941        4.066863  3.029762   3.030952   \n",
       "2628546    4.172542     4.172542        4.172443  3.185105   3.189226   \n",
       "2628547    4.282669     4.282669        4.282541  4.005785   4.009906   \n",
       "2628548    4.386953     4.386953        4.386816  4.826464   4.830586   \n",
       "2628549    4.503658     4.503658        4.503485  7.996234   7.998070   \n",
       "\n",
       "             ice     snow  snowice  \n",
       "0        0.00000  0.00000      0.0  \n",
       "1        0.00000  0.00000      0.0  \n",
       "2        0.00000  0.00000      0.0  \n",
       "3        0.00000  0.00000      0.0  \n",
       "4        0.00000  0.00000      0.0  \n",
       "...          ...      ...      ...  \n",
       "2628545  0.47505  0.00527      0.0  \n",
       "2628546  0.47505  0.00527      0.0  \n",
       "2628547  0.47505  0.00527      0.0  \n",
       "2628548  0.47505  0.00527      0.0  \n",
       "2628549  0.47505  0.00527      0.0  \n",
       "\n",
       "[2628550 rows x 45 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 105142\n",
      "Number of training points: 1577125\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_columns = ['depth', 'AirTemp_degC', 'Longwave_Wm-2', 'Latent_Wm-2', 'Sensible_Wm-2', 'Shortwave_Wm-2',\n",
    "#                'lightExtinct_m-1','Area_m2', 'Uw',\n",
    "#                 'day_of_year', 'time_of_day',  \n",
    "#                 'buoyancy', 'diffusivity', 'temp_initial00', \n",
    "#                'temp_heat01', 'temp_diff02', 'temp_conv04', 'temp_total05',\n",
    "#                'ice', 'snow', 'snowice']\n",
    "#output_columns = ['obs_temp']\n",
    "input_columns = ['depth', 'AirTemp_degC',   'Shortwave_Wm-2',\n",
    "                'lightExtinct_m-1','Area_m2', 'Uw',\n",
    "                 'day_of_year', 'time_of_day'] #,  \n",
    "               #  'buoyancy', 'diffusivity', 'temp_initial00', \n",
    "               # 'temp_heat01', 'temp_diff02', 'temp_total05',\n",
    "               # 'ice', 'snow', 'snowice'\n",
    "output_columns = ['obs_temp']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1577125, 8), X_test: (1051425, 8)\n",
      "y_train: (1577125, 1), y_test: (1051425, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1024\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32,32,32,32,32,32,32,32,32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=8, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_2): GELU()\n",
      "    (layer_3): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_3): GELU()\n",
      "    (layer_4): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_4): GELU()\n",
      "    (layer_5): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_5): GELU()\n",
      "    (layer_6): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_6): GELU()\n",
      "    (layer_7): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_7): GELU()\n",
      "    (layer_8): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_8): GELU()\n",
      "    (layer_9): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_9): GELU()\n",
      "    (layer_10): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:25<6:57:01, 25.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 0.10703511826215356, Test_loss: 0.06277169329055314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [16:27<5:32:26, 21.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 0.03174666273253526, Test_loss: 0.08792860425728488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [31:59<5:15:24, 21.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Train_loss: 0.026024431466456745, Test_loss: 0.09533640039876601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 151/1000 [47:32<5:06:29, 21.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 150, Train_loss: 0.023895719224595543, Test_loss: 0.10046497868846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [1:03:04<4:41:04, 21.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 200, Train_loss: 0.02305998002879423, Test_loss: 0.10079855067785122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 251/1000 [1:20:34<5:00:34, 24.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 250, Train_loss: 0.022564018380904955, Test_loss: 0.10306617531548196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [1:34:59<3:00:09, 15.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 300, Train_loss: 0.022012337624040382, Test_loss: 0.09916203609008448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 351/1000 [1:46:20<2:46:49, 15.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 350, Train_loss: 0.021423060165949064, Test_loss: 0.10024874250947732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [1:58:19<2:40:46, 16.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400, Train_loss: 0.021026961678260722, Test_loss: 0.10149953379173343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 451/1000 [2:09:46<2:20:56, 15.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 450, Train_loss: 0.02089754035327726, Test_loss: 0.10314259429674454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [2:21:17<2:21:40, 17.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500, Train_loss: 0.018029099547876546, Test_loss: 0.10285431433114484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 551/1000 [2:32:38<1:56:13, 15.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 550, Train_loss: 0.017576816555240724, Test_loss: 0.10608432860070152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 601/1000 [2:43:57<1:41:38, 15.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600, Train_loss: 0.017470608601355072, Test_loss: 0.10640753829283159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 651/1000 [2:55:14<1:29:37, 15.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 650, Train_loss: 0.017379174816998123, Test_loss: 0.10735756119131903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 701/1000 [3:06:34<1:16:40, 15.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 700, Train_loss: 0.01730821914680781, Test_loss: 0.10687355991061179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 751/1000 [3:17:55<1:04:29, 15.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 750, Train_loss: 0.01724835734398604, Test_loss: 0.1065552432526233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 801/1000 [3:29:17<51:05, 15.41s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800, Train_loss: 0.017197533543260937, Test_loss: 0.10786304896685613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 851/1000 [3:40:34<38:05, 15.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 850, Train_loss: 0.017142189177699593, Test_loss: 0.10761369546596958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 901/1000 [3:51:51<25:15, 15.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900, Train_loss: 0.01709645744630708, Test_loss: 0.10703754856839719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 951/1000 [4:03:10<12:34, 15.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 950, Train_loss: 0.017055194031406075, Test_loss: 0.10739359980156171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [4:14:10<00:00, 15.25s/it]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_[:,0], pred_[:,0])\n",
    "    \n",
    "    l2_error_temp = l2_error(y_[:,0], pred_[:,0])\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 2.10111541852218\n",
      "L2 Error  of Temp: 0.16971465271009895\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 0.8348311176550253\n",
      "L2 Error  of Temp: 0.07281344107385833\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/direct_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.50302379])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
