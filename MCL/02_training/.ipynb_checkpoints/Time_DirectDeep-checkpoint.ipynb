{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:2')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>diffusivity</th>\n",
       "      <th>temp_heat01</th>\n",
       "      <th>temp_diff02</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix03</th>\n",
       "      <th>temp_conv04</th>\n",
       "      <th>temp_initial00</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.416676</td>\n",
       "      <td>15.416676</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.426904</td>\n",
       "      <td>15.426904</td>\n",
       "      <td>15.489510</td>\n",
       "      <td>22.279</td>\n",
       "      <td>22.279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>15.448083</td>\n",
       "      <td>15.437735</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.401481</td>\n",
       "      <td>15.401481</td>\n",
       "      <td>15.448078</td>\n",
       "      <td>22.295</td>\n",
       "      <td>22.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>15.376622</td>\n",
       "      <td>15.374550</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.346109</td>\n",
       "      <td>15.346109</td>\n",
       "      <td>15.376617</td>\n",
       "      <td>22.091</td>\n",
       "      <td>22.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>15.287991</td>\n",
       "      <td>15.287547</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.272596</td>\n",
       "      <td>15.272596</td>\n",
       "      <td>15.287987</td>\n",
       "      <td>22.296</td>\n",
       "      <td>22.296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>15.195124</td>\n",
       "      <td>15.195829</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.193004</td>\n",
       "      <td>15.193004</td>\n",
       "      <td>15.195121</td>\n",
       "      <td>22.231</td>\n",
       "      <td>22.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495570</th>\n",
       "      <td>21</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>8.373718</td>\n",
       "      <td>8.375543</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>8.375543</td>\n",
       "      <td>8.375543</td>\n",
       "      <td>8.373683</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495571</th>\n",
       "      <td>22</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>7.324853</td>\n",
       "      <td>7.326184</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>7.326184</td>\n",
       "      <td>7.326184</td>\n",
       "      <td>7.324806</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495572</th>\n",
       "      <td>23</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>6.297841</td>\n",
       "      <td>6.298671</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>6.298671</td>\n",
       "      <td>6.298671</td>\n",
       "      <td>6.297760</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495573</th>\n",
       "      <td>24</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>5.282023</td>\n",
       "      <td>5.282477</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.282477</td>\n",
       "      <td>5.282477</td>\n",
       "      <td>5.282023</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495574</th>\n",
       "      <td>25</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495575 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0           1     13.965021     717.887954   -32.080993      -6.880394   \n",
       "1           2     13.965021     717.887954   -32.080993      -6.880394   \n",
       "2           3     13.965021     717.887954   -32.080993      -6.880394   \n",
       "3           4     13.965021     717.887954   -32.080993      -6.880394   \n",
       "4           5     13.965021     717.887954   -32.080993      -6.880394   \n",
       "...       ...           ...            ...          ...            ...   \n",
       "495570     21     17.945001     796.182785   -59.448422     -13.843945   \n",
       "495571     22     17.945001     796.182785   -59.448422     -13.843945   \n",
       "495572     23     17.945001     796.182785   -59.448422     -13.843945   \n",
       "495573     24     17.945001     796.182785   -59.448422     -13.843945   \n",
       "495574     25     17.945001     796.182785   -59.448422     -13.843945   \n",
       "\n",
       "        Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  \\\n",
       "0                  0.0               0.8            1.803546   \n",
       "1                  0.0               0.8            1.803546   \n",
       "2                  0.0               0.8            1.803546   \n",
       "3                  0.0               0.8            1.803546   \n",
       "4                  0.0               0.8            1.803546   \n",
       "...                ...               ...                 ...   \n",
       "495570             0.0               0.8            0.322170   \n",
       "495571             0.0               0.8            0.322170   \n",
       "495572             0.0               0.8            0.322170   \n",
       "495573             0.0               0.8            0.322170   \n",
       "495574             0.0               0.8            0.322170   \n",
       "\n",
       "        ShearStress_Nm-2     Area_m2  ...  diffusivity  temp_heat01  \\\n",
       "0               0.008386  36000000.0  ...     0.000037    15.416676   \n",
       "1               0.008386  36000000.0  ...     0.000031    15.448083   \n",
       "2               0.008386  36000000.0  ...     0.000028    15.376622   \n",
       "3               0.008386  36000000.0  ...     0.000028    15.287991   \n",
       "4               0.008386  36000000.0  ...     0.000029    15.195124   \n",
       "...                  ...         ...  ...          ...          ...   \n",
       "495570          0.000534  36000000.0  ...     0.000015     8.373718   \n",
       "495571          0.000534  36000000.0  ...     0.000017     7.324853   \n",
       "495572          0.000534  36000000.0  ...     0.000020     6.297841   \n",
       "495573          0.000534  36000000.0  ...     0.000029     5.282023   \n",
       "495574          0.000534  36000000.0  ...     0.000029     4.270583   \n",
       "\n",
       "        temp_diff02  day_of_year  time_of_day  temp_mix03  temp_conv04  \\\n",
       "0         15.416676          155            1   15.426904    15.426904   \n",
       "1         15.437735          155            1   15.401481    15.401481   \n",
       "2         15.374550          155            1   15.346109    15.346109   \n",
       "3         15.287547          155            1   15.272596    15.272596   \n",
       "4         15.195829          155            1   15.193004    15.193004   \n",
       "...             ...          ...          ...         ...          ...   \n",
       "495570     8.375543          213           23    8.375543     8.375543   \n",
       "495571     7.326184          213           23    7.326184     7.326184   \n",
       "495572     6.298671          213           23    6.298671     6.298671   \n",
       "495573     5.282477          213           23    5.282477     5.282477   \n",
       "495574     4.270583          213           23    4.270583     4.270583   \n",
       "\n",
       "        temp_initial00  obs_temp  input_obs  \n",
       "0            15.489510    22.279     22.279  \n",
       "1            15.448078    22.295     22.295  \n",
       "2            15.376617    22.091     22.091  \n",
       "3            15.287987    22.296     22.296  \n",
       "4            15.195121    22.231     22.231  \n",
       "...                ...       ...        ...  \n",
       "495570        8.373683    11.099     11.099  \n",
       "495571        7.324806    11.099     11.099  \n",
       "495572        6.297760    11.099     11.099  \n",
       "495573        5.282023    11.099     11.099  \n",
       "495574        4.270583    11.099     11.099  \n",
       "\n",
       "[495575 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 19823\n",
      "Number of training points: 297325\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'AirTemp_degC', 'Longwave_Wm-2', 'Latent_Wm-2', 'Sensible_Wm-2', 'Shortwave_Wm-2',\n",
    "                'lightExtinct_m-1','Area_m2', \n",
    "                 'day_of_year', 'time_of_day',\n",
    "                'ShearVelocity_mS-1', 'ShearStress_Nm-2',  \n",
    "                 'buoyancy', 'diffusivity', 'temp_initial00', \n",
    "                'temp_heat01', 'temp_diff02', 'temp_mix03', 'temp_conv04', 'temp_total05']\n",
    "output_columns = ['obs_temp']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (297325, 20), X_test: (198250, 20)\n",
      "y_train: (297325, 1), y_test: (198250, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1024\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32,32,32,32,32,32,32,32,32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=20, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:04<1:15:11,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 0.1951539072742577, Test_loss: 0.14312762329258868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [03:01<1:16:24,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 0.05818767462860268, Test_loss: 0.13515042122357437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [06:12<1:00:32,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Train_loss: 0.05010227492892046, Test_loss: 0.153501972076051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 151/1000 [09:14<1:07:21,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 150, Train_loss: 0.045977709373247994, Test_loss: 0.16688453458902455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [13:45<1:42:57,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 200, Train_loss: 0.04350835810770694, Test_loss: 0.1740299158960043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 251/1000 [18:12<1:05:25,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 250, Train_loss: 0.041920889975483884, Test_loss: 0.17307249426880142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [22:12<1:04:46,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 300, Train_loss: 0.040776969692141736, Test_loss: 0.17301373663790448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 351/1000 [25:56<50:57,  4.71s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 350, Train_loss: 0.03993635816672414, Test_loss: 0.1717132162686783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [29:32<46:36,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400, Train_loss: 0.03932206371088618, Test_loss: 0.172557867631393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 451/1000 [33:05<45:43,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 450, Train_loss: 0.038708798132862425, Test_loss: 0.16942784341877884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [36:54<46:19,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500, Train_loss: 0.03753829769201295, Test_loss: 0.1695839530817166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 551/1000 [40:36<39:47,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 550, Train_loss: 0.03740098243547264, Test_loss: 0.16977618681746967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 601/1000 [44:00<31:22,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600, Train_loss: 0.037370069458107766, Test_loss: 0.17126862621222882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 651/1000 [47:30<29:06,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 650, Train_loss: 0.03729482728642287, Test_loss: 0.16985921131581375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 701/1000 [51:27<29:39,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 700, Train_loss: 0.03720976885958636, Test_loss: 0.16938258721925242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 751/1000 [55:38<35:41,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 750, Train_loss: 0.03716851793920871, Test_loss: 0.1702196740535731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 801/1000 [59:44<18:48,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800, Train_loss: 0.03710562595617525, Test_loss: 0.17256256570252254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 851/1000 [1:03:48<13:09,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 850, Train_loss: 0.03705929469355603, Test_loss: 0.17067319832588593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 901/1000 [1:07:46<08:59,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900, Train_loss: 0.03701413590525024, Test_loss: 0.1712089802052096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 951/1000 [1:11:54<04:36,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 950, Train_loss: 0.0369747495566754, Test_loss: 0.16977519713841455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:15:36<00:00,  4.54s/it]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_[:,0], pred_[:,0])\n",
    "    \n",
    "    l2_error_temp = l2_error(y_[:,0], pred_[:,0])\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 2.1858881265483623\n",
      "L2 Error  of Temp: 0.135618553443117\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 1.0162205904145294\n",
      "L2 Error  of Temp: 0.062079655793877496\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/direct_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.49091384])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
