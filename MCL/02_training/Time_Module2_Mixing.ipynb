{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:2')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>buoyancy</th>\n",
       "      <th>diffusivity</th>\n",
       "      <th>temp_heat00</th>\n",
       "      <th>temp_diff01</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix02</th>\n",
       "      <th>temp_conv03</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>695.937161</td>\n",
       "      <td>-56.268384</td>\n",
       "      <td>-23.291619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085448</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>16.283408</td>\n",
       "      <td>16.149422</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>16.206994</td>\n",
       "      <td>16.241692</td>\n",
       "      <td>16.409</td>\n",
       "      <td>16.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>695.937161</td>\n",
       "      <td>-56.268384</td>\n",
       "      <td>-23.291619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085448</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>16.283408</td>\n",
       "      <td>16.267964</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>16.206994</td>\n",
       "      <td>16.247184</td>\n",
       "      <td>16.480</td>\n",
       "      <td>16.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>695.937161</td>\n",
       "      <td>-56.268384</td>\n",
       "      <td>-23.291619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085448</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>16.287068</td>\n",
       "      <td>16.286071</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>16.286071</td>\n",
       "      <td>16.251763</td>\n",
       "      <td>16.130</td>\n",
       "      <td>16.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>695.937161</td>\n",
       "      <td>-56.268384</td>\n",
       "      <td>-23.291619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085448</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>16.291257</td>\n",
       "      <td>16.288695</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>16.288695</td>\n",
       "      <td>16.251763</td>\n",
       "      <td>15.827</td>\n",
       "      <td>15.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>695.937161</td>\n",
       "      <td>-56.268384</td>\n",
       "      <td>-23.291619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085448</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>16.278268</td>\n",
       "      <td>16.270156</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>16.270156</td>\n",
       "      <td>16.256606</td>\n",
       "      <td>16.270</td>\n",
       "      <td>16.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141570</th>\n",
       "      <td>21</td>\n",
       "      <td>21.695001</td>\n",
       "      <td>832.055902</td>\n",
       "      <td>-93.493728</td>\n",
       "      <td>-12.091248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.162606</td>\n",
       "      <td>1.049822</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>8.537687</td>\n",
       "      <td>8.537921</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>8.537921</td>\n",
       "      <td>8.537921</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141571</th>\n",
       "      <td>22</td>\n",
       "      <td>21.695001</td>\n",
       "      <td>832.055902</td>\n",
       "      <td>-93.493728</td>\n",
       "      <td>-12.091248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.162606</td>\n",
       "      <td>1.049822</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>7.466041</td>\n",
       "      <td>7.466186</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>7.466186</td>\n",
       "      <td>7.466186</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141572</th>\n",
       "      <td>23</td>\n",
       "      <td>21.695001</td>\n",
       "      <td>832.055902</td>\n",
       "      <td>-93.493728</td>\n",
       "      <td>-12.091248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.162606</td>\n",
       "      <td>1.049822</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>6.396040</td>\n",
       "      <td>6.396125</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>6.396125</td>\n",
       "      <td>6.396125</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141573</th>\n",
       "      <td>24</td>\n",
       "      <td>21.695001</td>\n",
       "      <td>832.055902</td>\n",
       "      <td>-93.493728</td>\n",
       "      <td>-12.091248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.162606</td>\n",
       "      <td>1.049822</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>5.326140</td>\n",
       "      <td>5.326179</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.326179</td>\n",
       "      <td>5.326179</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141574</th>\n",
       "      <td>25</td>\n",
       "      <td>21.695001</td>\n",
       "      <td>832.055902</td>\n",
       "      <td>-93.493728</td>\n",
       "      <td>-12.091248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.162606</td>\n",
       "      <td>1.049822</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>4.256585</td>\n",
       "      <td>4.256585</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>4.256585</td>\n",
       "      <td>4.256585</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141575 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0           1     10.715021     695.937161   -56.268384     -23.291619   \n",
       "1           2     10.715021     695.937161   -56.268384     -23.291619   \n",
       "2           3     10.715021     695.937161   -56.268384     -23.291619   \n",
       "3           4     10.715021     695.937161   -56.268384     -23.291619   \n",
       "4           5     10.715021     695.937161   -56.268384     -23.291619   \n",
       "...       ...           ...            ...          ...            ...   \n",
       "141570     21     21.695001     832.055902   -93.493728     -12.091248   \n",
       "141571     22     21.695001     832.055902   -93.493728     -12.091248   \n",
       "141572     23     21.695001     832.055902   -93.493728     -12.091248   \n",
       "141573     24     21.695001     832.055902   -93.493728     -12.091248   \n",
       "141574     25     21.695001     832.055902   -93.493728     -12.091248   \n",
       "\n",
       "        Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  \\\n",
       "0                  0.0          0.255324            1.085448   \n",
       "1                  0.0          0.255324            1.085448   \n",
       "2                  0.0          0.255324            1.085448   \n",
       "3                  0.0          0.255324            1.085448   \n",
       "4                  0.0          0.255324            1.085448   \n",
       "...                ...               ...                 ...   \n",
       "141570             0.0          1.162606            1.049822   \n",
       "141571             0.0          1.162606            1.049822   \n",
       "141572             0.0          1.162606            1.049822   \n",
       "141573             0.0          1.162606            1.049822   \n",
       "141574             0.0          1.162606            1.049822   \n",
       "\n",
       "        ShearStress_Nm-2     Area_m2  ...  buoyancy  diffusivity  temp_heat00  \\\n",
       "0               0.002290  36000000.0  ... -0.000006     0.000037    16.283408   \n",
       "1               0.002290  36000000.0  ... -0.000006     0.000037    16.283408   \n",
       "2               0.002290  36000000.0  ... -0.000007     0.000037    16.287068   \n",
       "3               0.002290  36000000.0  ...  0.000021     0.000037    16.291257   \n",
       "4               0.002290  36000000.0  ...  0.000180     0.000025    16.278268   \n",
       "...                  ...         ...  ...       ...          ...          ...   \n",
       "141570          0.002174  36000000.0  ...  0.000637     0.000014     8.537687   \n",
       "141571          0.002174  36000000.0  ...  0.000474     0.000016     7.466041   \n",
       "141572          0.002174  36000000.0  ...  0.000307     0.000020     6.396040   \n",
       "141573          0.002174  36000000.0  ...  0.000134     0.000028     5.326140   \n",
       "141574          0.002174  36000000.0  ...  0.000134     0.000028     4.256585   \n",
       "\n",
       "        temp_diff01  day_of_year  time_of_day  temp_mix02  temp_conv03  \\\n",
       "0         16.149422          155            1   16.206994    16.241692   \n",
       "1         16.267964          155            1   16.206994    16.247184   \n",
       "2         16.286071          155            1   16.286071    16.251763   \n",
       "3         16.288695          155            1   16.288695    16.251763   \n",
       "4         16.270156          155            1   16.270156    16.256606   \n",
       "...             ...          ...          ...         ...          ...   \n",
       "141570     8.537921          213           23    8.537921     8.537921   \n",
       "141571     7.466186          213           23    7.466186     7.466186   \n",
       "141572     6.396125          213           23    6.396125     6.396125   \n",
       "141573     5.326179          213           23    5.326179     5.326179   \n",
       "141574     4.256585          213           23    4.256585     4.256585   \n",
       "\n",
       "        obs_temp  input_obs  \n",
       "0         16.409     16.350  \n",
       "1         16.480     16.426  \n",
       "2         16.130     16.088  \n",
       "3         15.827     15.789  \n",
       "4         16.270     16.240  \n",
       "...          ...        ...  \n",
       "141570     0.401      0.401  \n",
       "141571     0.401      0.401  \n",
       "141572     0.401      0.401  \n",
       "141573     0.401      0.401  \n",
       "141574     0.401      0.401  \n",
       "\n",
       "[141575 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time_wHeat.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 5663\n",
      "Number of training points: 84925\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'ShearVelocity_mS-1', 'ShearStress_Nm-2', 'day_of_year', 'time_of_day', 'temp_diff01']\n",
    "output_columns = ['temp_mix02']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (84925, 6), X_test: (56650, 6)\n",
      "y_train: (84925, 1), y_test: (56650, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1024\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=6, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:02<44:14,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 0.14524309294500265, Test_loss: 0.020800437404042377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [02:25<50:12,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 6.240703086985881e-05, Test_loss: 9.261262864259021e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [05:20<1:02:20,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Train_loss: 5.558052040017294e-05, Test_loss: 5.775113738439229e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 151/1000 [08:08<58:36,  4.14s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 150, Train_loss: 5.332713664690992e-05, Test_loss: 5.848289347503461e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [10:56<55:18,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 200, Train_loss: 5.557784528039531e-05, Test_loss: 6.905636856962312e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 251/1000 [13:35<46:36,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 250, Train_loss: 5.375937650229849e-05, Test_loss: 5.230541234725804e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [16:33<52:59,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 300, Train_loss: 5.39690958117191e-05, Test_loss: 5.236207334746723e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 351/1000 [19:15<39:27,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 350, Train_loss: 5.463566027086576e-05, Test_loss: 6.420464431552578e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [21:50<36:23,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400, Train_loss: 5.3270517643127333e-05, Test_loss: 5.748288346499716e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 451/1000 [24:32<31:22,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 450, Train_loss: 5.3797552290376755e-05, Test_loss: 5.4721466191105197e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [27:16<27:06,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500, Train_loss: 4.965113590975328e-05, Test_loss: 5.06913273860781e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 551/1000 [30:13<32:47,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 550, Train_loss: 4.969886325502064e-05, Test_loss: 5.166811292919452e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 601/1000 [33:00<27:10,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600, Train_loss: 4.970047788206048e-05, Test_loss: 5.099850501924915e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 651/1000 [35:44<21:22,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 650, Train_loss: 4.9543327760881976e-05, Test_loss: 5.054440101405687e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 701/1000 [38:25<21:17,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 700, Train_loss: 4.9636039787960236e-05, Test_loss: 5.071857759730847e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 751/1000 [41:07<15:14,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 750, Train_loss: 4.964550758397462e-05, Test_loss: 5.114589606591835e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 801/1000 [43:50<12:10,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800, Train_loss: 4.956314874052404e-05, Test_loss: 5.097314868456644e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 851/1000 [46:28<10:07,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 850, Train_loss: 4.969650827737803e-05, Test_loss: 5.101099742838804e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 901/1000 [49:22<06:17,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900, Train_loss: 4.9524073615594464e-05, Test_loss: 5.0910845800444804e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 951/1000 [52:23<03:22,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 950, Train_loss: 4.956622731434293e-05, Test_loss: 5.1229819494632724e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [54:28<00:00,  3.27s/it]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_[:,0], pred_[:,0])\n",
    "    \n",
    "    l2_error_temp = l2_error(y_[:,0], pred_[:,0])\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 0.04440403275985938\n",
      "L2 Error  of Temp: 0.002531299871909498\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 0.04351480342033695\n",
      "L2 Error  of Temp: 0.002818857383194995\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/mixing_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.15093506])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
