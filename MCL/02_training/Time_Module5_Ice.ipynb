{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ladwi\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:2')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix03</th>\n",
       "      <th>temp_conv04</th>\n",
       "      <th>temp_initial00</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "      <th>ice</th>\n",
       "      <th>snow</th>\n",
       "      <th>snowice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.252423</td>\n",
       "      <td>584.398073</td>\n",
       "      <td>-21.601480</td>\n",
       "      <td>-26.402849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "      <td>4.089224</td>\n",
       "      <td>4.089224</td>\n",
       "      <td>4.289738</td>\n",
       "      <td>2.532738</td>\n",
       "      <td>2.535714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.252423</td>\n",
       "      <td>584.398073</td>\n",
       "      <td>-21.601480</td>\n",
       "      <td>-26.402849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "      <td>4.203297</td>\n",
       "      <td>4.203297</td>\n",
       "      <td>4.215537</td>\n",
       "      <td>2.707606</td>\n",
       "      <td>2.710317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.252423</td>\n",
       "      <td>584.398073</td>\n",
       "      <td>-21.601480</td>\n",
       "      <td>-26.402849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "      <td>4.309042</td>\n",
       "      <td>4.309042</td>\n",
       "      <td>4.350104</td>\n",
       "      <td>2.707606</td>\n",
       "      <td>2.710317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.252423</td>\n",
       "      <td>584.398073</td>\n",
       "      <td>-21.601480</td>\n",
       "      <td>-26.402849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "      <td>4.426512</td>\n",
       "      <td>4.426512</td>\n",
       "      <td>4.464834</td>\n",
       "      <td>2.707606</td>\n",
       "      <td>2.710317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-1.252423</td>\n",
       "      <td>584.398073</td>\n",
       "      <td>-21.601480</td>\n",
       "      <td>-26.402849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "      <td>4.493034</td>\n",
       "      <td>4.493034</td>\n",
       "      <td>4.498299</td>\n",
       "      <td>2.707606</td>\n",
       "      <td>2.710317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752345</th>\n",
       "      <td>46</td>\n",
       "      <td>-3.068643</td>\n",
       "      <td>528.790329</td>\n",
       "      <td>-15.910644</td>\n",
       "      <td>-20.374966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.209855</td>\n",
       "      <td>4.209855</td>\n",
       "      <td>4.209767</td>\n",
       "      <td>3.029762</td>\n",
       "      <td>3.030952</td>\n",
       "      <td>0.287239</td>\n",
       "      <td>0.025556</td>\n",
       "      <td>0.044332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752346</th>\n",
       "      <td>47</td>\n",
       "      <td>-3.068643</td>\n",
       "      <td>528.790329</td>\n",
       "      <td>-15.910644</td>\n",
       "      <td>-20.374966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.304061</td>\n",
       "      <td>4.304061</td>\n",
       "      <td>4.303953</td>\n",
       "      <td>3.185105</td>\n",
       "      <td>3.189226</td>\n",
       "      <td>0.287239</td>\n",
       "      <td>0.025556</td>\n",
       "      <td>0.044332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752347</th>\n",
       "      <td>48</td>\n",
       "      <td>-3.068643</td>\n",
       "      <td>528.790329</td>\n",
       "      <td>-15.910644</td>\n",
       "      <td>-20.374966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.398476</td>\n",
       "      <td>4.398476</td>\n",
       "      <td>4.398347</td>\n",
       "      <td>4.005785</td>\n",
       "      <td>4.009906</td>\n",
       "      <td>0.287239</td>\n",
       "      <td>0.025556</td>\n",
       "      <td>0.044332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752348</th>\n",
       "      <td>49</td>\n",
       "      <td>-3.068643</td>\n",
       "      <td>528.790329</td>\n",
       "      <td>-15.910644</td>\n",
       "      <td>-20.374966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.492759</td>\n",
       "      <td>4.492759</td>\n",
       "      <td>4.492609</td>\n",
       "      <td>4.826464</td>\n",
       "      <td>4.830586</td>\n",
       "      <td>0.287239</td>\n",
       "      <td>0.025556</td>\n",
       "      <td>0.044332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752349</th>\n",
       "      <td>50</td>\n",
       "      <td>-3.068643</td>\n",
       "      <td>528.790329</td>\n",
       "      <td>-15.910644</td>\n",
       "      <td>-20.374966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.587525</td>\n",
       "      <td>4.587525</td>\n",
       "      <td>4.587352</td>\n",
       "      <td>7.996234</td>\n",
       "      <td>7.998070</td>\n",
       "      <td>0.287239</td>\n",
       "      <td>0.025556</td>\n",
       "      <td>0.044332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1752350 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0            1     -1.252423     584.398073   -21.601480     -26.402849   \n",
       "1            2     -1.252423     584.398073   -21.601480     -26.402849   \n",
       "2            3     -1.252423     584.398073   -21.601480     -26.402849   \n",
       "3            4     -1.252423     584.398073   -21.601480     -26.402849   \n",
       "4            5     -1.252423     584.398073   -21.601480     -26.402849   \n",
       "...        ...           ...            ...          ...            ...   \n",
       "1752345     46     -3.068643     528.790329   -15.910644     -20.374966   \n",
       "1752346     47     -3.068643     528.790329   -15.910644     -20.374966   \n",
       "1752347     48     -3.068643     528.790329   -15.910644     -20.374966   \n",
       "1752348     49     -3.068643     528.790329   -15.910644     -20.374966   \n",
       "1752349     50     -3.068643     528.790329   -15.910644     -20.374966   \n",
       "\n",
       "         Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  \\\n",
       "0                   0.0               0.4              -999.0   \n",
       "1                   0.0               0.4              -999.0   \n",
       "2                   0.0               0.4              -999.0   \n",
       "3                   0.0               0.4              -999.0   \n",
       "4                   0.0               0.4              -999.0   \n",
       "...                 ...               ...                 ...   \n",
       "1752345             0.0               0.4              -999.0   \n",
       "1752346             0.0               0.4              -999.0   \n",
       "1752347             0.0               0.4              -999.0   \n",
       "1752348             0.0               0.4              -999.0   \n",
       "1752349             0.0               0.4              -999.0   \n",
       "\n",
       "         ShearStress_Nm-2     Area_m2  ...  day_of_year  time_of_day  \\\n",
       "0                  -999.0  39850000.0  ...          364            1   \n",
       "1                  -999.0  39850000.0  ...          364            1   \n",
       "2                  -999.0  39850000.0  ...          364            1   \n",
       "3                  -999.0  39850000.0  ...          364            1   \n",
       "4                  -999.0  39850000.0  ...          364            1   \n",
       "...                   ...         ...  ...          ...          ...   \n",
       "1752345            -999.0  39850000.0  ...          362           23   \n",
       "1752346            -999.0  39850000.0  ...          362           23   \n",
       "1752347            -999.0  39850000.0  ...          362           23   \n",
       "1752348            -999.0  39850000.0  ...          362           23   \n",
       "1752349            -999.0  39850000.0  ...          362           23   \n",
       "\n",
       "         temp_mix03  temp_conv04  temp_initial00  obs_temp  input_obs  \\\n",
       "0          4.089224     4.089224        4.289738  2.532738   2.535714   \n",
       "1          4.203297     4.203297        4.215537  2.707606   2.710317   \n",
       "2          4.309042     4.309042        4.350104  2.707606   2.710317   \n",
       "3          4.426512     4.426512        4.464834  2.707606   2.710317   \n",
       "4          4.493034     4.493034        4.498299  2.707606   2.710317   \n",
       "...             ...          ...             ...       ...        ...   \n",
       "1752345    4.209855     4.209855        4.209767  3.029762   3.030952   \n",
       "1752346    4.304061     4.304061        4.303953  3.185105   3.189226   \n",
       "1752347    4.398476     4.398476        4.398347  4.005785   4.009906   \n",
       "1752348    4.492759     4.492759        4.492609  4.826464   4.830586   \n",
       "1752349    4.587525     4.587525        4.587352  7.996234   7.998070   \n",
       "\n",
       "              ice      snow   snowice  \n",
       "0        0.000000  0.000000  0.000000  \n",
       "1        0.000000  0.000000  0.000000  \n",
       "2        0.000000  0.000000  0.000000  \n",
       "3        0.000000  0.000000  0.000000  \n",
       "4        0.000000  0.000000  0.000000  \n",
       "...           ...       ...       ...  \n",
       "1752345  0.287239  0.025556  0.044332  \n",
       "1752346  0.287239  0.025556  0.044332  \n",
       "1752347  0.287239  0.025556  0.044332  \n",
       "1752348  0.287239  0.025556  0.044332  \n",
       "1752349  0.287239  0.025556  0.044332  \n",
       "\n",
       "[1752350 rows x 45 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 35047\n",
      "Number of training points: 1051400\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 50\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'day_of_year', 'time_of_day','ice', 'snow', 'snowice', 'temp_conv04']\n",
    "output_columns = ['temp_total05']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1051400, 7), X_test: (700950, 7)\n",
      "y_train: (1051400, 1), y_test: (700950, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1024\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=7, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:12<21:22, 12.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 0.038847115458437706, Test_loss: 0.00044192140687207766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [07:42<08:31, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 2.9505678364269274e-05, Test_loss: 2.505819982792155e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [15:03<00:00,  9.04s/it]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_[:,0], pred_[:,0])\n",
    "    \n",
    "    l2_error_temp = l2_error(y_[:,0], pred_[:,0])\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 0.018866212382946945\n",
      "L2 Error  of Temp: 0.0020409945564043557\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 0.022340894524467535\n",
      "L2 Error  of Temp: 0.002707157148757416\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/ice_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.16900742])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
