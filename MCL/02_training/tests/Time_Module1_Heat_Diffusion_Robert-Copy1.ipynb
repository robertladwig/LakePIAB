{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ladwi\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:3')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device =  torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>buoyancy</th>\n",
       "      <th>diffusivity</th>\n",
       "      <th>temp_heat00</th>\n",
       "      <th>temp_diff01</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix02</th>\n",
       "      <th>temp_conv03</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.409</td>\n",
       "      <td>16.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.627332</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.480</td>\n",
       "      <td>16.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>11.575860</td>\n",
       "      <td>16.130</td>\n",
       "      <td>16.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.394500</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>15.827</td>\n",
       "      <td>15.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>11.123803</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>16.270</td>\n",
       "      <td>16.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35370</th>\n",
       "      <td>21</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>6.772435</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35371</th>\n",
       "      <td>22</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>5.995879</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35372</th>\n",
       "      <td>23</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>5.229508</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35373</th>\n",
       "      <td>24</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>4.467800</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35374</th>\n",
       "      <td>25</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35375 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0          1     10.715021     678.292163  -152.775961      -4.194743   \n",
       "1          2     10.715021     678.292163  -152.775961      -4.194743   \n",
       "2          3     10.715021     678.292163  -152.775961      -4.194743   \n",
       "3          4     10.715021     678.292163  -152.775961      -4.194743   \n",
       "4          5     10.715021     678.292163  -152.775961      -4.194743   \n",
       "...      ...           ...            ...          ...            ...   \n",
       "35370     21     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35371     22     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35372     23     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35373     24     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35374     25     13.595026     718.547070  -230.901096     -40.903561   \n",
       "\n",
       "       Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  ShearStress_Nm-2  \\\n",
       "0                 0.0          0.255324            1.085796          0.002290   \n",
       "1                 0.0          0.255324            1.085796          0.002290   \n",
       "2                 0.0          0.255324            1.085796          0.002290   \n",
       "3                 0.0          0.255324            1.085796          0.002290   \n",
       "4                 0.0          0.255324            1.085796          0.002290   \n",
       "...               ...               ...                 ...               ...   \n",
       "35370             0.0          2.069661            2.343012          0.007849   \n",
       "35371             0.0          2.069661            2.343012          0.007849   \n",
       "35372             0.0          2.069661            2.343012          0.007849   \n",
       "35373             0.0          2.069661            2.343012          0.007849   \n",
       "35374             0.0          2.069661            2.343012          0.007849   \n",
       "\n",
       "          Area_m2  ...  buoyancy  diffusivity  temp_heat00  temp_diff01  \\\n",
       "0      36000000.0  ...  0.000000     0.000037    11.467275    11.467275   \n",
       "1      36000000.0  ...  0.000000     0.000037    11.650008    11.627332   \n",
       "2      36000000.0  ...  0.000271     0.000021    11.650008    11.631393   \n",
       "3      36000000.0  ...  0.000278     0.000021    11.394500    11.393058   \n",
       "4      36000000.0  ...  0.000185     0.000024    11.123803    11.130929   \n",
       "...           ...  ...       ...          ...          ...          ...   \n",
       "35370  36000000.0  ...  0.000282     0.000020     6.772435     6.773650   \n",
       "35371  36000000.0  ...  0.000191     0.000024     5.995879     5.996763   \n",
       "35372  36000000.0  ...  0.000102     0.000032     5.229508     5.230045   \n",
       "35373  36000000.0  ...  0.000013     0.000037     4.467800     4.468109   \n",
       "35374  36000000.0  ...  0.000013     0.000037     3.708436     3.708436   \n",
       "\n",
       "       day_of_year  time_of_day  temp_mix02  temp_conv03  obs_temp  input_obs  \n",
       "0              155            1   11.545011    11.570472    16.409     16.350  \n",
       "1              155            1   11.545011    11.570472    16.480     16.426  \n",
       "2              155            1   11.631393    11.575860    16.130     16.088  \n",
       "3              155            1   11.393058    11.393058    15.827     15.789  \n",
       "4              155            1   11.130929    11.130929    16.270     16.240  \n",
       "...            ...          ...         ...          ...       ...        ...  \n",
       "35370          213           23    6.773650     6.773650    12.204     12.204  \n",
       "35371          213           23    5.996763     5.996763    12.204     12.204  \n",
       "35372          213           23    5.230045     5.230045    12.204     12.204  \n",
       "35373          213           23    4.468109     4.468109    12.204     12.204  \n",
       "35374          213           23    3.708436     3.708436    12.204     12.204  \n",
       "\n",
       "[35375 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time_wHeat.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 1415\n",
      "Number of training points: 21225\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'AirTemp_degC', 'Longwave_Wm-2', 'Latent_Wm-2', 'Sensible_Wm-2', 'Shortwave_Wm-2',\n",
    "                'lightExtinct_m-1', 'ShearVelocity_mS-1', 'ShearStress_Nm-2', 'Area_m2', \n",
    "                 'buoyancy', 'day_of_year', 'time_of_day', 'temp_heat00', 'diffusivity']\n",
    "output_columns = ['temp_diff01']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (21225, 15), X_test: (14150, 15)\n",
      "y_train: (21225, 1), y_test: (14150, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1024\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=15, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicit_diffusion(diff, temp, mean, std, mean2, std2):\n",
    "    \n",
    "    #mean = torch.tensor(mean).to(device)\n",
    "    # std = torch.tensor(std).to(device)\n",
    "    mean_diff = torch.tensor(mean[input_column_ix[13]]).to(device)\n",
    "    std_diff = torch.tensor(std[input_column_ix[13]]).to(device)\n",
    "    \n",
    "    mean_temp = torch.tensor(mean[input_column_ix[14]]).to(device)\n",
    "    std_temp = torch.tensor(std[input_column_ix[14]]).to(device)\n",
    "    \n",
    "    mean_out = torch.tensor(mean2).to(device)\n",
    "    std_out = torch.tensor(std2).to(device)\n",
    "    \n",
    "    # de-normalise data\n",
    "    diff = diff * std_diff + mean_diff\n",
    "    print(\"diff:\", diff)\n",
    "    \n",
    "    # INPUT DATA FROM PREVIOUS MODULE\n",
    "    t = temp * std_temp + mean_temp # temperature profile from previous module output\n",
    "    print(\"t:\", t)\n",
    "    \n",
    "    dt = 3600 # model time step - fixed\n",
    "    dx = 1 # model space step - fixed\n",
    "\n",
    "    # OUTPUT FROM MLP\n",
    "    d = diff #np.array([1e-5] * len(t)) # estimated diffusivity values\n",
    "\n",
    "    # IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "    j = len(t)\n",
    "    y = torch.zeros((len(t), len(t)), dtype=torch.float64).to(device)\n",
    "\n",
    "    alpha = (dt/dx**2) * d    \n",
    "\n",
    "    az = alpha # subdiagonal\n",
    "    bz = 2 * (1 + alpha) # diagonal\n",
    "    cz = -alpha # superdiagonal\n",
    "\n",
    "    bz[0] = 1\n",
    "    az[len(az)-2] = 0\n",
    "    bz[len(bz)-1] = 1\n",
    "    cz[0] = 0\n",
    "\n",
    "    # tridiagonal matrix\n",
    "    for k in range(j-1):\n",
    "        y[k][k] = bz[k]\n",
    "        y[k][k+1] = cz[k]\n",
    "        y[k+1][k] = az[k]\n",
    "\n",
    "    y[j-1, j-1] = 1\n",
    "\n",
    "    mn = t * 0.0    \n",
    "    mn[0] = t[0]\n",
    "    mn[len(mn)-1] = t[len(t)-1]\n",
    "\n",
    "    for k in range(1,j-1):\n",
    "        mn[k] = alpha[k] * t[k-1] + 2 * (1 - alpha[k]) * t[k] + alpha[k] * t[k]\n",
    "\n",
    "    # DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "    print(y.dtype, mn.dtype)\n",
    "    output = torch.linalg.solve(y, mn)\n",
    "    \n",
    "    proj = output\n",
    "    \n",
    "    # scaler = StandardScaler()\n",
    "    # scaler.fit(proj.reshape(-1, 1))\n",
    "    # scaler.fit(proj)\n",
    "    \n",
    "    # normalise data back\n",
    "    #proj = scaler.transform(proj.reshape(-1, 1))\n",
    "    # proj = scaler.transform(proj)\n",
    "    mean, std, var = torch.mean(proj), torch.std(proj), torch.var(proj)\n",
    "    proj = (proj-mean_out)/std_out\n",
    "\n",
    "    proj = proj.to(torch.double)\n",
    "\n",
    "    \n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 16, 17, 14, 13]\n",
      "[ 1.30000000e+01  1.93619387e+01  7.97611281e+02 -1.27637027e+02\n",
      " -1.68297160e+01  2.36993670e+02  4.08006076e-01  2.30560213e+00\n",
      "  8.82174601e-03  3.60000000e+07  8.40535870e-04  1.72232038e+02\n",
      "  1.14310954e+01  1.13445025e+01  2.07829505e-05]\n",
      "2.0782950512289867e-05\n",
      "[11.34604205]\n"
     ]
    }
   ],
   "source": [
    "print(input_column_ix)\n",
    "print(input_mean)\n",
    "print(input_mean[input_column_ix[13]])\n",
    "print(output_mean)\n",
    "#print(torch.tensor(input_mean[input_column_ix][14]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusivity_true = torch.tensor(X_train[:,input_column_ix[13]], device=device).unsqueeze(1)\n",
    "temp_heat_true = torch.tensor(X_train[:,input_column_ix[14]], device=device)#.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0783e-05, dtype=torch.float64) tensor(1.0397e-05, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "print(mean_diff, std_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.7190e-05],\n",
       "        [3.7190e-05],\n",
       "        [2.0770e-05],\n",
       "        ...,\n",
       "        [3.7190e-05],\n",
       "        [3.7190e-05],\n",
       "        [3.7190e-05]], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffusivity_true*std_diff+mean_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5781e+00],\n",
      "        [ 1.5781e+00],\n",
      "        [-1.2058e-03],\n",
      "        [-2.3273e-02],\n",
      "        [ 3.5734e-01],\n",
      "        [ 7.7969e-01],\n",
      "        [ 1.0179e+00],\n",
      "        [ 8.0049e-01],\n",
      "        [ 1.7388e-01],\n",
      "        [-3.3551e-01],\n",
      "        [-3.6113e-01],\n",
      "        [-2.6854e-01],\n",
      "        [-1.6469e-01],\n",
      "        [-6.0495e-02],\n",
      "        [ 5.7249e-02],\n",
      "        [ 1.9935e-01],\n",
      "        [ 3.7310e-01],\n",
      "        [ 5.8682e-01],\n",
      "        [ 8.5537e-01],\n",
      "        [ 1.2092e+00],\n",
      "        [ 1.5781e+00],\n",
      "        [ 1.5781e+00],\n",
      "        [ 1.5781e+00],\n",
      "        [ 1.5781e+00],\n",
      "        [ 1.5781e+00]], dtype=torch.float64)\n",
      "tensor([ 0.0207,  0.0515,  0.0515,  0.0084, -0.0372, -0.0684, -0.0901, -0.1083,\n",
      "        -0.1304, -0.1711, -0.2509, -0.3405, -0.4267, -0.5096, -0.5905, -0.6698,\n",
      "        -0.7471, -0.8221, -0.8948, -0.9654, -1.0342, -1.1016, -1.1679, -1.2335,\n",
      "        -1.2987], dtype=torch.float64)\n",
      "[ 1.30000000e+01  1.93619387e+01  7.97611281e+02 -1.27637027e+02\n",
      " -1.68297160e+01  2.36993670e+02  4.08006076e-01  2.30560213e+00\n",
      "  8.82174601e-03  3.60000000e+07  8.40535870e-04  1.72232038e+02\n",
      "  1.14310954e+01  1.13445025e+01  2.07829505e-05]\n",
      "[7.21110255e+00 5.03261927e+00 6.19193238e+01 6.14544855e+01\n",
      " 3.85658666e+01 2.66392900e+02 2.60479759e-01 1.32707200e+00\n",
      " 8.34341075e-03 1.00000000e+00 1.45960828e-03 1.02147315e+01\n",
      " 6.92260930e+00 5.92664676e+00 1.03971321e-05]\n",
      "[11.34604205]\n",
      "[5.92675375]\n"
     ]
    }
   ],
   "source": [
    "print(diffusivity_true[:25])\n",
    "print(temp_heat_true[:25])\n",
    "print(input_mean)\n",
    "print(  input_std)\n",
    "print( output_mean)\n",
    "print( output_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff: tensor([[3.7190e-05],\n",
      "        [3.7190e-05],\n",
      "        [2.0770e-05],\n",
      "        [2.0541e-05],\n",
      "        [2.4498e-05],\n",
      "        [2.8890e-05],\n",
      "        [3.1367e-05],\n",
      "        [2.9106e-05],\n",
      "        [2.2591e-05],\n",
      "        [1.7295e-05],\n",
      "        [1.7028e-05],\n",
      "        [1.7991e-05],\n",
      "        [1.9071e-05],\n",
      "        [2.0154e-05],\n",
      "        [2.1378e-05],\n",
      "        [2.2856e-05],\n",
      "        [2.4662e-05],\n",
      "        [2.6884e-05],\n",
      "        [2.9676e-05],\n",
      "        [3.3355e-05],\n",
      "        [3.7190e-05],\n",
      "        [3.7190e-05],\n",
      "        [3.7190e-05],\n",
      "        [3.7190e-05],\n",
      "        [3.7190e-05]], dtype=torch.float64)\n",
      "t: tensor([11.4673, 11.6500, 11.6500, 11.3945, 11.1238, 10.9389, 10.8103, 10.7024,\n",
      "        10.5719, 10.3305,  9.8574,  9.3268,  8.8159,  8.3246,  7.8447,  7.3750,\n",
      "         6.9170,  6.4724,  6.0415,  5.6232,  5.2154,  4.8159,  4.4228,  4.0340,\n",
      "         3.6476], dtype=torch.float64)\n",
      "tensor([[ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [-0.1339,  2.2678, -0.1339,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000, -0.0748,  2.1495, -0.0748,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000, -0.0739,  2.1479, -0.0739,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000]], dtype=torch.float64)\n",
      "torch.float64 torch.float64\n",
      "tensor([[ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [-0.1339,  2.2678, -0.1339,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000, -0.0748,  2.1495, -0.0748,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000, -0.0739,  2.1479, -0.0739,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000, -0.0882,  2.1764, -0.0882,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000, -0.1040,  2.2080, -0.1040,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1129,  2.2258, -0.1129,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1048,  2.2096,\n",
      "         -0.1048,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0813,\n",
      "          2.1627, -0.0813,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         -0.0623,  2.1245, -0.0623,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000, -0.0613,  2.1226, -0.0613,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000, -0.0648,  2.1295, -0.0648,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000, -0.0687,  2.1373, -0.0687,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000, -0.0726,  2.1451, -0.0726,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0770,  2.1539, -0.0770,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0823,  2.1646,\n",
      "         -0.0823,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0888,\n",
      "          2.1776, -0.0888,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         -0.0968,  2.1936, -0.0968,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000, -0.1068,  2.2137, -0.1068,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000, -0.1201,  2.2402, -0.1201,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000, -0.1339,  2.2678, -0.1339,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000, -0.1339,  2.2678, -0.1339,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1339,  2.2678, -0.1339,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1339,  2.2678,\n",
      "         -0.1339],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          1.0000]], dtype=torch.float64)\n",
      "tensor([11.4673, 23.2756, 23.3000, 22.8079, 22.2715, 21.8970, 21.6351, 21.4161,\n",
      "        21.1544, 20.6761, 19.7438, 18.6879, 17.6668, 16.6848, 15.7264, 14.7886,\n",
      "        13.8746, 12.9878, 12.1291, 11.2966, 10.4854,  9.6852,  8.8983,  8.1200,\n",
      "         3.6476], dtype=torch.float64)\n",
      "tensor([11.4673, 11.6279, 11.6406, 11.4030, 11.1391, 10.9514, 10.8187, 10.7069,\n",
      "        10.5728, 10.3312,  9.8699,  9.3444,  8.8341,  8.3428,  7.8636,  7.3948,\n",
      "         6.9379,  6.4946,  6.0652,  5.6489,  5.2431,  4.8430,  4.4493,  4.0586,\n",
      "         3.6476], dtype=torch.float64)\n",
      "tensor([ 0.0205,  0.0476,  0.0497,  0.0096, -0.0349, -0.0666, -0.0890, -0.1078,\n",
      "        -0.1305, -0.1712, -0.2491, -0.3377, -0.4238, -0.5067, -0.5876, -0.6667,\n",
      "        -0.7438, -0.8186, -0.8910, -0.9613, -1.0297, -1.0972, -1.1637, -1.2296,\n",
      "        -1.2989], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "diff=diffusivity_true[:25]\n",
    "temp=temp_heat_true[:25]\n",
    "mean=input_mean\n",
    "std=input_std\n",
    "mean2=output_mean\n",
    "std2=output_std\n",
    "\n",
    "mean_diff = torch.tensor(mean[input_column_ix[13]]).to(device)\n",
    "std_diff = torch.tensor(std[input_column_ix[13]]).to(device)\n",
    "\n",
    "mean_temp = torch.tensor(mean[input_column_ix[14]]).to(device)\n",
    "std_temp = torch.tensor(std[input_column_ix[14]]).to(device)\n",
    "\n",
    "mean_out = torch.tensor(mean2).to(device)\n",
    "std_out = torch.tensor(std2).to(device)\n",
    "\n",
    "# de-normalise data\n",
    "diff = diff * std_diff + mean_diff\n",
    "print(\"diff:\", diff)\n",
    "\n",
    "# INPUT DATA FROM PREVIOUS MODULE\n",
    "t = temp * std_temp + mean_temp # temperature profile from previous module output\n",
    "print(\"t:\", t)\n",
    "\n",
    "dt = 3600 # model time step - fixed\n",
    "dx = 1 # model space step - fixed\n",
    "\n",
    "# OUTPUT FROM MLP\n",
    "d = diff #np.array([1e-5] * len(t)) # estimated diffusivity values\n",
    "\n",
    "# IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "j = len(t)\n",
    "y = torch.zeros((len(t), len(t)), dtype=torch.float64).to(device)\n",
    "\n",
    "alpha = (dt/dx**2) * d\n",
    "\n",
    "az = - alpha # subdiagonal\n",
    "bz = 2 * (1 + alpha) # diagonal\n",
    "cz = - alpha # superdiagonal\n",
    "\n",
    "az[0] = 0\n",
    "bz[0] = 1\n",
    "cz[len(az)-1] = 0\n",
    "bz[len(bz)-1] = 1\n",
    "\n",
    "az =  np.delete(az,0)\n",
    "cz =  np.delete(cz,len(cz)-1)\n",
    "\n",
    "# tridiagonal matrix\n",
    "for k in range(j-1):\n",
    "    y[k][k] = bz[k]\n",
    "    y[k][k+1] = cz[k]\n",
    "    y[k+1][k] = az[k]\n",
    "\n",
    "y[0,1] = 0    \n",
    "y[j-1, j-1] = 1\n",
    "y[j-1, j-2] = 0\n",
    "\n",
    "print(y[0:4])\n",
    "\n",
    "mn = t * 0.0    \n",
    "mn[0] = t[0]\n",
    "mn[len(mn)-1] = t[len(t)-1]\n",
    "\n",
    "for k in range(1,j-1):\n",
    "    mn[k] = alpha[k] * t[k-1] + 2 * (1 - alpha[k]) * t[k] + alpha[k] * t[k]\n",
    "# DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "print(y.dtype, mn.dtype)\n",
    "\n",
    "print(y)\n",
    "print(mn)\n",
    "output = torch.linalg.solve(y, mn)\n",
    "\n",
    "proj = output\n",
    "print(proj)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(proj.reshape(-1, 1))\n",
    "# scaler.fit(proj)\n",
    "\n",
    "# normalise data back\n",
    "#proj = scaler.transform(proj.reshape(-1, 1))\n",
    "# proj = scaler.transform(proj)\n",
    "mean, std, var = torch.mean(proj), torch.std(proj), torch.var(proj)\n",
    "proj = (proj-mean_out)/std_out\n",
    "\n",
    "proj = proj.to(torch.double)\n",
    "print(proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff: tensor([[3.7190e-05],\n",
      "        [3.7190e-05],\n",
      "        [2.0770e-05],\n",
      "        [2.0541e-05],\n",
      "        [2.4498e-05],\n",
      "        [2.8890e-05],\n",
      "        [3.1367e-05],\n",
      "        [2.9106e-05],\n",
      "        [2.2591e-05],\n",
      "        [1.7295e-05],\n",
      "        [1.7028e-05],\n",
      "        [1.7991e-05],\n",
      "        [1.9071e-05],\n",
      "        [2.0154e-05],\n",
      "        [2.1378e-05],\n",
      "        [2.2856e-05],\n",
      "        [2.4662e-05],\n",
      "        [2.6884e-05],\n",
      "        [2.9676e-05],\n",
      "        [3.3355e-05],\n",
      "        [3.7190e-05],\n",
      "        [3.7190e-05],\n",
      "        [3.7190e-05],\n",
      "        [3.7190e-05],\n",
      "        [3.7190e-05]], dtype=torch.float64)\n",
      "t: tensor([11.4673, 11.6500, 11.6500, 11.3945, 11.1238, 10.9389, 10.8103, 10.7024,\n",
      "        10.5719, 10.3305,  9.8574,  9.3268,  8.8159,  8.3246,  7.8447,  7.3750,\n",
      "         6.9170,  6.4724,  6.0415,  5.6232,  5.2154,  4.8159,  4.4228,  4.0340,\n",
      "         3.6476], dtype=torch.float64)\n",
      "torch.float64 torch.float64\n"
     ]
    }
   ],
   "source": [
    "pred = implicit_diffusion(diff=diffusivity_true[:25], \n",
    "                          temp=temp_heat_true[:25], \n",
    "                          mean=input_mean, \n",
    "                          std=input_std,\n",
    "                          mean2=output_mean, \n",
    "                          std2=output_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0205, -0.1915, -0.1305, -0.1251, -0.1804, -0.2329, -0.2703, -0.2856,\n",
       "        -0.2817, -0.2890, -0.3499, -0.4364, -0.5224, -0.6050, -0.6855, -0.7646,\n",
       "        -0.8421, -0.9181, -0.9925, -1.0658, -1.1371, -1.2010, -1.2591, -1.3165,\n",
       "        -1.2989], dtype=torch.float64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02045524],\n",
       "       [ 0.0474611 ],\n",
       "       [ 0.0481462 ],\n",
       "       [ 0.00793292],\n",
       "       [-0.0362952 ],\n",
       "       [-0.06772897],\n",
       "       [-0.09001629],\n",
       "       [-0.10901893],\n",
       "       [-0.13213088],\n",
       "       [-0.17369716],\n",
       "       [-0.25179477],\n",
       "       [-0.34051382],\n",
       "       [-0.42668375],\n",
       "       [-0.50966083],\n",
       "       [-0.5906289 ],\n",
       "       [-0.66986329],\n",
       "       [-0.74710139],\n",
       "       [-0.82208893],\n",
       "       [-0.89478916],\n",
       "       [-0.9653834 ],\n",
       "       [-1.03421521],\n",
       "       [-1.10166929],\n",
       "       [-1.16803615],\n",
       "       [-1.23368658],\n",
       "       [-1.29892429]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14f58cda820>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pred.numpy(),y_train[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0207,  0.0515,  0.0515,  0.0084, -0.0372, -0.0684, -0.0901, -0.1083,\n",
      "        -0.1304, -0.1711, -0.2509, -0.3405, -0.4267, -0.5096, -0.5905, -0.6698,\n",
      "        -0.7471, -0.8221, -0.8948, -0.9654, -1.0342, -1.1016, -1.1679, -1.2335,\n",
      "        -1.2987], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(temp_heat_true[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test if the Crank-Nicholson scheme works\n",
    "\n",
    "# temp = torch.rand(5,1).to(device)\n",
    "# diff = torch.rand(5,1).to(device)\n",
    "# print(temp), print(diff)\n",
    "# implicit_diffusion(diff, temp, input_mean, input_std,\n",
    "#                                  output_mean, output_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        \n",
    "        # get temperature input\n",
    "        temp_input = x[:,13]\n",
    "        #print(temp_input)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #print(model(x))\n",
    "        proj = model(x)\n",
    "        #print(proj)\n",
    "        \n",
    "        # torch.set_printoptions(profile=\"full\")\n",
    "        \n",
    "        pred = implicit_diffusion(proj, temp_input, input_mean, input_std,\n",
    "                                 output_mean, output_std)\n",
    "\n",
    "        # print(pred)\n",
    "        # print(y)\n",
    "        \n",
    "        #pred.grad.data.copy_(proj.grad.data)\n",
    "        \n",
    "        # proj[0:30,0] = pred\n",
    "        \n",
    "        # print(proj)\n",
    "        \n",
    "        #print(pred)\n",
    "        #print(y)\n",
    "        \n",
    "        pred = pred.to(dtype=torch.float32)\n",
    "        \n",
    "        loss = criterion(pred, y)\n",
    "        #print(loss)\n",
    "        #loss= loss.double\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            #pred = model(x)\n",
    "            \n",
    "            #mean=0.0\n",
    "            #std=1.0\n",
    "            #mean = torch.tensor(mean).to(device)\n",
    "            #std = torch.tensor(std).to(device)\n",
    "            temp_input = x[:,13] #* std + mean\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            proj = model(x)\n",
    "\n",
    "            pred = implicit_diffusion(proj, temp_input, input_mean, input_std,\n",
    "                                 output_mean, output_std)\n",
    "\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        \n",
    "        temp_input = x[:,13]\n",
    "        proj = model(x)\n",
    "        pred = implicit_diffusion(proj, temp_input, input_mean, input_std,\n",
    "                                 output_mean, output_std)        \n",
    "        pred = pred.to(dtype=torch.float32)\n",
    "        \n",
    "        \n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        \n",
    "        #red = torch.squeeze(pred)\n",
    "        \n",
    "        #rint(pred.shape)\n",
    "        \n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    \n",
    "    rmse_temp = rmse(y_[:,0], pred_)\n",
    "    \n",
    "    l2_error_temp = l2_error(y_[:,0], pred_)\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/heat_diffusion_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
