{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ladwi\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>buoyancy</th>\n",
       "      <th>diffusivity</th>\n",
       "      <th>temp_heat00</th>\n",
       "      <th>temp_diff01</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix02</th>\n",
       "      <th>temp_conv03</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.409</td>\n",
       "      <td>16.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.627332</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.480</td>\n",
       "      <td>16.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>11.575860</td>\n",
       "      <td>16.130</td>\n",
       "      <td>16.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.394500</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>15.827</td>\n",
       "      <td>15.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>11.123803</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>16.270</td>\n",
       "      <td>16.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35370</th>\n",
       "      <td>21</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>6.772435</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35371</th>\n",
       "      <td>22</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>5.995879</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35372</th>\n",
       "      <td>23</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>5.229508</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35373</th>\n",
       "      <td>24</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>4.467800</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35374</th>\n",
       "      <td>25</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35375 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0          1     10.715021     678.292163  -152.775961      -4.194743   \n",
       "1          2     10.715021     678.292163  -152.775961      -4.194743   \n",
       "2          3     10.715021     678.292163  -152.775961      -4.194743   \n",
       "3          4     10.715021     678.292163  -152.775961      -4.194743   \n",
       "4          5     10.715021     678.292163  -152.775961      -4.194743   \n",
       "...      ...           ...            ...          ...            ...   \n",
       "35370     21     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35371     22     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35372     23     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35373     24     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35374     25     13.595026     718.547070  -230.901096     -40.903561   \n",
       "\n",
       "       Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  ShearStress_Nm-2  \\\n",
       "0                 0.0          0.255324            1.085796          0.002290   \n",
       "1                 0.0          0.255324            1.085796          0.002290   \n",
       "2                 0.0          0.255324            1.085796          0.002290   \n",
       "3                 0.0          0.255324            1.085796          0.002290   \n",
       "4                 0.0          0.255324            1.085796          0.002290   \n",
       "...               ...               ...                 ...               ...   \n",
       "35370             0.0          2.069661            2.343012          0.007849   \n",
       "35371             0.0          2.069661            2.343012          0.007849   \n",
       "35372             0.0          2.069661            2.343012          0.007849   \n",
       "35373             0.0          2.069661            2.343012          0.007849   \n",
       "35374             0.0          2.069661            2.343012          0.007849   \n",
       "\n",
       "          Area_m2  ...  buoyancy  diffusivity  temp_heat00  temp_diff01  \\\n",
       "0      36000000.0  ...  0.000000     0.000037    11.467275    11.467275   \n",
       "1      36000000.0  ...  0.000000     0.000037    11.650008    11.627332   \n",
       "2      36000000.0  ...  0.000271     0.000021    11.650008    11.631393   \n",
       "3      36000000.0  ...  0.000278     0.000021    11.394500    11.393058   \n",
       "4      36000000.0  ...  0.000185     0.000024    11.123803    11.130929   \n",
       "...           ...  ...       ...          ...          ...          ...   \n",
       "35370  36000000.0  ...  0.000282     0.000020     6.772435     6.773650   \n",
       "35371  36000000.0  ...  0.000191     0.000024     5.995879     5.996763   \n",
       "35372  36000000.0  ...  0.000102     0.000032     5.229508     5.230045   \n",
       "35373  36000000.0  ...  0.000013     0.000037     4.467800     4.468109   \n",
       "35374  36000000.0  ...  0.000013     0.000037     3.708436     3.708436   \n",
       "\n",
       "       day_of_year  time_of_day  temp_mix02  temp_conv03  obs_temp  input_obs  \n",
       "0              155            1   11.545011    11.570472    16.409     16.350  \n",
       "1              155            1   11.545011    11.570472    16.480     16.426  \n",
       "2              155            1   11.631393    11.575860    16.130     16.088  \n",
       "3              155            1   11.393058    11.393058    15.827     15.789  \n",
       "4              155            1   11.130929    11.130929    16.270     16.240  \n",
       "...            ...          ...         ...          ...       ...        ...  \n",
       "35370          213           23    6.773650     6.773650    12.204     12.204  \n",
       "35371          213           23    5.996763     5.996763    12.204     12.204  \n",
       "35372          213           23    5.230045     5.230045    12.204     12.204  \n",
       "35373          213           23    4.468109     4.468109    12.204     12.204  \n",
       "35374          213           23    3.708436     3.708436    12.204     12.204  \n",
       "\n",
       "[35375 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time_wHeat.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 1415\n",
      "Number of training points: 21225\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'AirTemp_degC', 'Longwave_Wm-2', 'Latent_Wm-2', 'Sensible_Wm-2', 'Shortwave_Wm-2',\n",
    "                'lightExtinct_m-1', 'ShearVelocity_mS-1', 'ShearStress_Nm-2', 'Area_m2', \n",
    "                 'buoyancy', 'day_of_year', 'time_of_day', 'temp_heat00', 'diffusivity']\n",
    "output_columns = ['temp_diff01']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (21225, 15), X_test: (14150, 15)\n",
      "y_train: (21225, 1), y_test: (14150, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1024\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=15, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicit_diffusion(self, temp, mean, std, mean2, std2):\n",
    "    \n",
    "    #mean = torch.tensor(mean).to(device)\n",
    "    # std = torch.tensor(std).to(device)\n",
    "    mean_diff = torch.tensor(mean[input_column_ix[13]]).to(device)\n",
    "    std_diff = torch.tensor(std[input_column_ix[13]]).to(device)\n",
    "    \n",
    "    mean_temp = torch.tensor(mean[input_column_ix[14]]).to(device)\n",
    "    std_temp = torch.tensor(std[input_column_ix[14]]).to(device)\n",
    "    \n",
    "    mean_out = torch.tensor(mean2).to(device)\n",
    "    std_out = torch.tensor(std2).to(device)\n",
    "    \n",
    "    # de-normalise data\n",
    "    self = self * std_diff + mean_diff\n",
    "    \n",
    "    #print(self)\n",
    "    \n",
    "    # INPUT DATA FROM PREVIOUS MODULE\n",
    "    t = temp * std_temp + mean_temp # temperature profile from previous module output\n",
    "    \n",
    "    #print(t)\n",
    "    \n",
    "    dt = 3600 # model time step - fixed\n",
    "    dx = 1 # model space step - fixed\n",
    "\n",
    "    # OUTPUT FROM MLP\n",
    "    d = self #np.array([1e-5] * len(t)) # estimated diffusivity values\n",
    "\n",
    "    # IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "    j = len(t)\n",
    "    y = torch.zeros((len(t), len(t)))\n",
    "\n",
    "    alpha = (dt/dx**2) * d    \n",
    "\n",
    "    az = alpha # subdiagonal\n",
    "    bz = 2 * (1 + alpha) # diagonal\n",
    "    cz = -alpha # superdiagonal\n",
    "\n",
    "    bz[0] = 1\n",
    "    az[len(az)-2] = 0\n",
    "    bz[len(bz)-1] = 1\n",
    "    cz[0] = 0\n",
    "\n",
    "    # tridiagonal matrix\n",
    "    for k in range(j-1):\n",
    "        y[k][k] = bz[k]\n",
    "        y[k][k+1] = cz[k]\n",
    "        y[k+1][k] = az[k]\n",
    "\n",
    "    y[j-1, j-1] = 1\n",
    "\n",
    "    mn = t * 0.0    \n",
    "    mn[0] = t[0]\n",
    "    mn[len(mn)-1] = t[len(t)-1]\n",
    "\n",
    "    for k in range(1,j-1):\n",
    "        mn[k] = alpha[k] * t[k-1] + 2 * (1 - alpha[k]) * t[k] + alpha[k] * t[k]\n",
    "\n",
    "    # DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "    output = torch.linalg.solve(y, mn)\n",
    "    \n",
    "    proj = output\n",
    "    \n",
    "    # scaler = StandardScaler()\n",
    "    # scaler.fit(proj.reshape(-1, 1))\n",
    "    # scaler.fit(proj)\n",
    "    \n",
    "    # normalise data back\n",
    "    #proj = scaler.transform(proj.reshape(-1, 1))\n",
    "    # proj = scaler.transform(proj)\n",
    "    mean, std, var = torch.mean(proj), torch.std(proj), torch.var(proj)\n",
    "    proj = (proj-mean_out)/std_out\n",
    "\n",
    "    proj = proj.to(torch.double)\n",
    "\n",
    "    \n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 16, 17, 14, 13]\n",
      "[ 1.30000000e+01  1.93619387e+01  7.97611281e+02 -1.27637027e+02\n",
      " -1.68297160e+01  2.36993670e+02  4.08006076e-01  2.30560213e+00\n",
      "  8.82174601e-03  3.60000000e+07  8.40535870e-04  1.72232038e+02\n",
      "  1.14310954e+01  1.13445025e+01  2.07829505e-05]\n",
      "2.0782950512289867e-05\n",
      "[11.34604205]\n"
     ]
    }
   ],
   "source": [
    "print(input_column_ix)\n",
    "print(input_mean)\n",
    "print(input_mean[input_column_ix[13]])\n",
    "print(output_mean)\n",
    "#print(torch.tensor(input_mean[input_column_ix][14]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4679],\n",
      "        [0.8803],\n",
      "        [0.7058],\n",
      "        [0.3833],\n",
      "        [0.2044]])\n",
      "tensor([[0.8847],\n",
      "        [0.4477],\n",
      "        [0.3417],\n",
      "        [0.6000],\n",
      "        [0.8121]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4676],\n",
       "        [0.6109],\n",
       "        [0.4795],\n",
       "        [0.1777],\n",
       "        [0.2041]], dtype=torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if the Crank-Nicholson scheme works\n",
    "\n",
    "temp = torch.rand(5,1)\n",
    "diff = torch.rand(5,1)\n",
    "print(temp), print(diff)\n",
    "implicit_diffusion(diff, temp, input_mean, input_std,\n",
    "                                 output_mean, output_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 1/1000 [00:10<2:54:59, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 1.8234010878063382, Test_loss: 1.889078761756038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▉                                     | 51/1000 [07:19<2:22:27,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 1.432098280815851, Test_loss: 1.6982366217308502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▊                                  | 101/1000 [14:21<2:13:25,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Train_loss: 1.4371555589494251, Test_loss: 1.7193302548296232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████▋                                | 151/1000 [21:20<2:07:29,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 150, Train_loss: 1.4303276538848877, Test_loss: 1.6856737838624276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▋                              | 201/1000 [28:25<1:59:58,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 200, Train_loss: 1.4304501783280146, Test_loss: 1.6834195463167156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████▌                            | 251/1000 [35:29<1:51:16,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 250, Train_loss: 1.4326622656413488, Test_loss: 1.7079676115925948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████▍                          | 301/1000 [42:40<1:44:34,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 300, Train_loss: 1.4346108493350802, Test_loss: 1.6890421751771374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████▎                        | 351/1000 [49:45<1:38:02,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 350, Train_loss: 1.4358513525554113, Test_loss: 1.687938735183941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████▏                      | 401/1000 [56:54<1:30:03,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400, Train_loss: 1.43293449424562, Test_loss: 1.6933088804058738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████████▏                   | 451/1000 [1:03:56<1:22:26,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 450, Train_loss: 1.4324038142249698, Test_loss: 1.694431229720409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████                  | 501/1000 [1:10:50<1:13:20,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500, Train_loss: 1.436902261915661, Test_loss: 1.6741535490432162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████▊                | 551/1000 [1:18:07<1:06:58,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 550, Train_loss: 1.4347102755591983, Test_loss: 1.6918969413745444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████▋              | 601/1000 [1:25:27<1:02:01,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600, Train_loss: 1.4391188905352639, Test_loss: 1.7037503969545824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████▋             | 651/1000 [1:32:48<53:29,  9.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 650, Train_loss: 1.4345952896844774, Test_loss: 1.696586696857514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████▋           | 701/1000 [1:40:03<45:34,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 700, Train_loss: 1.437037808554513, Test_loss: 1.693605147187951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████▌         | 751/1000 [1:47:12<38:21,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 750, Train_loss: 1.4313031889143444, Test_loss: 1.6852216125243487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████▍       | 801/1000 [1:54:31<30:09,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800, Train_loss: 1.4299970865249634, Test_loss: 1.6875625201443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████▎     | 851/1000 [2:01:54<22:45,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 850, Train_loss: 1.4299032574608213, Test_loss: 1.687929040719376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████▏   | 901/1000 [2:09:14<15:17,  9.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900, Train_loss: 1.4325932604925973, Test_loss: 1.6881313591667182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████████████████▏ | 951/1000 [2:16:40<07:58,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 950, Train_loss: 1.4334061770212083, Test_loss: 1.6977810723336757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1000/1000 [2:23:55<00:00,  8.64s/it]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        \n",
    "        # get temperature input\n",
    "        temp_input = x[:,13]\n",
    "        #print(temp_input)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #print(model(x))\n",
    "        proj = model(x)\n",
    "        \n",
    "        #print(proj)\n",
    "        \n",
    "        # torch.set_printoptions(profile=\"full\")\n",
    "        \n",
    "        pred = implicit_diffusion(proj, temp_input, input_mean, input_std,\n",
    "                                 output_mean, output_std)\n",
    "\n",
    "        # print(pred)\n",
    "        # print(y)\n",
    "        \n",
    "        #pred.grad.data.copy_(proj.grad.data)\n",
    "        \n",
    "        # proj[0:30,0] = pred\n",
    "        \n",
    "        # print(proj)\n",
    "        \n",
    "        #print(pred)\n",
    "        #print(y)\n",
    "        \n",
    "        pred = pred.to(dtype=torch.float32)\n",
    "        \n",
    "        loss = criterion(pred, y)\n",
    "        #print(loss)\n",
    "        #loss= loss.double\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            #pred = model(x)\n",
    "            \n",
    "            #mean=0.0\n",
    "            #std=1.0\n",
    "            #mean = torch.tensor(mean).to(device)\n",
    "            #std = torch.tensor(std).to(device)\n",
    "            temp_input = x[:,13] #* std + mean\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            proj = model(x)\n",
    "\n",
    "            pred = implicit_diffusion(proj, temp_input, input_mean, input_std,\n",
    "                                 output_mean, output_std)\n",
    "\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        \n",
    "        temp_input = x[:,13]\n",
    "        proj = model(x)\n",
    "        pred = implicit_diffusion(proj, temp_input, input_mean, input_std,\n",
    "                                 output_mean, output_std)        \n",
    "        pred = pred.to(dtype=torch.float32)\n",
    "        \n",
    "        \n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        \n",
    "        #red = torch.squeeze(pred)\n",
    "        \n",
    "        #rint(pred.shape)\n",
    "        \n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    \n",
    "    rmse_temp = rmse(y_[:,0], pred_)\n",
    "    \n",
    "    l2_error_temp = l2_error(y_[:,0], pred_)\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 4.672588302163922\n",
      "L2 Error  of Temp: 0.32180458091049735\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 4.413606211770692\n",
      "L2 Error  of Temp: 0.3447929091444347\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/heat_diffusion_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.34604205])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
