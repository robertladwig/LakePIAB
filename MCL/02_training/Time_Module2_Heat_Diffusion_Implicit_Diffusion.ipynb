{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:3')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device =  torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>diffusivity</th>\n",
       "      <th>temp_heat01</th>\n",
       "      <th>temp_diff02</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix03</th>\n",
       "      <th>temp_conv04</th>\n",
       "      <th>temp_initial00</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.416676</td>\n",
       "      <td>15.416676</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.426904</td>\n",
       "      <td>15.426904</td>\n",
       "      <td>15.489510</td>\n",
       "      <td>22.279</td>\n",
       "      <td>22.279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>15.448083</td>\n",
       "      <td>15.437735</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.401481</td>\n",
       "      <td>15.401481</td>\n",
       "      <td>15.448078</td>\n",
       "      <td>22.295</td>\n",
       "      <td>22.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>15.376622</td>\n",
       "      <td>15.374550</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.346109</td>\n",
       "      <td>15.346109</td>\n",
       "      <td>15.376617</td>\n",
       "      <td>22.091</td>\n",
       "      <td>22.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>15.287991</td>\n",
       "      <td>15.287547</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.272596</td>\n",
       "      <td>15.272596</td>\n",
       "      <td>15.287987</td>\n",
       "      <td>22.296</td>\n",
       "      <td>22.296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>15.195124</td>\n",
       "      <td>15.195829</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.193004</td>\n",
       "      <td>15.193004</td>\n",
       "      <td>15.195121</td>\n",
       "      <td>22.231</td>\n",
       "      <td>22.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495570</th>\n",
       "      <td>21</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>8.373718</td>\n",
       "      <td>8.375543</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>8.375543</td>\n",
       "      <td>8.375543</td>\n",
       "      <td>8.373683</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495571</th>\n",
       "      <td>22</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>7.324853</td>\n",
       "      <td>7.326184</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>7.326184</td>\n",
       "      <td>7.326184</td>\n",
       "      <td>7.324806</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495572</th>\n",
       "      <td>23</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>6.297841</td>\n",
       "      <td>6.298671</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>6.298671</td>\n",
       "      <td>6.298671</td>\n",
       "      <td>6.297760</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495573</th>\n",
       "      <td>24</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>5.282023</td>\n",
       "      <td>5.282477</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.282477</td>\n",
       "      <td>5.282477</td>\n",
       "      <td>5.282023</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495574</th>\n",
       "      <td>25</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495575 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0           1     13.965021     717.887954   -32.080993      -6.880394   \n",
       "1           2     13.965021     717.887954   -32.080993      -6.880394   \n",
       "2           3     13.965021     717.887954   -32.080993      -6.880394   \n",
       "3           4     13.965021     717.887954   -32.080993      -6.880394   \n",
       "4           5     13.965021     717.887954   -32.080993      -6.880394   \n",
       "...       ...           ...            ...          ...            ...   \n",
       "495570     21     17.945001     796.182785   -59.448422     -13.843945   \n",
       "495571     22     17.945001     796.182785   -59.448422     -13.843945   \n",
       "495572     23     17.945001     796.182785   -59.448422     -13.843945   \n",
       "495573     24     17.945001     796.182785   -59.448422     -13.843945   \n",
       "495574     25     17.945001     796.182785   -59.448422     -13.843945   \n",
       "\n",
       "        Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  \\\n",
       "0                  0.0               0.8            1.803546   \n",
       "1                  0.0               0.8            1.803546   \n",
       "2                  0.0               0.8            1.803546   \n",
       "3                  0.0               0.8            1.803546   \n",
       "4                  0.0               0.8            1.803546   \n",
       "...                ...               ...                 ...   \n",
       "495570             0.0               0.8            0.322170   \n",
       "495571             0.0               0.8            0.322170   \n",
       "495572             0.0               0.8            0.322170   \n",
       "495573             0.0               0.8            0.322170   \n",
       "495574             0.0               0.8            0.322170   \n",
       "\n",
       "        ShearStress_Nm-2     Area_m2  ...  diffusivity  temp_heat01  \\\n",
       "0               0.008386  36000000.0  ...     0.000037    15.416676   \n",
       "1               0.008386  36000000.0  ...     0.000031    15.448083   \n",
       "2               0.008386  36000000.0  ...     0.000028    15.376622   \n",
       "3               0.008386  36000000.0  ...     0.000028    15.287991   \n",
       "4               0.008386  36000000.0  ...     0.000029    15.195124   \n",
       "...                  ...         ...  ...          ...          ...   \n",
       "495570          0.000534  36000000.0  ...     0.000015     8.373718   \n",
       "495571          0.000534  36000000.0  ...     0.000017     7.324853   \n",
       "495572          0.000534  36000000.0  ...     0.000020     6.297841   \n",
       "495573          0.000534  36000000.0  ...     0.000029     5.282023   \n",
       "495574          0.000534  36000000.0  ...     0.000029     4.270583   \n",
       "\n",
       "        temp_diff02  day_of_year  time_of_day  temp_mix03  temp_conv04  \\\n",
       "0         15.416676          155            1   15.426904    15.426904   \n",
       "1         15.437735          155            1   15.401481    15.401481   \n",
       "2         15.374550          155            1   15.346109    15.346109   \n",
       "3         15.287547          155            1   15.272596    15.272596   \n",
       "4         15.195829          155            1   15.193004    15.193004   \n",
       "...             ...          ...          ...         ...          ...   \n",
       "495570     8.375543          213           23    8.375543     8.375543   \n",
       "495571     7.326184          213           23    7.326184     7.326184   \n",
       "495572     6.298671          213           23    6.298671     6.298671   \n",
       "495573     5.282477          213           23    5.282477     5.282477   \n",
       "495574     4.270583          213           23    4.270583     4.270583   \n",
       "\n",
       "        temp_initial00  obs_temp  input_obs  \n",
       "0            15.489510    22.279     22.279  \n",
       "1            15.448078    22.295     22.295  \n",
       "2            15.376617    22.091     22.091  \n",
       "3            15.287987    22.296     22.296  \n",
       "4            15.195121    22.231     22.231  \n",
       "...                ...       ...        ...  \n",
       "495570        8.373683    11.099     11.099  \n",
       "495571        7.324806    11.099     11.099  \n",
       "495572        6.297760    11.099     11.099  \n",
       "495573        5.282023    11.099     11.099  \n",
       "495574        4.270583    11.099     11.099  \n",
       "\n",
       "[495575 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 19823\n",
      "Number of training points: 297325\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'AirTemp_degC', 'Longwave_Wm-2', 'Latent_Wm-2', 'Sensible_Wm-2', 'Shortwave_Wm-2',\n",
    "                'lightExtinct_m-1', 'ShearVelocity_mS-1', 'ShearStress_Nm-2', 'Area_m2', \n",
    "                 'buoyancy', 'day_of_year', 'time_of_day', 'diffusivity' ,'temp_heat01']\n",
    "output_columns = ['temp_diff02']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (297325, 15), X_test: (198250, 15)\n",
      "y_train: (297325, 1), y_test: (198250, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1000\n",
    "\n",
    "assert batch_size % 25 ==0, \"Batchsize has to be multiple of 25\" \n",
    "\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=15, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "# std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "\n",
    "# mean_temp = torch.tensor(input_mean[input_column_ix[14]]).to(device)\n",
    "# std_temp = torch.tensor(input_std[input_column_ix[14]]).to(device)\n",
    "\n",
    "# mean_out = torch.tensor(output_mean).to(device)\n",
    "# std_out = torch.tensor(output_std).to(device)\n",
    "    \n",
    "# def implicit_diffusion(diff, temp, dt=3600, dx=1, depth_steps=25):\n",
    "#     # de-normalise data\n",
    "#     diff = diff * std_diff + mean_diff\n",
    "\n",
    "#     # INPUT DATA FROM PREVIOUS MODULE\n",
    "#     t = temp * std_temp + mean_temp # temperature profile from previous module output\n",
    "\n",
    "#     # IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "#     j = len(t)\n",
    "#     y = torch.zeros((len(t), len(t)), dtype=torch.float64).to(device)\n",
    "\n",
    "#     alpha = (dt/dx**2) * diff\n",
    "\n",
    "#     az = - alpha # subdiagonal\n",
    "#     bz = 2 * (1 + alpha) # diagonal\n",
    "#     cz = - alpha # superdiagonal\n",
    "\n",
    "#     bz[0] = 1\n",
    "#     az[len(az)-2] = 0\n",
    "#     bz[len(bz)-1] = 1\n",
    "#     cz[0] = 0\n",
    "\n",
    "#     az = az[1:,:]\n",
    "#     cz = cz[:-1,:]\n",
    "\n",
    "#     y = torch.diag(bz[:, 0])+torch.diag(az[:, 0],-1)+torch.diag(cz[:, 0],1) #slightly efficient way of computing the diagonal matrices\n",
    "#     y[j-1, j-1] = 1\n",
    "    \n",
    "#     mn = torch.zeros_like(t)  \n",
    "#     mn[0] = t[0]\n",
    "#     mn[len(mn)-1] = t[len(t)-1]\n",
    "    \n",
    "#     mn[1:j-1] = alpha[1:j-1,0]*t[:j-2] + 2 * (1 - alpha[1:j-1,0])*t[1:j-1] + alpha[1:j-1,0]*t[1:j-1] #is be same as the loop\n",
    "    \n",
    "#     # DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "#     proj = torch.linalg.solve(y, mn)\n",
    "\n",
    "#     mean, std, var = torch.mean(proj), torch.std(proj), torch.var(proj)\n",
    "#     proj = (proj-mean_out)/std_out\n",
    "\n",
    "#     proj = proj.to(torch.double)\n",
    "#     return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 16, 17, 13, 14]\n",
      "13\n",
      "5\n",
      "[0, 1]\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(input_column_ix)\n",
    "print(input_column_ix[13])\n",
    "print(input_column_ix[5])\n",
    "print(input_column_ix[:2])\n",
    "print(input_column_ix[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "\n",
    "mean_temp = torch.tensor(input_mean[input_column_ix[14]]).to(device)\n",
    "std_temp = torch.tensor(input_std[input_column_ix[14]]).to(device)\n",
    "\n",
    "mean_out = torch.tensor(output_mean).to(device)\n",
    "std_out = torch.tensor(output_std).to(device)\n",
    "    \n",
    "def implicit_diffusion(diff, temp, dt=3600, dx=1, depth_steps=25):\n",
    "    # de-normalise data\n",
    "    diff = diff * std_diff + mean_diff\n",
    "    diff = diff.view(-1, depth_steps)\n",
    "    \n",
    "    # INPUT DATA FROM PREVIOUS MODULE\n",
    "    t = temp * std_temp + mean_temp # temperature profile from previous module output\n",
    "    t = t.view(-1, depth_steps)\n",
    "    \n",
    "    # IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "#     len_t = t.shape[1]\n",
    "    y = torch.zeros((t.shape[0], depth_steps, depth_steps), dtype=torch.float64).to(device)\n",
    "\n",
    "    alpha = (dt/dx**2) * diff\n",
    "\n",
    "    az = - alpha # subdiagonal\n",
    "    bz = 2 * (1 + alpha) # diagonal\n",
    "    cz = - alpha # superdiagonal\n",
    "    \n",
    "    bz[:, 0] = 1\n",
    "    az[:, depth_steps-2] = 0\n",
    "    bz[:, depth_steps-1] = 1\n",
    "    cz[:, 0] = 0\n",
    "    \n",
    "    az = az[:,1:]\n",
    "    cz = cz[:,:-1]\n",
    "\n",
    "    y = torch.diag_embed(bz, offset=0)+torch.diag_embed(az,offset=-1)+torch.diag_embed(cz,offset=1) #slightly efficient way of computing the diagonal matrices\n",
    "    y[:, depth_steps-1, depth_steps-1] = 1\n",
    "    \n",
    "    mn = torch.zeros_like(t)  \n",
    "    mn[:, 0] = t[:, 0]\n",
    "    mn[:,depth_steps-1] = t[:, depth_steps-1]\n",
    "    \n",
    "    mn[:, 1:depth_steps-1] = alpha[:, 1:depth_steps-1]*t[:, :depth_steps-2] + 2 * (1 - alpha[:,1:depth_steps-1])*t[:,1:depth_steps-1] + alpha[:,1:depth_steps-1]*t[:,1:depth_steps-1] #is be same as the loop\n",
    "    \n",
    "    # DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "    proj = torch.linalg.solve(y, mn)\n",
    "\n",
    "    mean, std, var = torch.mean(proj), torch.std(proj), torch.var(proj)\n",
    "    proj = (proj-mean_out)/std_out\n",
    "\n",
    "    proj = proj.to(torch.float32)\n",
    "    proj = proj.view(-1, 1)\n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffusivity_true = torch.tensor(X_train[:,input_column_ix[13]], device=device).unsqueeze(1)\n",
    "# temp_heat_true = torch.tensor(X_train[:,input_column_ix[14]], device=device)#.unsqueeze(1)\n",
    "# mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "# std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "# print(mean_diff, std_diff)\n",
    "\n",
    "# pred = implicit_diffusion(diff=diffusivity_true, \n",
    "#                           temp=temp_heat_true)\n",
    "\n",
    "# print(torch.mean((pred-y_train)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = 20\n",
    "# # print(pred[25*time:25*(time+1)])\n",
    "# # print(y_train[25*time:25*(time+1)])\n",
    "# print((pred[25*time:25*(time+1)]-y_train[25*time:25*(time+1)]).abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test if the Crank-Nicholson scheme works\n",
    "\n",
    "# temp = torch.rand(5,1).to(device)\n",
    "# diff = torch.rand(5,1).to(device)\n",
    "# print(temp), print(diff)\n",
    "# implicit_diffusion(diff, temp, input_mean, input_std,\n",
    "#                                  output_mean, output_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:13<3:50:34, 13.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 0.0012895059671974506, Test_loss: 3.5430852840043592e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [14:59<5:41:19, 21.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 2.4325588217211984e-06, Test_loss: 2.8273812940664467e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [29:57<5:03:08, 20.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Train_loss: 2.3425206907955455e-06, Test_loss: 2.8112684365614722e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 151/1000 [45:12<4:38:46, 19.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 150, Train_loss: 2.324926243399137e-06, Test_loss: 2.82932438093708e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [1:00:13<4:37:26, 20.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 200, Train_loss: 2.2809370050055696e-06, Test_loss: 2.8578008825672952e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 251/1000 [1:15:19<4:04:56, 19.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 250, Train_loss: 2.2634554352865375e-06, Test_loss: 2.8368258332517857e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [1:30:29<4:01:56, 20.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 300, Train_loss: 2.26502240538682e-06, Test_loss: 2.8270985209092396e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 351/1000 [1:45:51<3:39:31, 20.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 350, Train_loss: 2.228868184972924e-06, Test_loss: 2.8546815288316236e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [2:01:04<3:19:45, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400, Train_loss: 2.248168565172257e-06, Test_loss: 2.8538185903181244e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 451/1000 [2:16:24<3:09:20, 20.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 450, Train_loss: 2.2263760367282555e-06, Test_loss: 2.8601937819802513e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [2:31:30<2:48:52, 20.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500, Train_loss: 2.190284560385298e-06, Test_loss: 2.8446904513141055e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 551/1000 [2:46:30<2:28:00, 19.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 550, Train_loss: 2.1936718253802623e-06, Test_loss: 2.85204131741418e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 601/1000 [3:01:40<2:08:23, 19.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600, Train_loss: 2.1709837319241045e-06, Test_loss: 2.8512353925641527e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 651/1000 [3:16:57<1:59:45, 20.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 650, Train_loss: 2.1743455211484336e-06, Test_loss: 2.8444439768216983e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 701/1000 [3:32:01<1:40:52, 20.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 700, Train_loss: 2.1640406795092267e-06, Test_loss: 2.8505790750222417e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 751/1000 [3:46:41<1:27:16, 21.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 750, Train_loss: 2.1799094804998504e-06, Test_loss: 2.8509634070881353e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 801/1000 [3:59:21<19:19,  5.83s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800, Train_loss: 2.1886991253298728e-06, Test_loss: 2.849522146201954e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 851/1000 [4:01:40<07:46,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 850, Train_loss: 2.1727775805135368e-06, Test_loss: 2.8502948245074353e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 901/1000 [4:03:55<05:05,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900, Train_loss: 2.1685975554536704e-06, Test_loss: 2.8479893082828254e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 951/1000 [4:06:09<02:28,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 950, Train_loss: 2.203638974383497e-06, Test_loss: 2.854312461080389e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [4:08:19<00:00, 14.90s/it]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        \n",
    "        # get temperature input\n",
    "        temp_input = x[:,14]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        proj = model(x)\n",
    "        \n",
    "        pred = implicit_diffusion(proj, temp_input)\n",
    "#         pred = pred.to(dtype=torch.float32)\n",
    "        \n",
    "#         print(pred.mean(), y.mean(), pred.std(), y.std())\n",
    "        loss = criterion(pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            temp_input = x[:,14] #* std + mean\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            proj = model(x)\n",
    "\n",
    "            pred = implicit_diffusion(proj, temp_input)\n",
    "\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        \n",
    "        temp_input = x[:,14]\n",
    "        proj = model(x)\n",
    "        pred = implicit_diffusion(proj, temp_input)        \n",
    "        pred = pred.to(dtype=torch.float32)\n",
    "        \n",
    "#         print(torch.mean((pred-y)**2))\n",
    "#         print(y.shape)\n",
    "        \n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        \n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_, pred_)\n",
    "    l2_error_temp = l2_error(y_, pred_)\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 0.009307150131261478\n",
      "L2 Error  of Temp: 0.0006025864670669463\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 0.008142524303035206\n",
      "L2 Error  of Temp: 0.0005310471749693952\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/heat_diffusion_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.30940717])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
