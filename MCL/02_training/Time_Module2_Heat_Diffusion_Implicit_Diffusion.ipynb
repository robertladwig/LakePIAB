{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:3')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device =  torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix03</th>\n",
       "      <th>temp_conv04</th>\n",
       "      <th>temp_initial00</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "      <th>ice</th>\n",
       "      <th>snow</th>\n",
       "      <th>snowice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.220007</td>\n",
       "      <td>590.851292</td>\n",
       "      <td>-30.129462</td>\n",
       "      <td>-35.559056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.757216</td>\n",
       "      <td>0.008038</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.379096</td>\n",
       "      <td>5.402835</td>\n",
       "      <td>5.431685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.220007</td>\n",
       "      <td>590.851292</td>\n",
       "      <td>-30.129462</td>\n",
       "      <td>-35.559056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.757216</td>\n",
       "      <td>0.008038</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.427976</td>\n",
       "      <td>5.429684</td>\n",
       "      <td>5.464454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.220007</td>\n",
       "      <td>590.851292</td>\n",
       "      <td>-30.129462</td>\n",
       "      <td>-35.559056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.757216</td>\n",
       "      <td>0.008038</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.458125</td>\n",
       "      <td>5.452260</td>\n",
       "      <td>5.481707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.220007</td>\n",
       "      <td>590.851292</td>\n",
       "      <td>-30.129462</td>\n",
       "      <td>-35.559056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.757216</td>\n",
       "      <td>0.008038</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.476137</td>\n",
       "      <td>5.452260</td>\n",
       "      <td>5.490656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-1.220007</td>\n",
       "      <td>590.851292</td>\n",
       "      <td>-30.129462</td>\n",
       "      <td>-35.559056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.757216</td>\n",
       "      <td>0.008038</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.486623</td>\n",
       "      <td>5.486623</td>\n",
       "      <td>5.495258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065970</th>\n",
       "      <td>21</td>\n",
       "      <td>3.860010</td>\n",
       "      <td>597.535984</td>\n",
       "      <td>25.682372</td>\n",
       "      <td>36.658380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.709571</td>\n",
       "      <td>0.068577</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>0.478225</td>\n",
       "      <td>0.496168</td>\n",
       "      <td>0.478190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.255083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065971</th>\n",
       "      <td>22</td>\n",
       "      <td>3.860010</td>\n",
       "      <td>597.535984</td>\n",
       "      <td>25.682372</td>\n",
       "      <td>36.658380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.709571</td>\n",
       "      <td>0.068577</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461923</td>\n",
       "      <td>0.483696</td>\n",
       "      <td>0.461851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.255083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065972</th>\n",
       "      <td>23</td>\n",
       "      <td>3.860010</td>\n",
       "      <td>597.535984</td>\n",
       "      <td>25.682372</td>\n",
       "      <td>36.658380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.709571</td>\n",
       "      <td>0.068577</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>0.456284</td>\n",
       "      <td>0.471708</td>\n",
       "      <td>0.456712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.255083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065973</th>\n",
       "      <td>24</td>\n",
       "      <td>3.860010</td>\n",
       "      <td>597.535984</td>\n",
       "      <td>25.682372</td>\n",
       "      <td>36.658380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.709571</td>\n",
       "      <td>0.068577</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.457236</td>\n",
       "      <td>0.456712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.255083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065974</th>\n",
       "      <td>25</td>\n",
       "      <td>3.860010</td>\n",
       "      <td>597.535984</td>\n",
       "      <td>25.682372</td>\n",
       "      <td>36.658380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.709571</td>\n",
       "      <td>0.068577</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>4.151886</td>\n",
       "      <td>4.151886</td>\n",
       "      <td>4.151886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.255083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3065975 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0            1     -1.220007     590.851292   -30.129462     -35.559056   \n",
       "1            2     -1.220007     590.851292   -30.129462     -35.559056   \n",
       "2            3     -1.220007     590.851292   -30.129462     -35.559056   \n",
       "3            4     -1.220007     590.851292   -30.129462     -35.559056   \n",
       "4            5     -1.220007     590.851292   -30.129462     -35.559056   \n",
       "...        ...           ...            ...          ...            ...   \n",
       "3065970     21      3.860010     597.535984    25.682372      36.658380   \n",
       "3065971     22      3.860010     597.535984    25.682372      36.658380   \n",
       "3065972     23      3.860010     597.535984    25.682372      36.658380   \n",
       "3065973     24      3.860010     597.535984    25.682372      36.658380   \n",
       "3065974     25      3.860010     597.535984    25.682372      36.658380   \n",
       "\n",
       "         Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  \\\n",
       "0                   0.0               0.8            1.757216   \n",
       "1                   0.0               0.8            1.757216   \n",
       "2                   0.0               0.8            1.757216   \n",
       "3                   0.0               0.8            1.757216   \n",
       "4                   0.0               0.8            1.757216   \n",
       "...                 ...               ...                 ...   \n",
       "3065970             0.0               0.8            6.709571   \n",
       "3065971             0.0               0.8            6.709571   \n",
       "3065972             0.0               0.8            6.709571   \n",
       "3065973             0.0               0.8            6.709571   \n",
       "3065974             0.0               0.8            6.709571   \n",
       "\n",
       "         ShearStress_Nm-2     Area_m2  ...  day_of_year  time_of_day  \\\n",
       "0                0.008038  36000000.0  ...            1            2   \n",
       "1                0.008038  36000000.0  ...            1            2   \n",
       "2                0.008038  36000000.0  ...            1            2   \n",
       "3                0.008038  36000000.0  ...            1            2   \n",
       "4                0.008038  36000000.0  ...            1            2   \n",
       "...                   ...         ...  ...          ...          ...   \n",
       "3065970          0.068577  36000000.0  ...          363            0   \n",
       "3065971          0.068577  36000000.0  ...          363            0   \n",
       "3065972          0.068577  36000000.0  ...          363            0   \n",
       "3065973          0.068577  36000000.0  ...          363            0   \n",
       "3065974          0.068577  36000000.0  ...          363            0   \n",
       "\n",
       "         temp_mix03  temp_conv04  temp_initial00  obs_temp  input_obs  \\\n",
       "0          5.379096     5.402835        5.431685       NaN        NaN   \n",
       "1          5.427976     5.429684        5.464454       NaN        NaN   \n",
       "2          5.458125     5.452260        5.481707       NaN        NaN   \n",
       "3          5.476137     5.452260        5.490656       NaN        NaN   \n",
       "4          5.486623     5.486623        5.495258       NaN        NaN   \n",
       "...             ...          ...             ...       ...        ...   \n",
       "3065970    0.478225     0.496168        0.478190       NaN        NaN   \n",
       "3065971    0.461923     0.483696        0.461851       NaN        NaN   \n",
       "3065972    0.456284     0.471708        0.456712       NaN        NaN   \n",
       "3065973    0.001672     0.457236        0.456712       NaN        NaN   \n",
       "3065974    4.151886     4.151886        4.151886       NaN        NaN   \n",
       "\n",
       "              ice  snow  snowice  \n",
       "0        0.000000   0.0      0.0  \n",
       "1        0.000000   0.0      0.0  \n",
       "2        0.000000   0.0      0.0  \n",
       "3        0.000000   0.0      0.0  \n",
       "4        0.000000   0.0      0.0  \n",
       "...           ...   ...      ...  \n",
       "3065970  0.255083   0.0      0.0  \n",
       "3065971  0.255083   0.0      0.0  \n",
       "3065972  0.255083   0.0      0.0  \n",
       "3065973  0.255083   0.0      0.0  \n",
       "3065974  0.255083   0.0      0.0  \n",
       "\n",
       "[3065975 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 122639\n",
      "Number of training points: 1839575\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'AirTemp_degC', 'Longwave_Wm-2', 'Latent_Wm-2', 'Sensible_Wm-2', 'Shortwave_Wm-2',\n",
    "                'lightExtinct_m-1', 'ShearVelocity_mS-1', 'ShearStress_Nm-2', 'Area_m2', \n",
    "                 'buoyancy', 'day_of_year', 'time_of_day', 'diffusivity' ,'temp_heat01']\n",
    "output_columns = ['temp_diff02']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1839575, 15), X_test: (1226400, 15)\n",
      "y_train: (1839575, 1), y_test: (1226400, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1000\n",
    "\n",
    "assert batch_size % 25 ==0, \"Batchsize has to be multiple of 25\" \n",
    "\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=15, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "# std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "\n",
    "# mean_temp = torch.tensor(input_mean[input_column_ix[14]]).to(device)\n",
    "# std_temp = torch.tensor(input_std[input_column_ix[14]]).to(device)\n",
    "\n",
    "# mean_out = torch.tensor(output_mean).to(device)\n",
    "# std_out = torch.tensor(output_std).to(device)\n",
    "    \n",
    "# def implicit_diffusion(diff, temp, dt=3600, dx=1, depth_steps=25):\n",
    "#     # de-normalise data\n",
    "#     diff = diff * std_diff + mean_diff\n",
    "\n",
    "#     # INPUT DATA FROM PREVIOUS MODULE\n",
    "#     t = temp * std_temp + mean_temp # temperature profile from previous module output\n",
    "\n",
    "#     # IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "#     j = len(t)\n",
    "#     y = torch.zeros((len(t), len(t)), dtype=torch.float64).to(device)\n",
    "\n",
    "#     alpha = (dt/dx**2) * diff\n",
    "\n",
    "#     az = - alpha # subdiagonal\n",
    "#     bz = 2 * (1 + alpha) # diagonal\n",
    "#     cz = - alpha # superdiagonal\n",
    "\n",
    "#     bz[0] = 1\n",
    "#     az[len(az)-2] = 0\n",
    "#     bz[len(bz)-1] = 1\n",
    "#     cz[0] = 0\n",
    "\n",
    "#     az = az[1:,:]\n",
    "#     cz = cz[:-1,:]\n",
    "\n",
    "#     y = torch.diag(bz[:, 0])+torch.diag(az[:, 0],-1)+torch.diag(cz[:, 0],1) #slightly efficient way of computing the diagonal matrices\n",
    "#     y[j-1, j-1] = 1\n",
    "    \n",
    "#     mn = torch.zeros_like(t)  \n",
    "#     mn[0] = t[0]\n",
    "#     mn[len(mn)-1] = t[len(t)-1]\n",
    "    \n",
    "#     mn[1:j-1] = alpha[1:j-1,0]*t[:j-2] + 2 * (1 - alpha[1:j-1,0])*t[1:j-1] + alpha[1:j-1,0]*t[1:j-1] #is be same as the loop\n",
    "    \n",
    "#     # DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "#     proj = torch.linalg.solve(y, mn)\n",
    "\n",
    "#     mean, std, var = torch.mean(proj), torch.std(proj), torch.var(proj)\n",
    "#     proj = (proj-mean_out)/std_out\n",
    "\n",
    "#     proj = proj.to(torch.double)\n",
    "#     return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 16, 17, 13, 14]\n",
      "13\n",
      "5\n",
      "[0, 1]\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(input_column_ix)\n",
    "print(input_column_ix[13])\n",
    "print(input_column_ix[5])\n",
    "print(input_column_ix[:2])\n",
    "print(input_column_ix[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "\n",
    "mean_temp = torch.tensor(input_mean[input_column_ix[14]]).to(device)\n",
    "std_temp = torch.tensor(input_std[input_column_ix[14]]).to(device)\n",
    "\n",
    "mean_out = torch.tensor(output_mean).to(device)\n",
    "std_out = torch.tensor(output_std).to(device)\n",
    "    \n",
    "def implicit_diffusion(diff, temp, dt=3600, dx=1, depth_steps=25):\n",
    "    # de-normalise data\n",
    "    diff = diff * std_diff + mean_diff\n",
    "    diff = diff.view(-1, depth_steps)\n",
    "    \n",
    "    # INPUT DATA FROM PREVIOUS MODULE\n",
    "    t = temp * std_temp + mean_temp # temperature profile from previous module output\n",
    "    t = t.view(-1, depth_steps)\n",
    "    \n",
    "    # IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "#     len_t = t.shape[1]\n",
    "    y = torch.zeros((t.shape[0], depth_steps, depth_steps), dtype=torch.float64).to(device)\n",
    "\n",
    "    alpha = (dt/dx**2) * diff\n",
    "\n",
    "    az = - alpha # subdiagonal\n",
    "    bz = 2 * (1 + alpha) # diagonal\n",
    "    cz = - alpha # superdiagonal\n",
    "    \n",
    "    bz[:, 0] = 1\n",
    "    az[:, depth_steps-2] = 0\n",
    "    bz[:, depth_steps-1] = 1\n",
    "    cz[:, 0] = 0\n",
    "    \n",
    "    az = az[:,1:]\n",
    "    cz = cz[:,:-1]\n",
    "\n",
    "    y = torch.diag_embed(bz, offset=0)+torch.diag_embed(az,offset=-1)+torch.diag_embed(cz,offset=1) #slightly efficient way of computing the diagonal matrices\n",
    "    y[:, depth_steps-1, depth_steps-1] = 1\n",
    "    \n",
    "    mn = torch.zeros_like(t)  \n",
    "    mn[:, 0] = t[:, 0]\n",
    "    mn[:,depth_steps-1] = t[:, depth_steps-1]\n",
    "    \n",
    "    mn[:, 1:depth_steps-1] = alpha[:, 1:depth_steps-1]*t[:, :depth_steps-2] + 2 * (1 - alpha[:,1:depth_steps-1])*t[:,1:depth_steps-1] + alpha[:,1:depth_steps-1]*t[:,1:depth_steps-1] #is be same as the loop\n",
    "    \n",
    "    # DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "    proj = torch.linalg.solve(y, mn)\n",
    "\n",
    "    mean, std, var = torch.mean(proj), torch.std(proj), torch.var(proj)\n",
    "    proj = (proj-mean_out)/std_out\n",
    "\n",
    "    proj = proj.to(torch.float32)\n",
    "    proj = proj.view(-1, 1)\n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffusivity_true = torch.tensor(X_train[:,input_column_ix[13]], device=device).unsqueeze(1)\n",
    "# temp_heat_true = torch.tensor(X_train[:,input_column_ix[14]], device=device)#.unsqueeze(1)\n",
    "# mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "# std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "# print(mean_diff, std_diff)\n",
    "\n",
    "# pred = implicit_diffusion(diff=diffusivity_true, \n",
    "#                           temp=temp_heat_true)\n",
    "\n",
    "# print(torch.mean((pred-y_train)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = 20\n",
    "# # print(pred[25*time:25*(time+1)])\n",
    "# # print(y_train[25*time:25*(time+1)])\n",
    "# print((pred[25*time:25*(time+1)]-y_train[25*time:25*(time+1)]).abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test if the Crank-Nicholson scheme works\n",
    "\n",
    "# temp = torch.rand(5,1).to(device)\n",
    "# diff = torch.rand(5,1).to(device)\n",
    "# print(temp), print(diff)\n",
    "# implicit_diffusion(diff, temp, input_mean, input_std,\n",
    "#                                  output_mean, output_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:50<14:09:00, 50.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 0.006745448468743986, Test_loss: 0.007290090857035571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [31:01<10:40:28, 40.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 0.005024232218768346, Test_loss: 0.008164587088914248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [1:01:18<10:02:25, 40.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Train_loss: 0.005023297204815722, Test_loss: 0.008290868536527194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 151/1000 [1:31:25<9:26:07, 40.01s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 150, Train_loss: 0.005009254741573544, Test_loss: 0.008219132633570858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [2:01:24<8:53:25, 40.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 200, Train_loss: 0.005012210329068298, Test_loss: 0.008268047549215738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 251/1000 [2:29:43<8:46:30, 42.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 250, Train_loss: 0.005027219290850158, Test_loss: 0.008156617628170654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [3:00:36<7:51:48, 40.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 300, Train_loss: 0.0050093894900941375, Test_loss: 0.008139099802450617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 351/1000 [3:30:54<7:21:57, 40.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 350, Train_loss: 0.005018954512691024, Test_loss: 0.008148948072959555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [4:00:58<6:47:55, 40.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400, Train_loss: 0.005030332944411582, Test_loss: 0.008184686205980682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 451/1000 [4:23:31<3:52:45, 25.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 450, Train_loss: 0.004999415729790875, Test_loss: 0.0081612716219688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [4:42:25<3:32:04, 25.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500, Train_loss: 0.00502276668969147, Test_loss: 0.008207109307259444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 551/1000 [5:01:12<3:10:05, 25.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 550, Train_loss: 0.00502236225052595, Test_loss: 0.00819369797338817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 601/1000 [5:20:07<2:50:44, 25.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600, Train_loss: 0.0049754183772323735, Test_loss: 0.00821887630300728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 651/1000 [5:38:49<2:29:19, 25.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 650, Train_loss: 0.005045181782612496, Test_loss: 0.008182296785019567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 701/1000 [5:57:44<2:09:43, 26.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 700, Train_loss: 0.0050134092957191375, Test_loss: 0.00820848687516621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 751/1000 [6:16:26<1:45:56, 25.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 750, Train_loss: 0.005028390025773146, Test_loss: 0.008207147625799655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 801/1000 [6:35:26<1:26:46, 26.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800, Train_loss: 0.005008736809616929, Test_loss: 0.008193324034886143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 851/1000 [6:54:12<1:03:07, 25.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 850, Train_loss: 0.005017931421120327, Test_loss: 0.008193605072938448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 901/1000 [7:13:08<42:13, 25.59s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900, Train_loss: 0.005003622521927236, Test_loss: 0.008213915795132478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 951/1000 [7:31:56<20:45, 25.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 950, Train_loss: 0.005005375336939165, Test_loss: 0.008198308157999164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [7:50:16<00:00, 28.22s/it]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        \n",
    "        # get temperature input\n",
    "        temp_input = x[:,14]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        proj = model(x)\n",
    "        \n",
    "        pred = implicit_diffusion(proj, temp_input)\n",
    "#         pred = pred.to(dtype=torch.float32)\n",
    "        \n",
    "#         print(pred.mean(), y.mean(), pred.std(), y.std())\n",
    "        loss = criterion(pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            temp_input = x[:,14] #* std + mean\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            proj = model(x)\n",
    "\n",
    "            pred = implicit_diffusion(proj, temp_input)\n",
    "\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        \n",
    "        temp_input = x[:,14]\n",
    "        proj = model(x)\n",
    "        pred = implicit_diffusion(proj, temp_input)        \n",
    "        pred = pred.to(dtype=torch.float32)\n",
    "        \n",
    "#         print(torch.mean((pred-y)**2))\n",
    "#         print(y.shape)\n",
    "        \n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        \n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_, pred_)\n",
    "    l2_error_temp = l2_error(y_, pred_)\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 0.5987123966827401\n",
      "L2 Error  of Temp: 0.05843629116334848\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 0.4678005875868935\n",
      "L2 Error  of Temp: 0.048724301194336794\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/heat_diffusion_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.96297147])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
