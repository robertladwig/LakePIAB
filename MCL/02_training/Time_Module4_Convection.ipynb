{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:2')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>diffusivity</th>\n",
       "      <th>temp_heat01</th>\n",
       "      <th>temp_diff02</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix03</th>\n",
       "      <th>temp_conv04</th>\n",
       "      <th>temp_initial00</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.416676</td>\n",
       "      <td>15.416676</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.426904</td>\n",
       "      <td>15.426904</td>\n",
       "      <td>15.489510</td>\n",
       "      <td>22.279</td>\n",
       "      <td>22.279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>15.448083</td>\n",
       "      <td>15.437735</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.401481</td>\n",
       "      <td>15.401481</td>\n",
       "      <td>15.448078</td>\n",
       "      <td>22.295</td>\n",
       "      <td>22.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>15.376622</td>\n",
       "      <td>15.374550</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.346109</td>\n",
       "      <td>15.346109</td>\n",
       "      <td>15.376617</td>\n",
       "      <td>22.091</td>\n",
       "      <td>22.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>15.287991</td>\n",
       "      <td>15.287547</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.272596</td>\n",
       "      <td>15.272596</td>\n",
       "      <td>15.287987</td>\n",
       "      <td>22.296</td>\n",
       "      <td>22.296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>15.195124</td>\n",
       "      <td>15.195829</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.193004</td>\n",
       "      <td>15.193004</td>\n",
       "      <td>15.195121</td>\n",
       "      <td>22.231</td>\n",
       "      <td>22.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495570</th>\n",
       "      <td>21</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>8.373718</td>\n",
       "      <td>8.375543</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>8.375543</td>\n",
       "      <td>8.375543</td>\n",
       "      <td>8.373683</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495571</th>\n",
       "      <td>22</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>7.324853</td>\n",
       "      <td>7.326184</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>7.326184</td>\n",
       "      <td>7.326184</td>\n",
       "      <td>7.324806</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495572</th>\n",
       "      <td>23</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>6.297841</td>\n",
       "      <td>6.298671</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>6.298671</td>\n",
       "      <td>6.298671</td>\n",
       "      <td>6.297760</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495573</th>\n",
       "      <td>24</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>5.282023</td>\n",
       "      <td>5.282477</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.282477</td>\n",
       "      <td>5.282477</td>\n",
       "      <td>5.282023</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495574</th>\n",
       "      <td>25</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495575 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0           1     13.965021     717.887954   -32.080993      -6.880394   \n",
       "1           2     13.965021     717.887954   -32.080993      -6.880394   \n",
       "2           3     13.965021     717.887954   -32.080993      -6.880394   \n",
       "3           4     13.965021     717.887954   -32.080993      -6.880394   \n",
       "4           5     13.965021     717.887954   -32.080993      -6.880394   \n",
       "...       ...           ...            ...          ...            ...   \n",
       "495570     21     17.945001     796.182785   -59.448422     -13.843945   \n",
       "495571     22     17.945001     796.182785   -59.448422     -13.843945   \n",
       "495572     23     17.945001     796.182785   -59.448422     -13.843945   \n",
       "495573     24     17.945001     796.182785   -59.448422     -13.843945   \n",
       "495574     25     17.945001     796.182785   -59.448422     -13.843945   \n",
       "\n",
       "        Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  \\\n",
       "0                  0.0               0.8            1.803546   \n",
       "1                  0.0               0.8            1.803546   \n",
       "2                  0.0               0.8            1.803546   \n",
       "3                  0.0               0.8            1.803546   \n",
       "4                  0.0               0.8            1.803546   \n",
       "...                ...               ...                 ...   \n",
       "495570             0.0               0.8            0.322170   \n",
       "495571             0.0               0.8            0.322170   \n",
       "495572             0.0               0.8            0.322170   \n",
       "495573             0.0               0.8            0.322170   \n",
       "495574             0.0               0.8            0.322170   \n",
       "\n",
       "        ShearStress_Nm-2     Area_m2  ...  diffusivity  temp_heat01  \\\n",
       "0               0.008386  36000000.0  ...     0.000037    15.416676   \n",
       "1               0.008386  36000000.0  ...     0.000031    15.448083   \n",
       "2               0.008386  36000000.0  ...     0.000028    15.376622   \n",
       "3               0.008386  36000000.0  ...     0.000028    15.287991   \n",
       "4               0.008386  36000000.0  ...     0.000029    15.195124   \n",
       "...                  ...         ...  ...          ...          ...   \n",
       "495570          0.000534  36000000.0  ...     0.000015     8.373718   \n",
       "495571          0.000534  36000000.0  ...     0.000017     7.324853   \n",
       "495572          0.000534  36000000.0  ...     0.000020     6.297841   \n",
       "495573          0.000534  36000000.0  ...     0.000029     5.282023   \n",
       "495574          0.000534  36000000.0  ...     0.000029     4.270583   \n",
       "\n",
       "        temp_diff02  day_of_year  time_of_day  temp_mix03  temp_conv04  \\\n",
       "0         15.416676          155            1   15.426904    15.426904   \n",
       "1         15.437735          155            1   15.401481    15.401481   \n",
       "2         15.374550          155            1   15.346109    15.346109   \n",
       "3         15.287547          155            1   15.272596    15.272596   \n",
       "4         15.195829          155            1   15.193004    15.193004   \n",
       "...             ...          ...          ...         ...          ...   \n",
       "495570     8.375543          213           23    8.375543     8.375543   \n",
       "495571     7.326184          213           23    7.326184     7.326184   \n",
       "495572     6.298671          213           23    6.298671     6.298671   \n",
       "495573     5.282477          213           23    5.282477     5.282477   \n",
       "495574     4.270583          213           23    4.270583     4.270583   \n",
       "\n",
       "        temp_initial00  obs_temp  input_obs  \n",
       "0            15.489510    22.279     22.279  \n",
       "1            15.448078    22.295     22.295  \n",
       "2            15.376617    22.091     22.091  \n",
       "3            15.287987    22.296     22.296  \n",
       "4            15.195121    22.231     22.231  \n",
       "...                ...       ...        ...  \n",
       "495570        8.373683    11.099     11.099  \n",
       "495571        7.324806    11.099     11.099  \n",
       "495572        6.297760    11.099     11.099  \n",
       "495573        5.282023    11.099     11.099  \n",
       "495574        4.270583    11.099     11.099  \n",
       "\n",
       "[495575 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 19823\n",
      "Number of training points: 297325\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'day_of_year', 'time_of_day', 'temp_mix03']\n",
    "output_columns = ['temp_conv04']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (297325, 4), X_test: (198250, 4)\n",
      "y_train: (297325, 1), y_test: (198250, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1024\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=4, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:16<4:40:07, 16.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 0.1046494336357129, Test_loss: 0.001269471990565659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [11:50<4:22:01, 16.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 1.6572218330636423e-06, Test_loss: 5.488162302529033e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [23:29<4:02:14, 16.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Train_loss: 1.5498551895671971e-06, Test_loss: 1.0535474203192696e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 151/1000 [35:20<3:36:32, 15.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 150, Train_loss: 1.8176635971182502e-06, Test_loss: 1.1276855512983979e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [46:55<3:33:21, 16.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 200, Train_loss: 1.2291969875006475e-06, Test_loss: 1.1133851915658233e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 251/1000 [58:32<3:15:38, 15.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 250, Train_loss: 1.4885103270838034e-06, Test_loss: 1.136265452184381e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [1:10:22<3:07:43, 16.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 300, Train_loss: 1.4980911487913845e-06, Test_loss: 2.1481011355938122e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 351/1000 [1:22:19<2:56:58, 16.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 350, Train_loss: 1.1555500635171784e-06, Test_loss: 1.1947044002522255e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [1:34:03<2:40:24, 16.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400, Train_loss: 1.2515530642369562e-06, Test_loss: 1.1904175583604509e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 451/1000 [1:46:09<2:25:37, 15.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 450, Train_loss: 1.4795769473265993e-06, Test_loss: 1.8832129586247357e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [1:58:16<2:15:05, 16.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500, Train_loss: 6.9180735518516e-07, Test_loss: 8.455919496887561e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 551/1000 [2:10:18<1:55:46, 15.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 550, Train_loss: 7.247544232997569e-07, Test_loss: 8.619649120927201e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 601/1000 [2:22:14<1:51:12, 16.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600, Train_loss: 7.133074800088368e-07, Test_loss: 8.382605637162205e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 651/1000 [2:33:56<1:28:19, 15.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 650, Train_loss: 7.090580814728475e-07, Test_loss: 8.800459240427003e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 701/1000 [2:45:44<1:20:01, 16.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 700, Train_loss: 6.991149138334658e-07, Test_loss: 8.379691095243973e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 751/1000 [2:57:51<1:05:59, 15.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 750, Train_loss: 7.125859140449274e-07, Test_loss: 8.145166867119272e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 801/1000 [3:09:47<52:06, 15.71s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800, Train_loss: 7.072907463286365e-07, Test_loss: 9.177435150891799e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 851/1000 [3:21:50<42:58, 17.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 850, Train_loss: 6.988925875996778e-07, Test_loss: 8.352813432719938e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 901/1000 [3:33:55<27:25, 16.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900, Train_loss: 6.941723866700543e-07, Test_loss: 8.071467689774181e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 951/1000 [3:45:37<12:27, 15.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 950, Train_loss: 6.969157808432079e-07, Test_loss: 8.422426087055012e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [3:56:57<00:00, 14.22s/it]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_[:,0], pred_[:,0])\n",
    "    \n",
    "    l2_error_temp = l2_error(y_[:,0], pred_[:,0])\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 0.004928978170999525\n",
      "L2 Error  of Temp: 0.0003191028594751019\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 0.00454317937925632\n",
      "L2 Error  of Temp: 0.0002962804542535063\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/convection_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.31060277])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
