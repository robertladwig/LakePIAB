{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:2')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>diffusivity</th>\n",
       "      <th>temp_heat01</th>\n",
       "      <th>temp_diff02</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix03</th>\n",
       "      <th>temp_conv04</th>\n",
       "      <th>temp_initial00</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.416676</td>\n",
       "      <td>15.416676</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.426904</td>\n",
       "      <td>15.426904</td>\n",
       "      <td>15.489510</td>\n",
       "      <td>22.279</td>\n",
       "      <td>22.279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>15.448083</td>\n",
       "      <td>15.437735</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.401481</td>\n",
       "      <td>15.401481</td>\n",
       "      <td>15.448078</td>\n",
       "      <td>22.295</td>\n",
       "      <td>22.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>15.376622</td>\n",
       "      <td>15.374550</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.346109</td>\n",
       "      <td>15.346109</td>\n",
       "      <td>15.376617</td>\n",
       "      <td>22.091</td>\n",
       "      <td>22.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>15.287991</td>\n",
       "      <td>15.287547</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.272596</td>\n",
       "      <td>15.272596</td>\n",
       "      <td>15.287987</td>\n",
       "      <td>22.296</td>\n",
       "      <td>22.296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13.965021</td>\n",
       "      <td>717.887954</td>\n",
       "      <td>-32.080993</td>\n",
       "      <td>-6.880394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.803546</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>15.195124</td>\n",
       "      <td>15.195829</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>15.193004</td>\n",
       "      <td>15.193004</td>\n",
       "      <td>15.195121</td>\n",
       "      <td>22.231</td>\n",
       "      <td>22.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495570</th>\n",
       "      <td>21</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>8.373718</td>\n",
       "      <td>8.375543</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>8.375543</td>\n",
       "      <td>8.375543</td>\n",
       "      <td>8.373683</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495571</th>\n",
       "      <td>22</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>7.324853</td>\n",
       "      <td>7.326184</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>7.326184</td>\n",
       "      <td>7.326184</td>\n",
       "      <td>7.324806</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495572</th>\n",
       "      <td>23</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>6.297841</td>\n",
       "      <td>6.298671</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>6.298671</td>\n",
       "      <td>6.298671</td>\n",
       "      <td>6.297760</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495573</th>\n",
       "      <td>24</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>5.282023</td>\n",
       "      <td>5.282477</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.282477</td>\n",
       "      <td>5.282477</td>\n",
       "      <td>5.282023</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495574</th>\n",
       "      <td>25</td>\n",
       "      <td>17.945001</td>\n",
       "      <td>796.182785</td>\n",
       "      <td>-59.448422</td>\n",
       "      <td>-13.843945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.322170</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>4.270583</td>\n",
       "      <td>11.099</td>\n",
       "      <td>11.099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495575 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0           1     13.965021     717.887954   -32.080993      -6.880394   \n",
       "1           2     13.965021     717.887954   -32.080993      -6.880394   \n",
       "2           3     13.965021     717.887954   -32.080993      -6.880394   \n",
       "3           4     13.965021     717.887954   -32.080993      -6.880394   \n",
       "4           5     13.965021     717.887954   -32.080993      -6.880394   \n",
       "...       ...           ...            ...          ...            ...   \n",
       "495570     21     17.945001     796.182785   -59.448422     -13.843945   \n",
       "495571     22     17.945001     796.182785   -59.448422     -13.843945   \n",
       "495572     23     17.945001     796.182785   -59.448422     -13.843945   \n",
       "495573     24     17.945001     796.182785   -59.448422     -13.843945   \n",
       "495574     25     17.945001     796.182785   -59.448422     -13.843945   \n",
       "\n",
       "        Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  \\\n",
       "0                  0.0               0.8            1.803546   \n",
       "1                  0.0               0.8            1.803546   \n",
       "2                  0.0               0.8            1.803546   \n",
       "3                  0.0               0.8            1.803546   \n",
       "4                  0.0               0.8            1.803546   \n",
       "...                ...               ...                 ...   \n",
       "495570             0.0               0.8            0.322170   \n",
       "495571             0.0               0.8            0.322170   \n",
       "495572             0.0               0.8            0.322170   \n",
       "495573             0.0               0.8            0.322170   \n",
       "495574             0.0               0.8            0.322170   \n",
       "\n",
       "        ShearStress_Nm-2     Area_m2  ...  diffusivity  temp_heat01  \\\n",
       "0               0.008386  36000000.0  ...     0.000037    15.416676   \n",
       "1               0.008386  36000000.0  ...     0.000031    15.448083   \n",
       "2               0.008386  36000000.0  ...     0.000028    15.376622   \n",
       "3               0.008386  36000000.0  ...     0.000028    15.287991   \n",
       "4               0.008386  36000000.0  ...     0.000029    15.195124   \n",
       "...                  ...         ...  ...          ...          ...   \n",
       "495570          0.000534  36000000.0  ...     0.000015     8.373718   \n",
       "495571          0.000534  36000000.0  ...     0.000017     7.324853   \n",
       "495572          0.000534  36000000.0  ...     0.000020     6.297841   \n",
       "495573          0.000534  36000000.0  ...     0.000029     5.282023   \n",
       "495574          0.000534  36000000.0  ...     0.000029     4.270583   \n",
       "\n",
       "        temp_diff02  day_of_year  time_of_day  temp_mix03  temp_conv04  \\\n",
       "0         15.416676          155            1   15.426904    15.426904   \n",
       "1         15.437735          155            1   15.401481    15.401481   \n",
       "2         15.374550          155            1   15.346109    15.346109   \n",
       "3         15.287547          155            1   15.272596    15.272596   \n",
       "4         15.195829          155            1   15.193004    15.193004   \n",
       "...             ...          ...          ...         ...          ...   \n",
       "495570     8.375543          213           23    8.375543     8.375543   \n",
       "495571     7.326184          213           23    7.326184     7.326184   \n",
       "495572     6.298671          213           23    6.298671     6.298671   \n",
       "495573     5.282477          213           23    5.282477     5.282477   \n",
       "495574     4.270583          213           23    4.270583     4.270583   \n",
       "\n",
       "        temp_initial00  obs_temp  input_obs  \n",
       "0            15.489510    22.279     22.279  \n",
       "1            15.448078    22.295     22.295  \n",
       "2            15.376617    22.091     22.091  \n",
       "3            15.287987    22.296     22.296  \n",
       "4            15.195121    22.231     22.231  \n",
       "...                ...       ...        ...  \n",
       "495570        8.373683    11.099     11.099  \n",
       "495571        7.324806    11.099     11.099  \n",
       "495572        6.297760    11.099     11.099  \n",
       "495573        5.282023    11.099     11.099  \n",
       "495574        4.270583    11.099     11.099  \n",
       "\n",
       "[495575 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 19823\n",
      "Number of training points: 297325\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'ShearVelocity_mS-1', 'ShearStress_Nm-2', 'day_of_year', 'time_of_day', 'temp_diff02']\n",
    "output_columns = ['temp_mix03']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (297325, 6), X_test: (198250, 6)\n",
      "y_train: (297325, 1), y_test: (198250, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1024\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=6, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:13<3:41:03, 13.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 0.04219935259312116, Test_loss: 0.0008263760967931431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [12:22<4:24:01, 16.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 8.438430515675417e-05, Test_loss: 7.685079349029525e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [24:32<4:10:15, 16.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Train_loss: 8.208160663431245e-05, Test_loss: 7.654878512316968e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 151/1000 [36:44<4:05:42, 17.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 150, Train_loss: 8.113245610704788e-05, Test_loss: 7.522389693204065e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [48:36<3:33:46, 16.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 200, Train_loss: 8.088478546650021e-05, Test_loss: 8.125626534810809e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 251/1000 [1:00:41<3:34:22, 17.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 250, Train_loss: 8.099285433357109e-05, Test_loss: 7.479455223815843e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [1:12:21<3:08:42, 16.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 300, Train_loss: 7.993666341209654e-05, Test_loss: 7.94597187131771e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 351/1000 [1:24:18<3:02:57, 16.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 350, Train_loss: 7.871224168667857e-05, Test_loss: 7.481892234793741e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [1:36:29<2:56:11, 17.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400, Train_loss: 7.78770478326496e-05, Test_loss: 7.465783520255519e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 451/1000 [1:48:40<2:30:04, 16.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 450, Train_loss: 7.714101210416774e-05, Test_loss: 7.416341685777447e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [2:00:32<2:15:05, 16.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500, Train_loss: 7.377123741510634e-05, Test_loss: 7.011981146611903e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 551/1000 [2:13:03<2:14:27, 17.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 550, Train_loss: 7.356167704663464e-05, Test_loss: 7.011067217068633e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 601/1000 [2:25:04<1:47:29, 16.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600, Train_loss: 7.361390248895743e-05, Test_loss: 7.034883230913299e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 651/1000 [2:37:04<1:33:46, 16.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 650, Train_loss: 7.34800003656315e-05, Test_loss: 7.016292867197971e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 701/1000 [2:48:54<1:19:26, 15.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 700, Train_loss: 7.331828024358164e-05, Test_loss: 7.014507329267403e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 751/1000 [3:01:21<1:09:22, 16.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 750, Train_loss: 7.318298696216054e-05, Test_loss: 6.989508584603154e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 801/1000 [3:13:14<56:03, 16.90s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800, Train_loss: 7.30346866188346e-05, Test_loss: 6.98488501873576e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 851/1000 [3:25:28<39:08, 15.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 850, Train_loss: 7.313589522050201e-05, Test_loss: 6.957103943777744e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 901/1000 [3:37:27<27:17, 16.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900, Train_loss: 7.296471859759906e-05, Test_loss: 6.958114468924924e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 951/1000 [3:49:46<13:51, 16.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 950, Train_loss: 7.298947020524455e-05, Test_loss: 6.945634953171037e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [3:59:17<00:00, 14.36s/it]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_[:,0], pred_[:,0])\n",
    "    \n",
    "    l2_error_temp = l2_error(y_[:,0], pred_[:,0])\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 0.04598526644572595\n",
      "L2 Error  of Temp: 0.0029770726578738165\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 0.04697958909075463\n",
      "L2 Error  of Temp: 0.0030637252883438364\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/mixing_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.31067016])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
