{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ladwi\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:2')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix03</th>\n",
       "      <th>temp_conv04</th>\n",
       "      <th>temp_initial00</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "      <th>ice</th>\n",
       "      <th>snow</th>\n",
       "      <th>snowice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-10.049883</td>\n",
       "      <td>493.493435</td>\n",
       "      <td>-62.756461</td>\n",
       "      <td>-104.669918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.127760e-10</td>\n",
       "      <td>4.127760e-10</td>\n",
       "      <td>1.356178e-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136942</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-10.049883</td>\n",
       "      <td>493.493435</td>\n",
       "      <td>-62.756461</td>\n",
       "      <td>-104.669918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.063974e-01</td>\n",
       "      <td>1.063974e-01</td>\n",
       "      <td>2.019853e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136942</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-10.049883</td>\n",
       "      <td>493.493435</td>\n",
       "      <td>-62.756461</td>\n",
       "      <td>-104.669918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.332566e-01</td>\n",
       "      <td>2.332566e-01</td>\n",
       "      <td>1.994957e-02</td>\n",
       "      <td>6.016256</td>\n",
       "      <td>6.018909</td>\n",
       "      <td>0.136942</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-10.049883</td>\n",
       "      <td>493.493435</td>\n",
       "      <td>-62.756461</td>\n",
       "      <td>-104.669918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.605703e-01</td>\n",
       "      <td>3.605703e-01</td>\n",
       "      <td>1.924648e-02</td>\n",
       "      <td>6.068845</td>\n",
       "      <td>6.071542</td>\n",
       "      <td>0.136942</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-10.049883</td>\n",
       "      <td>493.493435</td>\n",
       "      <td>-62.756461</td>\n",
       "      <td>-104.669918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.726815e-01</td>\n",
       "      <td>4.726815e-01</td>\n",
       "      <td>3.375901e-02</td>\n",
       "      <td>6.124844</td>\n",
       "      <td>6.127587</td>\n",
       "      <td>0.136942</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751195</th>\n",
       "      <td>46</td>\n",
       "      <td>-12.920028</td>\n",
       "      <td>494.226632</td>\n",
       "      <td>-46.982710</td>\n",
       "      <td>-95.220702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.066941e+00</td>\n",
       "      <td>4.066941e+00</td>\n",
       "      <td>4.066863e+00</td>\n",
       "      <td>3.029762</td>\n",
       "      <td>3.030952</td>\n",
       "      <td>0.475050</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751196</th>\n",
       "      <td>47</td>\n",
       "      <td>-12.920028</td>\n",
       "      <td>494.226632</td>\n",
       "      <td>-46.982710</td>\n",
       "      <td>-95.220702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.172542e+00</td>\n",
       "      <td>4.172542e+00</td>\n",
       "      <td>4.172443e+00</td>\n",
       "      <td>3.185105</td>\n",
       "      <td>3.189226</td>\n",
       "      <td>0.475050</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751197</th>\n",
       "      <td>48</td>\n",
       "      <td>-12.920028</td>\n",
       "      <td>494.226632</td>\n",
       "      <td>-46.982710</td>\n",
       "      <td>-95.220702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.282669e+00</td>\n",
       "      <td>4.282669e+00</td>\n",
       "      <td>4.282541e+00</td>\n",
       "      <td>4.005785</td>\n",
       "      <td>4.009906</td>\n",
       "      <td>0.475050</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751198</th>\n",
       "      <td>49</td>\n",
       "      <td>-12.920028</td>\n",
       "      <td>494.226632</td>\n",
       "      <td>-46.982710</td>\n",
       "      <td>-95.220702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.386953e+00</td>\n",
       "      <td>4.386953e+00</td>\n",
       "      <td>4.386816e+00</td>\n",
       "      <td>4.826464</td>\n",
       "      <td>4.830586</td>\n",
       "      <td>0.475050</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751199</th>\n",
       "      <td>50</td>\n",
       "      <td>-12.920028</td>\n",
       "      <td>494.226632</td>\n",
       "      <td>-46.982710</td>\n",
       "      <td>-95.220702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.503658e+00</td>\n",
       "      <td>4.503658e+00</td>\n",
       "      <td>4.503485e+00</td>\n",
       "      <td>7.996234</td>\n",
       "      <td>7.998070</td>\n",
       "      <td>0.475050</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>751200 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0           1    -10.049883     493.493435   -62.756461    -104.669918   \n",
       "1           2    -10.049883     493.493435   -62.756461    -104.669918   \n",
       "2           3    -10.049883     493.493435   -62.756461    -104.669918   \n",
       "3           4    -10.049883     493.493435   -62.756461    -104.669918   \n",
       "4           5    -10.049883     493.493435   -62.756461    -104.669918   \n",
       "...       ...           ...            ...          ...            ...   \n",
       "751195     46    -12.920028     494.226632   -46.982710     -95.220702   \n",
       "751196     47    -12.920028     494.226632   -46.982710     -95.220702   \n",
       "751197     48    -12.920028     494.226632   -46.982710     -95.220702   \n",
       "751198     49    -12.920028     494.226632   -46.982710     -95.220702   \n",
       "751199     50    -12.920028     494.226632   -46.982710     -95.220702   \n",
       "\n",
       "        Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  \\\n",
       "0                  0.0               0.4              -999.0   \n",
       "1                  0.0               0.4              -999.0   \n",
       "2                  0.0               0.4              -999.0   \n",
       "3                  0.0               0.4              -999.0   \n",
       "4                  0.0               0.4              -999.0   \n",
       "...                ...               ...                 ...   \n",
       "751195             0.0               0.4              -999.0   \n",
       "751196             0.0               0.4              -999.0   \n",
       "751197             0.0               0.4              -999.0   \n",
       "751198             0.0               0.4              -999.0   \n",
       "751199             0.0               0.4              -999.0   \n",
       "\n",
       "        ShearStress_Nm-2     Area_m2  ...  day_of_year  time_of_day  \\\n",
       "0                 -999.0  39850000.0  ...            3            0   \n",
       "1                 -999.0  39850000.0  ...            3            0   \n",
       "2                 -999.0  39850000.0  ...            3            0   \n",
       "3                 -999.0  39850000.0  ...            3            0   \n",
       "4                 -999.0  39850000.0  ...            3            0   \n",
       "...                  ...         ...  ...          ...          ...   \n",
       "751195            -999.0  39850000.0  ...          362           23   \n",
       "751196            -999.0  39850000.0  ...          362           23   \n",
       "751197            -999.0  39850000.0  ...          362           23   \n",
       "751198            -999.0  39850000.0  ...          362           23   \n",
       "751199            -999.0  39850000.0  ...          362           23   \n",
       "\n",
       "          temp_mix03   temp_conv04  temp_initial00  obs_temp  input_obs  \\\n",
       "0       4.127760e-10  4.127760e-10    1.356178e-09  0.000000   0.000000   \n",
       "1       1.063974e-01  1.063974e-01    2.019853e-02  0.000000   0.000000   \n",
       "2       2.332566e-01  2.332566e-01    1.994957e-02  6.016256   6.018909   \n",
       "3       3.605703e-01  3.605703e-01    1.924648e-02  6.068845   6.071542   \n",
       "4       4.726815e-01  4.726815e-01    3.375901e-02  6.124844   6.127587   \n",
       "...              ...           ...             ...       ...        ...   \n",
       "751195  4.066941e+00  4.066941e+00    4.066863e+00  3.029762   3.030952   \n",
       "751196  4.172542e+00  4.172542e+00    4.172443e+00  3.185105   3.189226   \n",
       "751197  4.282669e+00  4.282669e+00    4.282541e+00  4.005785   4.009906   \n",
       "751198  4.386953e+00  4.386953e+00    4.386816e+00  4.826464   4.830586   \n",
       "751199  4.503658e+00  4.503658e+00    4.503485e+00  7.996234   7.998070   \n",
       "\n",
       "             ice     snow  snowice  \n",
       "0       0.136942  0.00000      0.0  \n",
       "1       0.136942  0.00000      0.0  \n",
       "2       0.136942  0.00000      0.0  \n",
       "3       0.136942  0.00000      0.0  \n",
       "4       0.136942  0.00000      0.0  \n",
       "...          ...      ...      ...  \n",
       "751195  0.475050  0.00527      0.0  \n",
       "751196  0.475050  0.00527      0.0  \n",
       "751197  0.475050  0.00527      0.0  \n",
       "751198  0.475050  0.00527      0.0  \n",
       "751199  0.475050  0.00527      0.0  \n",
       "\n",
       "[751200 rows x 45 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time_reduced.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 30048\n",
      "Number of training points: 450700\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'AirTemp_degC',   'Shortwave_Wm-2',\n",
    "                'lightExtinct_m-1','Area_m2', 'Uw',\n",
    "                 'day_of_year', 'time_of_day'] #,  \n",
    "               #  'buoyancy', 'diffusivity', 'temp_initial00', \n",
    "               # 'temp_heat01', 'temp_diff02', 'temp_total05',\n",
    "               # 'ice', 'snow', 'snowice'\n",
    "output_columns = ['obs_temp']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (450700, 8), X_test: (300500, 8)\n",
      "y_train: (450700, 1), y_test: (300500, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1024\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32,32,32,32,32,32,32,32,32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=8, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_2): GELU()\n",
      "    (layer_3): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_3): GELU()\n",
      "    (layer_4): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_4): GELU()\n",
      "    (layer_5): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_5): GELU()\n",
      "    (layer_6): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_6): GELU()\n",
      "    (layer_7): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_7): GELU()\n",
      "    (layer_8): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_8): GELU()\n",
      "    (layer_9): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_9): GELU()\n",
      "    (layer_10): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:06<1:49:12,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 0.1856112566326751, Test_loss: 0.06720108670961795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [04:54<1:41:01,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 0.03383468005747076, Test_loss: 0.10676649183060238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [09:25<1:33:03,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Train_loss: 0.019373058599088333, Test_loss: 0.11135518092814149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 151/1000 [13:51<1:25:34,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 150, Train_loss: 0.015962506473368526, Test_loss: 0.11472971578996603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [18:20<1:21:16,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 200, Train_loss: 0.0140601390858694, Test_loss: 0.11930079646503591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 251/1000 [22:47<1:16:03,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 250, Train_loss: 0.012759751338266732, Test_loss: 0.11526866525500304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [27:13<1:10:20,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 300, Train_loss: 0.012094800922250936, Test_loss: 0.11767444585697079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 351/1000 [31:41<1:05:19,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 350, Train_loss: 0.01157003349694265, Test_loss: 0.11508300909329028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [36:08<1:00:52,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400, Train_loss: 0.011012145404676462, Test_loss: 0.11635177713014236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 451/1000 [40:36<55:10,  6.03s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 450, Train_loss: 0.010909603003733484, Test_loss: 0.11409826298738468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [45:02<50:07,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500, Train_loss: 0.008575687195489061, Test_loss: 0.11550050155183643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 551/1000 [49:30<45:19,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 550, Train_loss: 0.008165123385679221, Test_loss: 0.11800665370042936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 601/1000 [53:57<40:19,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600, Train_loss: 0.008090441865960554, Test_loss: 0.11870712872125766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 651/1000 [58:26<35:27,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 650, Train_loss: 0.00801173599158116, Test_loss: 0.12030187238096482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 701/1000 [1:02:52<30:15,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 700, Train_loss: 0.007955571956501728, Test_loss: 0.11987547439580061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 751/1000 [1:07:19<25:04,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 750, Train_loss: 0.007910319078130787, Test_loss: 0.11941177406836123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 801/1000 [1:12:12<20:28,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800, Train_loss: 0.007855552407044943, Test_loss: 0.12026849594030554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 851/1000 [1:17:34<16:57,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 850, Train_loss: 0.0077769591118253415, Test_loss: 0.11997881690103586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 901/1000 [1:22:39<10:01,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900, Train_loss: 0.007761164884085085, Test_loss: 0.12019464929214344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 951/1000 [1:27:10<05:01,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 950, Train_loss: 0.007728971761615436, Test_loss: 0.12006787273741397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:31:34<00:00,  5.49s/it]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_[:,0], pred_[:,0])\n",
    "    \n",
    "    l2_error_temp = l2_error(y_[:,0], pred_[:,0])\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 2.238344289441688\n",
      "L2 Error  of Temp: 0.1811062124721452\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 0.5608954087846175\n",
      "L2 Error  of Temp: 0.04882961744914135\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/direct_model_time_reduced.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.51555217])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
