{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ladwi\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:2')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix03</th>\n",
       "      <th>temp_conv04</th>\n",
       "      <th>temp_initial00</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "      <th>ice</th>\n",
       "      <th>snow</th>\n",
       "      <th>snowice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-10.049883</td>\n",
       "      <td>493.493435</td>\n",
       "      <td>-62.756461</td>\n",
       "      <td>-104.669918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.127760e-10</td>\n",
       "      <td>4.127760e-10</td>\n",
       "      <td>1.356178e-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136942</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-10.049883</td>\n",
       "      <td>493.493435</td>\n",
       "      <td>-62.756461</td>\n",
       "      <td>-104.669918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.063974e-01</td>\n",
       "      <td>1.063974e-01</td>\n",
       "      <td>2.019853e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136942</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-10.049883</td>\n",
       "      <td>493.493435</td>\n",
       "      <td>-62.756461</td>\n",
       "      <td>-104.669918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.332566e-01</td>\n",
       "      <td>2.332566e-01</td>\n",
       "      <td>1.994957e-02</td>\n",
       "      <td>6.016256</td>\n",
       "      <td>6.018909</td>\n",
       "      <td>0.136942</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-10.049883</td>\n",
       "      <td>493.493435</td>\n",
       "      <td>-62.756461</td>\n",
       "      <td>-104.669918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.605703e-01</td>\n",
       "      <td>3.605703e-01</td>\n",
       "      <td>1.924648e-02</td>\n",
       "      <td>6.068845</td>\n",
       "      <td>6.071542</td>\n",
       "      <td>0.136942</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-10.049883</td>\n",
       "      <td>493.493435</td>\n",
       "      <td>-62.756461</td>\n",
       "      <td>-104.669918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.726815e-01</td>\n",
       "      <td>4.726815e-01</td>\n",
       "      <td>3.375901e-02</td>\n",
       "      <td>6.124844</td>\n",
       "      <td>6.127587</td>\n",
       "      <td>0.136942</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751195</th>\n",
       "      <td>46</td>\n",
       "      <td>-12.920028</td>\n",
       "      <td>494.226632</td>\n",
       "      <td>-46.982710</td>\n",
       "      <td>-95.220702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.066941e+00</td>\n",
       "      <td>4.066941e+00</td>\n",
       "      <td>4.066863e+00</td>\n",
       "      <td>3.029762</td>\n",
       "      <td>3.030952</td>\n",
       "      <td>0.475050</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751196</th>\n",
       "      <td>47</td>\n",
       "      <td>-12.920028</td>\n",
       "      <td>494.226632</td>\n",
       "      <td>-46.982710</td>\n",
       "      <td>-95.220702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.172542e+00</td>\n",
       "      <td>4.172542e+00</td>\n",
       "      <td>4.172443e+00</td>\n",
       "      <td>3.185105</td>\n",
       "      <td>3.189226</td>\n",
       "      <td>0.475050</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751197</th>\n",
       "      <td>48</td>\n",
       "      <td>-12.920028</td>\n",
       "      <td>494.226632</td>\n",
       "      <td>-46.982710</td>\n",
       "      <td>-95.220702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.282669e+00</td>\n",
       "      <td>4.282669e+00</td>\n",
       "      <td>4.282541e+00</td>\n",
       "      <td>4.005785</td>\n",
       "      <td>4.009906</td>\n",
       "      <td>0.475050</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751198</th>\n",
       "      <td>49</td>\n",
       "      <td>-12.920028</td>\n",
       "      <td>494.226632</td>\n",
       "      <td>-46.982710</td>\n",
       "      <td>-95.220702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.386953e+00</td>\n",
       "      <td>4.386953e+00</td>\n",
       "      <td>4.386816e+00</td>\n",
       "      <td>4.826464</td>\n",
       "      <td>4.830586</td>\n",
       "      <td>0.475050</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751199</th>\n",
       "      <td>50</td>\n",
       "      <td>-12.920028</td>\n",
       "      <td>494.226632</td>\n",
       "      <td>-46.982710</td>\n",
       "      <td>-95.220702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>39850000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>4.503658e+00</td>\n",
       "      <td>4.503658e+00</td>\n",
       "      <td>4.503485e+00</td>\n",
       "      <td>7.996234</td>\n",
       "      <td>7.998070</td>\n",
       "      <td>0.475050</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>751200 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0           1    -10.049883     493.493435   -62.756461    -104.669918   \n",
       "1           2    -10.049883     493.493435   -62.756461    -104.669918   \n",
       "2           3    -10.049883     493.493435   -62.756461    -104.669918   \n",
       "3           4    -10.049883     493.493435   -62.756461    -104.669918   \n",
       "4           5    -10.049883     493.493435   -62.756461    -104.669918   \n",
       "...       ...           ...            ...          ...            ...   \n",
       "751195     46    -12.920028     494.226632   -46.982710     -95.220702   \n",
       "751196     47    -12.920028     494.226632   -46.982710     -95.220702   \n",
       "751197     48    -12.920028     494.226632   -46.982710     -95.220702   \n",
       "751198     49    -12.920028     494.226632   -46.982710     -95.220702   \n",
       "751199     50    -12.920028     494.226632   -46.982710     -95.220702   \n",
       "\n",
       "        Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  \\\n",
       "0                  0.0               0.4              -999.0   \n",
       "1                  0.0               0.4              -999.0   \n",
       "2                  0.0               0.4              -999.0   \n",
       "3                  0.0               0.4              -999.0   \n",
       "4                  0.0               0.4              -999.0   \n",
       "...                ...               ...                 ...   \n",
       "751195             0.0               0.4              -999.0   \n",
       "751196             0.0               0.4              -999.0   \n",
       "751197             0.0               0.4              -999.0   \n",
       "751198             0.0               0.4              -999.0   \n",
       "751199             0.0               0.4              -999.0   \n",
       "\n",
       "        ShearStress_Nm-2     Area_m2  ...  day_of_year  time_of_day  \\\n",
       "0                 -999.0  39850000.0  ...            3            0   \n",
       "1                 -999.0  39850000.0  ...            3            0   \n",
       "2                 -999.0  39850000.0  ...            3            0   \n",
       "3                 -999.0  39850000.0  ...            3            0   \n",
       "4                 -999.0  39850000.0  ...            3            0   \n",
       "...                  ...         ...  ...          ...          ...   \n",
       "751195            -999.0  39850000.0  ...          362           23   \n",
       "751196            -999.0  39850000.0  ...          362           23   \n",
       "751197            -999.0  39850000.0  ...          362           23   \n",
       "751198            -999.0  39850000.0  ...          362           23   \n",
       "751199            -999.0  39850000.0  ...          362           23   \n",
       "\n",
       "          temp_mix03   temp_conv04  temp_initial00  obs_temp  input_obs  \\\n",
       "0       4.127760e-10  4.127760e-10    1.356178e-09  0.000000   0.000000   \n",
       "1       1.063974e-01  1.063974e-01    2.019853e-02  0.000000   0.000000   \n",
       "2       2.332566e-01  2.332566e-01    1.994957e-02  6.016256   6.018909   \n",
       "3       3.605703e-01  3.605703e-01    1.924648e-02  6.068845   6.071542   \n",
       "4       4.726815e-01  4.726815e-01    3.375901e-02  6.124844   6.127587   \n",
       "...              ...           ...             ...       ...        ...   \n",
       "751195  4.066941e+00  4.066941e+00    4.066863e+00  3.029762   3.030952   \n",
       "751196  4.172542e+00  4.172542e+00    4.172443e+00  3.185105   3.189226   \n",
       "751197  4.282669e+00  4.282669e+00    4.282541e+00  4.005785   4.009906   \n",
       "751198  4.386953e+00  4.386953e+00    4.386816e+00  4.826464   4.830586   \n",
       "751199  4.503658e+00  4.503658e+00    4.503485e+00  7.996234   7.998070   \n",
       "\n",
       "             ice     snow  snowice  \n",
       "0       0.136942  0.00000      0.0  \n",
       "1       0.136942  0.00000      0.0  \n",
       "2       0.136942  0.00000      0.0  \n",
       "3       0.136942  0.00000      0.0  \n",
       "4       0.136942  0.00000      0.0  \n",
       "...          ...      ...      ...  \n",
       "751195  0.475050  0.00527      0.0  \n",
       "751196  0.475050  0.00527      0.0  \n",
       "751197  0.475050  0.00527      0.0  \n",
       "751198  0.475050  0.00527      0.0  \n",
       "751199  0.475050  0.00527      0.0  \n",
       "\n",
       "[751200 rows x 45 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time_reduced.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 30048\n",
      "Number of training points: 450700\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'AirTemp_degC',   'Shortwave_Wm-2',\n",
    "                'lightExtinct_m-1','Area_m2', 'Uw',\n",
    "                 'day_of_year', 'time_of_day'] #,  \n",
    "               #  'buoyancy', 'diffusivity', 'temp_initial00', \n",
    "               # 'temp_heat01', 'temp_diff02', 'temp_total05',\n",
    "               # 'ice', 'snow', 'snowice'\n",
    "output_columns = ['obs_temp']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (450700, 8), X_test: (300500, 8)\n",
      "y_train: (450700, 1), y_test: (300500, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1024\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32,32,32,32,32,32,32,32,32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=8, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_2): GELU()\n",
      "    (layer_3): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_3): GELU()\n",
      "    (layer_4): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_4): GELU()\n",
      "    (layer_5): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_5): GELU()\n",
      "    (layer_6): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_6): GELU()\n",
      "    (layer_7): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_7): GELU()\n",
      "    (layer_8): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_8): GELU()\n",
      "    (layer_9): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_9): GELU()\n",
      "    (layer_10): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:10<2:49:37, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 0.17730245337126746, Test_loss: 0.07473001008865987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [05:44<1:23:48,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 0.03333720698310675, Test_loss: 0.10099185850521943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 83/1000 [07:53<1:01:37,  4.03s/it]"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_[:,0], pred_[:,0])\n",
    "    \n",
    "    l2_error_temp = l2_error(y_[:,0], pred_[:,0])\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/direct_model_time_reduced.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
